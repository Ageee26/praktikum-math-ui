[
  {
    "objectID": "semuahalaman/praktikum.html",
    "href": "semuahalaman/praktikum.html",
    "title": "Praktikum",
    "section": "",
    "text": "Struktur Data (dengan Python)\n\n\n\n\n\nPersamaan Diferensial Numerik\nSains Data"
  },
  {
    "objectID": "semuahalaman/praktikum.html#semester-ganjil-september-desember-1",
    "href": "semuahalaman/praktikum.html#semester-ganjil-september-desember-1",
    "title": "Praktikum",
    "section": "Semester Ganjil (September-Desember)",
    "text": "Semester Ganjil (September-Desember)\n\nStruktur Data (modul belum tersedia)"
  },
  {
    "objectID": "semuahalaman/praktikum.html#semester-genap-februari-juni-1",
    "href": "semuahalaman/praktikum.html#semester-genap-februari-juni-1",
    "title": "Praktikum",
    "section": "Semester Genap (Februari-Juni)",
    "text": "Semester Genap (Februari-Juni)\n\nSains Data (modul belum tersedia)"
  },
  {
    "objectID": "semuahalaman/about.html",
    "href": "semuahalaman/about.html",
    "title": "About",
    "section": "",
    "text": "Langsung pencet Praktikum aja yaa!\nAbout this site"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/sainsdata/sainsdata2023.html",
    "href": "semuahalaman/modulprak/2023/genap/sainsdata/sainsdata2023.html",
    "title": "Praktikum Sains Data 2023 Genap",
    "section": "",
    "text": "Kembali ke Praktikum\nModul ini adalah salinan dari: https://github.com/carlesoctav/sains-data-2023\n\nTimeline\n\nmodul-tahun-lalu\npraktikum-1: 1 Maret 2023, presensi ristek.link/presensi-sains-data-01\npraktikum-2: 8 Maret 2023, presensi ristek.link/presensi-sains-data-02\npraktikum-3: 15 Maret 2023, presensi ristek.link/presensi-sains-data-03\nTugas-1: 22 Maret 2023, tempat pengumpulan: bit.ly/Tugas1PrakSainsData\nTugas-2: 21 April 2023, tempat pengumpulan: https://ristek.link/tugas-sains-data-02\nTugas-3: 21 April 2023, tempat pengumpulan: https://ristek.link/tugas-sains-data-03\npraktikum-4: 26 April 2023, presensi ristek.link/presensi-sains-data-04\npraktikum-5: 3 Mei 2023, presensi ristek.link/presensi-sains-data-05\npraktikum-6: 10 Mei 2023, presensi ristek.link/presensi-sains-data-06\ntugas-akhir"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/sainsdata/tugas/tugas-3.html",
    "href": "semuahalaman/modulprak/2023/genap/sainsdata/tugas/tugas-3.html",
    "title": "Lab Praktikum Departemen Matematika FMIPA UI",
    "section": "",
    "text": "Kembali ke Sains Data\n\n\n\nKerjakan secara individu\nKerjakan tugas ini dengan bahasa pemrograman python. Anda disarankan menggunakan jupyter untuk mengerjakan tugas ini.\nUntuk setiap proses sains data (pembersihan data, transformasi data, EDA, dan pemodela ) yang dilakukan Anda diperlukan untuk menuliskan justifikasi-nya. Justifikasi-nya dapat berupa penjelasan singkat mengenai proses yang dilakukan, dan penjelasan mengenai alasan mengapa anda melakukan proses tersebut.\nFile yang harus diunggah terdiri dari:\n\nbeberapa model dalam format .pkl. Penamaan untuk model dibebaskan, namun harus jelas mengenai model apa yang disimpan.\nsatu file python notebook (file berbentuk .ipynb BUKAN .py) dengan ketentuan serupa.\n\nSemua file disatukan dalam 1 (satu) file .zip, dengan format penamaan: Nama_NPM_Kelas SIAK Sains Data_Tugas3PrakSainsData.zip. contoh: Itadori-Yuji_190688675_A_Tugas3PrakSainsData.zip\nBatas pengumpulan tugas ini adalah 21 April 2023 pukul 23.59. Tugas dikumpulkan sesuai dengan link berikut: https://ristek.link/tugas-sains-data-03\nDilarang melakukan plagiarisme atau menduplikasi dalam mengerjakan tugas ini. Apabila terdapat kesamaan program atau penjelasan pada tugas yang dikumpulkan, NILAI TUGAS PRAKTIKUM SAINS DATA ANDA LANGSUNG MENJADI 0 TANPA PERINGATAN bagi semua pihak yang terlibat plagiarisme dalam tugas ini.\nGunakan module (python package) yang telah dipelajari di praktikum atau kelas. Anda diperbolehkan untuk menggunakan module (python package) lain dengan catatan bahwa Anda harus menuliskan penjelasan singkat mengenai module tersebut.\nApabila ada yang ingin ditanyakan anda dapat bertanya pada kolom komentar atau, silakan mengontak salah satu kontak berikut:\n\nLINE: Tulus Setiawan (WA/LINE: tlsnew/081213679316)\n\n\n\n\n\n[akses-data]: https://drive.google.com/open?id=19WogXg2YgH7tNhAXESJ7SaITOWGGu2HX&authuser=carlesoctavianus%40gmail.com&usp=drive_fs\nKerjakan secara end-to-end (pembersihan data, transformasi data , EDA, dan pemodelan) untuk mengklasifikasikan harga ponsel berdasarkan data yang diberikan. Gunakan metode yang telah dipelajari di praktikum ataupun kelas (model Klasifikasi)."
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/sainsdata/tugas/tugas-akhir.html",
    "href": "semuahalaman/modulprak/2023/genap/sainsdata/tugas/tugas-akhir.html",
    "title": "Lab Praktikum Departemen Matematika FMIPA UI",
    "section": "",
    "text": "Tugas Akhir\nKembali ke Sains Data\nTulisan di bawah ini adalah salinan dari: https://linevoom.line.me/post/1168595921012325899\n[TUGAS AKHIR PRAKTIKUM SAINS DATA dan PDNUM]\nSelamat sore, warga Departemen Matematika!\nBerikut ini adalah tugas praktikum yang harus dikerjakan bagi mahasiswa yang mengambil mata kuliah Sains Data dan PDNum.\nhttps://drive.google.com/drive/folders/10hEyh6MTFnrx2kwC4IEL74cOCo-_NoNQ\nTugas dikerjakan secara individu dengan ketentuan yang sudah tentukan di masing masing tugas yang tertera pada tautan di atas.\nTugas dikumpulkan paling lambat pada hari Rabu, 21 Juni 2023 pukul 23.59 WIB melalui tautan berikut.\nSains Data: https://forms.gle/4i2tj8Zf7v7kDPoG7\nPDNum: https://forms.gle/m8s6iqyufpH9g3fUA\nDemikian informasi yang dapat kami sampaikan. Jika ada pertanyaan lebih lanjut, silakan hubungi kontak berikut.\nNarahubung:\n■ Justin (LINE: iamjustin10)\n■ Carles (LINE: Carles_octavianus)\n■ Tulus (LINE: tlsnew)"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/sainsdata/tugas/tugas-2.html",
    "href": "semuahalaman/modulprak/2023/genap/sainsdata/tugas/tugas-2.html",
    "title": "Lab Praktikum Departemen Matematika FMIPA UI",
    "section": "",
    "text": "Kembali ke Sains Data\n\n\n\nKerjakan secara individu\nKerjakan tugas ini dengan bahasa pemrograman python. Anda disarankan menggunakan jupyter untuk mengerjakan tugas ini.\nUntuk setiap proses sains data (pembersihan data, transformasi data, EDA, dan pemodela ) yang dilakukan Anda diperlukan untuk menuliskan justifikasi-nya. Justifikasi-nya dapat berupa penjelasan singkat mengenai proses yang dilakukan, dan penjelasan mengenai alasan mengapa anda melakukan proses tersebut.\nFile yang harus diunggah terdiri dari:\n\nbeberapa model dalam format .pkl. Penamaan untuk model dibebaskan, namun harus jelas mengenai model apa yang disimpan.\nsatu file python notebook (file berbentuk .ipynb BUKAN .py) dengan ketentuan serupa.\n\nSemua file disatukan dalam 1 (satu) file .zip, dengan format penamaan: Nama_NPM_Kelas SIAK Sains Data_Tugas2PrakSainsData.zip. contoh: Itadori-Yuji_190688675_A_Tugas2PrakSainsData.zip\nBatas pengumpulan tugas ini adalah 21 April 2023 pukul 23.59. Tugas dikumpulkan sesuai dengan link berikut: https://ristek.link/tugas-sains-data-02\nDilarang melakukan plagiarisme atau menduplikasi dalam mengerjakan tugas ini. Apabila terdapat kesamaan program atau penjelasan pada tugas yang dikumpulkan, NILAI TUGAS PRAKTIKUM SAINS DATA ANDA LANGSUNG MENJADI 0 TANPA PERINGATAN bagi semua pihak yang terlibat plagiarisme dalam tugas ini.\nGunakan module (python package) yang telah dipelajari di praktikum atau kelas. Anda diperbolehkan untuk menggunakan module (python package) lain dengan catatan bahwa Anda harus menuliskan penjelasan singkat mengenai module tersebut.\nApabila ada yang ingin ditanyakan anda dapat bertanya pada kolom komentar atau, silakan mengontak salah satu kontak berikut:\n\nLINE: Carles_Octavianus (carles)\n\n\n\n\n\n[akses-data]: https://drive.google.com/open?id=1whKzd5rd-Rtg8bGmEYeBonsXLQMKfxTB&authuser=carlesoctavianus%40gmail.com&usp=drive_fs\nKerjakan secara end-to-end (pembersihan data, transformasi data , EDA, dan pemodelan) untuk memprediksi harga rumah berdasarkan data yang diberikan. Gunakan metode yang telah dipelajari di praktikum ataupun kelas (model regresi)."
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-02.html",
    "href": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-02.html",
    "title": "Lab Praktikum Departemen Matematika FMIPA UI",
    "section": "",
    "text": "Kembali ke Sains Data\nPada modul ini kita akan mempelajari beberapa cara untuk membuat visualisasi data menggunakan package Matplotlib dan Seaborn. Seaborn merupakan salah satu package visualisasi data yang sangat sering digunakan karena fleksibilitas dan banyaknya jenis plot yang disediakan.\n\n\n\n\nSebelum memulai, mari kita import terlebih dahulu module - module yang diperlukan.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n\n\nPada module kali ini, akan digunakan tiga data csv yang berbeda untuk mempermudah kebutuhan visualisasi.\nKetiga data tersebut dapat kalian unduh pada tautan berikut: https://bit.ly/DataWeek2\n\nspotify_df = pd.read_csv('data/week 2/spotify.csv', index_col='Date', parse_dates=['Date'])\nflight_df = pd.read_csv('data/week 2/flight_delays.csv')\ninsurance_df = pd.read_csv('data/week 2/insurance.csv')\n\n\n\n\n\nSeperti yang sudah dipelajari pada Algoritma dan Pemrograman, visualisasi data dapat dilakukan dengan module matplotlib, antara lain untuk membuat line plot dan scatter plot.\nPertama, kita akan menggunakan data Spotify, yaitu data total daily streams 5 lagu hits pada masanya.\n\nspotify_df\n\n\n\n\n\n  \n    \n      \n      Shape of You\n      Despacito\n      Something Just Like This\n      HUMBLE.\n      Unforgettable\n    \n    \n      Date\n      \n      \n      \n      \n      \n    \n  \n  \n    \n      2017-01-06\n      12287078\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      2017-01-07\n      13190270\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      2017-01-08\n      13099919\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      2017-01-09\n      14506351\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      2017-01-10\n      14275628\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      2018-01-05\n      4492978\n      3450315.0\n      2408365.0\n      2685857.0\n      2869783.0\n    \n    \n      2018-01-06\n      4416476\n      3394284.0\n      2188035.0\n      2559044.0\n      2743748.0\n    \n    \n      2018-01-07\n      4009104\n      3020789.0\n      1908129.0\n      2350985.0\n      2441045.0\n    \n    \n      2018-01-08\n      4135505\n      2755266.0\n      2023251.0\n      2523265.0\n      2622693.0\n    \n    \n      2018-01-09\n      4168506\n      2791601.0\n      2058016.0\n      2727678.0\n      2627334.0\n    \n  \n\n366 rows × 5 columns\n\n\n\nBerikut adalah cara untuk membuat line plot pada satu fitur di dataframe menggunakan matplotlib\n\n\"\"\"\nMembuat line plot untuk lagu Shape of You menggunakan matplotlib\n\"\"\"\n\n# Mengatur besar figur plot\nplt.subplots(figsize=(8,6))\n\n# Membuat line plot\nplt.plot(spotify_df['Shape of You'], 'b')\n# Membuat label sumbu-x dan sumbu-y\nplt.xlabel('Date')\nplt.ylabel('Shape of You Total Daily Streams')\n# Menampilkan plot\nplt.show()\n\n\n\n\nApabila kita ingin menampilkan fitur-fitur lain dalam figur yang sama, kita dapat memanfaatkan loop\n\n\"\"\"\nMembuat line plot untuk semua lagu dalam spotify_df menggunakan loop\n\"\"\"\n\nplt.subplots(figsize=(8,6))\n\n# Loop setiap nama kolom pada dataframe, lalu plot\nfor column in spotify_df.columns:\n    plt.plot(spotify_df[column])\n\nplt.legend(spotify_df.columns)\nplt.show()\n\n\n\n\nNamun, terdapat cara yang lebih mudah selain menggunakan looping. pandas dataframe memiliki method yang dapat secara langsung memvisualisasikan keseluruhan fiturnya, yaitu .plot().\nPada .plot() kita memiliki beberapa parameter yang dapat diatur, antara lain kind dan figsize. kind berfungsi untuk mengatur jenis plot yang ingin kita buat, sedangkan figsize berfungsi untuk mengatur besar figur yang dihasilkan.\nParameter lainnya dapat dilihat pada: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.html\n\n\"\"\"\nMembuat line plot untuk semua lagu dalam spotify_df menggunakan pandas .plot()\n\"\"\"\n\nspotify_df.plot(kind='line', figsize=(8,6))\nplt.xlabel('Date')\nplt.ylabel('Total Daily Streams')\nplt.show()\n\n\n\n\nSelain line plot, terdapat banyak macam kind yang bisa digunakan. Pada code cell dibawah terlihat bahwa pandas .plot() dapat menghasilkan histogram (perlu diperhatikan bahwa jenis plot perlu menyesuaikan tipe data yang dimiliki, terlihat bahwa menggunakan data spotify, histogram tidak menghasilkan insight yang cukup berguna).\n\nspotify_df.plot(kind='hist', figsize=(8,6), alpha=.7)\n\nplt.show()\n\n\n\n\nPada praktikum Algoritma dan Pemrograman kita juga telah mempelajari cara untuk membuat scatter plot. Berikut code untuk membuat scatter plot menggunakan matplotlib, untuk melihat korelasi antara daily streams lagu Shape of You dengan Something Just Like This.\n\n\"\"\"\nMembuat scatter plot untuk melihat korelasi antara lagu\nShape of You dengan Something Just Like This menggunakan\nmatplotlib\n\"\"\"\n\nplt.subplots(figsize=(8,6))\n\nplt.scatter(x=spotify_df['Shape of You'], \n            y=spotify_df['Something Just Like This'],\n            alpha=.5)\nplt.xlabel('\"Shape of You\" Total Daily Streams')\nplt.ylabel('\"Something Just Like This\" Total Daily Streams')\nplt.show()\n\n\n\n\n\n\n\nWalaupun matplotlib cukup fleksibel dalam menghasilkan plot, tetapi tipe plot yang disediakan cenderung terbatas. Oleh karena itu, kita dapat menggunakan Seaborn karena tipe plot yang disediakan sangat banyak sesuai kebutuhan kita, antara lain line, bar, heatmap, scatter, box, swarm, histogram, density, dan masih banyak lagi.\n\n\nLine plot biasa digunakan untuk melihat trend data dalam jangka waktu tertentu.\nUntuk membuat line plot pada seaborn, kita dapat menggunakan sns.lineplot(). Jika data yang ingin kita visualisasikan adalah dataframe, kita dapat memasukkan variabel dataframe tersebut pada parameter data, seperti code di bawah ini.\n\n\"\"\"\nMembuat line plot dengan module seaborn\n\"\"\"\n\nplt.subplots(figsize=(8,6))\nsns.lineplot(data=spotify_df)\nplt.show()\n\n\n\n\nFleksibilitas Seaborn membuat kita dapat memilih color palette yang sesuai dengan keinginan kita. Kita dapat memilih palette yang sudah disediakan oleh seaborn (antara lain: bright, deep, pastel, dan masih banyak lagi) atau kita dapat mengatur sendiri palette yang ingin kita gunakan.\nUntuk memilih palette yang akan digunakan untuk plot selanjutnya pada seaborn, kita dapat menggunakan sns.set_palette().\nJenis palette yang disediakan seaborn serta cara membuat color palette secara mandiri dapat dilihat pada: https://seaborn.pydata.org/tutorial/color_palettes.html#tools-for-choosing-color-palettes\n\n# Mengganti color palette menjadi \"bright\"\nsns.set_palette('bright')\n\n\n\"\"\"\nMembuat line plot setelah color palette diubah menjadi \"bright\"\n\"\"\"\n\n# Mengatur besar figur yang ingin ditampilkan\nplt.figure(figsize=(14,6))\n\n# Membuat line plot\nsns.lineplot(data=spotify_df)\n# Membuat judul figur\nplt.title(\"Daily Global Streams of Popular Songs in 2017-2018\")\n# Menampilkan plot\nplt.show()\n\n\n\n\nApabila tidak semua fitur pada data ingin kita visualisasikan, kita dapat menggunakan sns.lineplot() beberapa kali, sesuai dengan banyaknya fitur yang ingin kita tampilkan, seperti pada code di bawah.\n\nplt.figure(figsize=(14,6))\n\n# Membuat line plot hanya dengan lagu Shape of You\nsns.lineplot(data=spotify_df['Shape of You'], label=\"Shape of You\")\n# Menambahkan line plot pada figur dengan lagu Despacito\nsns.lineplot(data=spotify_df['Despacito'], label=\"Despacito\")\n\nplt.title(\"Daily Global Streams of Popular Songs in 2017-2018\")\nplt.xlabel(\"Date\")\nplt.ylabel('')\nplt.show()\n\n\n\n\n\n\n\nBar plot biasa digunakan untuk membandingkan kuantitas/nilai pada data bertipe kategori.\nSelanjutnya, kita akan menggunakan data flight_delays.csv, yaitu data rata-rata keterlambatan beberapa maskapai pesawat pada setiap bulannya.\n\nflight_df\n\n\n\n\n\n  \n    \n      \n      Month\n      AA\n      AS\n      B6\n      DL\n      EV\n      F9\n      HA\n      MQ\n      NK\n      OO\n      UA\n      US\n      VX\n      WN\n    \n  \n  \n    \n      0\n      1\n      6.955843\n      -0.320888\n      7.347281\n      -2.043847\n      8.537497\n      18.357238\n      3.512640\n      18.164974\n      11.398054\n      10.889894\n      6.352729\n      3.107457\n      1.420702\n      3.389466\n    \n    \n      1\n      2\n      7.530204\n      -0.782923\n      18.657673\n      5.614745\n      10.417236\n      27.424179\n      6.029967\n      21.301627\n      16.474466\n      9.588895\n      7.260662\n      7.114455\n      7.784410\n      3.501363\n    \n    \n      2\n      3\n      6.693587\n      -0.544731\n      10.741317\n      2.077965\n      6.730101\n      20.074855\n      3.468383\n      11.018418\n      10.039118\n      3.181693\n      4.892212\n      3.330787\n      5.348207\n      3.263341\n    \n    \n      3\n      4\n      4.931778\n      -3.009003\n      2.780105\n      0.083343\n      4.821253\n      12.640440\n      0.011022\n      5.131228\n      8.766224\n      3.223796\n      4.376092\n      2.660290\n      0.995507\n      2.996399\n    \n    \n      4\n      5\n      5.173878\n      -1.716398\n      -0.709019\n      0.149333\n      7.724290\n      13.007554\n      0.826426\n      5.466790\n      22.397347\n      4.141162\n      6.827695\n      0.681605\n      7.102021\n      5.680777\n    \n    \n      5\n      6\n      8.191017\n      -0.220621\n      5.047155\n      4.419594\n      13.952793\n      19.712951\n      0.882786\n      9.639323\n      35.561501\n      8.338477\n      16.932663\n      5.766296\n      5.779415\n      10.743462\n    \n    \n      6\n      7\n      3.870440\n      0.377408\n      5.841454\n      1.204862\n      6.926421\n      14.464543\n      2.001586\n      3.980289\n      14.352382\n      6.790333\n      10.262551\n      NaN\n      7.135773\n      10.504942\n    \n    \n      7\n      8\n      3.193907\n      2.503899\n      9.280950\n      0.653114\n      5.154422\n      9.175737\n      7.448029\n      1.896565\n      20.519018\n      5.606689\n      5.014041\n      NaN\n      5.106221\n      5.532108\n    \n    \n      8\n      9\n      -1.432732\n      -1.813800\n      3.539154\n      -3.703377\n      0.851062\n      0.978460\n      3.696915\n      -2.167268\n      8.000101\n      1.530896\n      -1.794265\n      NaN\n      0.070998\n      -1.336260\n    \n    \n      9\n      10\n      -0.580930\n      -2.993617\n      3.676787\n      -5.011516\n      2.303760\n      0.082127\n      0.467074\n      -3.735054\n      6.810736\n      1.750897\n      -2.456542\n      NaN\n      2.254278\n      -0.688851\n    \n    \n      10\n      11\n      0.772630\n      -1.916516\n      1.418299\n      -3.175414\n      4.415930\n      11.164527\n      -2.719894\n      0.220061\n      7.543881\n      4.925548\n      0.281064\n      NaN\n      0.116370\n      0.995684\n    \n    \n      11\n      12\n      4.149684\n      -1.846681\n      13.839290\n      2.504595\n      6.685176\n      9.346221\n      -1.706475\n      0.662486\n      12.733123\n      10.947612\n      7.012079\n      NaN\n      13.498720\n      6.720893\n    \n  \n\n\n\n\nUntuk membuat bar plot pada seaborn dengan dataframe, kita dapat menggunakan sns.barplot() dengan tiga parameter yang wajib kita set, yaitu:\n- data: dataframe yang ingin kita visualisasikan\n\n- x: nama fitur pada dataframe yang ingin kita jadikan sumbu-x\n\n- y: nama fitur pada dataframe yang ingin kita jadikan sumbu-y\nPada kode di bawah, juga digunakan satu parameter opsional, yaitu palette yang merupakan cara lain untuk mengatur color palette yang ingin kita gunakan\n\n\"\"\"\nMembuat bar plot keterlambatan maskapai EV setiap \nbulannya menggunakan seaborn\n\"\"\"\n\nplt.figure(figsize=(14,6))\n\nsns.barplot(data=flight_df, x='Month', y='EV',\n            palette=sns.color_palette('deep'))\nplt.ylabel('EV Flight Delays (minute)')\nplt.title('Average EV Flight Delays per Month')\nplt.show()\n\n\n\n\nBerdasarkan hasil plot di atas, terlihat bahwa maskapai EV memiliki rata-rata keterlambatan terlama pada bulan Juni, serta tercepat pada bulan September.\nSelanjutnya, mari kita coba lihat urutan rata-rata keterlambatan semua maskapai dalam satu tahun (maskapai mana yang memiliki rata-rata keterlambatan terlama, serta maskapai mana yang tercepat).\nHal pertama yang perlu kita lakukan adalah, jadikan fitur Month sebagai index dataframe.\n\n# Set fitur \"Month\" menjadi index dataframe\nflight_df = flight_df.set_index('Month')\nflight_df.head(2)\n\n\n\n\n\n  \n    \n      \n      AA\n      AS\n      B6\n      DL\n      EV\n      F9\n      HA\n      MQ\n      NK\n      OO\n      UA\n      US\n      VX\n      WN\n    \n    \n      Month\n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      1\n      6.955843\n      -0.320888\n      7.347281\n      -2.043847\n      8.537497\n      18.357238\n      3.512640\n      18.164974\n      11.398054\n      10.889894\n      6.352729\n      3.107457\n      1.420702\n      3.389466\n    \n    \n      2\n      7.530204\n      -0.782923\n      18.657673\n      5.614745\n      10.417236\n      27.424179\n      6.029967\n      21.301627\n      16.474466\n      9.588895\n      7.260662\n      7.114455\n      7.784410\n      3.501363\n    \n  \n\n\n\n\nSelanjutnya, kita perlu hitung rata-rata keterlambatan tiap maskapai dalam satu tahun, yaitu hitung rata-rata tiap kolom pada dataframe menggunakan .mean() (Tambahan: apabila kita ingin menghitung rata-rata tiap barisnya, kita dapat menggunakan parameter axis=1 pada .mean()). .mean() akan menghasilkan pandas Series.\nLalu, agar mempermudah kita dalam melihat visualisasi bar plotnya, kita dapat menggunakan .sort_values().\n\n# Simpan rata-rata keterlambatan semua maskapai dalam satu tahun pada variabel flight_mean_inyear\nflight_mean_inyear = flight_df.mean()\n# Urutkan flight_mean_inyear secara ascending\nflight_mean_inyear = flight_mean_inyear.sort_values()\n\nflight_mean_inyear\n\nAS    -1.023656\nDL     0.231116\nHA     1.993205\nUS     3.776815\nAA     4.120776\nWN     4.275277\nVX     4.717718\nUA     5.413415\nOO     5.909658\nMQ     5.964953\nEV     6.543328\nB6     6.788370\nF9    13.035736\nNK    14.549663\ndtype: float64\n\n\nTerakhir, visualisasikan bar plot menggunakan cara seperti sebelumnya.\nKita dapat lihat pada code dibawah bahwa tidak digunakan parameter data, karena flight_mean_inyear merupakan pandas Series (bukan dataframe) sehingga lebih mudah jika kita langsung menggunakan parameter x dan y saja.\n\nplt.subplots(figsize=(14,6))\nsns.barplot(x=flight_mean_inyear.index, \n            y=flight_mean_inyear.values,\n            palette=sns.color_palette('deep'))\nplt.title('Average Delay per Flight in a Year')\nplt.show()\n\n\n\n\nBerdasarkan plot diatas, NK merupakan maskapai dengan rata-rata keterlambatan terlama dalam satu tahun, sedangkan AS adalah yang tercepat (AS bernilai negatif yang berarti rata-rata kedatangan pesawat lebih cepat dari yang dijadwalkan dalam satu tahun.\n\n\n\nHeatmap biasa digunakan untuk mempermudah melihat pola pada data berdasarkan warna yang dihasilkan.\nPada seaborn, kita dapat menggunakan heatmap dengan sns.heatmap() seperti pada kode dibawah. Parameter annot berfungsi untuk menampilkan nilai data (jika True) atau tidak (jika False).\nBar sebelah kanan heatmap menunjukkan bahwa, semakin lama keterlambatan pesawat, maka warna yang dihasilkan semakin terang. Sebaliknya, semakin gelap warna yang dihasilkan berarti semakin cepat pesawat datang tersebut.\n\n\"\"\"\nMembuat heatmap menggunakan Seaborn\n\"\"\"\nplt.figure(figsize=(14,10))\n\nsns.heatmap(data=flight_df, annot=True)\nplt.title(\"Average Arrival Delay for Each Airline, by Month\")\nplt.xlabel(\"Airline\")\nplt.show()\n\n\n\n\nBerdasarkan heatmap di atas, kita dapat melihat dengan mudah pada bulan apa suatu maskapai sangat terlambat (contoh: maskapai NK pada bulan Juni).\nHeatmap sangat sering digunakan untuk melihat korelasi antarfitur pada dataset agar kita dapat mengerti lebih jauh tentang fitur-fitur pada data, atau juga dapat dimanfaatkan untuk melakukan feature selection sebelum membuat sebuat model Machine Learning.\nUntuk melakukan hal tersebut, kita perlu menghitung dahulu korelasi antar fitur menggunakan pandas .corr(), yaitu fungsi yang akan menghitung korelasi antar dua fitur menggunakan korelasi Pearson.\nNotes: Metode korelasi dapat diubah dengan menggunakan parameter method pada .corr(), contoh: .corr(method='spearman'). Metode lainnya dapat dilihat pada: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html\n\n# Hitung korelasi antar dua fitur pada flight_df\nflight_corr = flight_df.corr()\n\nflight_corr\n\n\n\n\n\n  \n    \n      \n      AA\n      AS\n      B6\n      DL\n      EV\n      F9\n      HA\n      MQ\n      NK\n      OO\n      UA\n      US\n      VX\n      WN\n    \n  \n  \n    \n      AA\n      1.000000\n      0.334980\n      0.429854\n      0.805229\n      0.896523\n      0.903986\n      0.220065\n      0.842701\n      0.573716\n      0.620477\n      0.809874\n      0.823713\n      0.425237\n      0.615664\n    \n    \n      AS\n      0.334980\n      1.000000\n      0.340359\n      0.394359\n      0.356608\n      0.336791\n      0.684979\n      0.283977\n      0.480863\n      0.350657\n      0.457414\n      0.489025\n      0.229571\n      0.519228\n    \n    \n      B6\n      0.429854\n      0.340359\n      1.000000\n      0.643313\n      0.342627\n      0.510718\n      0.467905\n      0.529724\n      0.032038\n      0.591115\n      0.233021\n      0.788345\n      0.579750\n      0.151750\n    \n    \n      DL\n      0.805229\n      0.394359\n      0.643313\n      1.000000\n      0.796951\n      0.783265\n      0.262251\n      0.598765\n      0.625277\n      0.569073\n      0.797339\n      0.821757\n      0.700605\n      0.691805\n    \n    \n      EV\n      0.896523\n      0.356608\n      0.342627\n      0.796951\n      1.000000\n      0.828515\n      0.099369\n      0.721468\n      0.784026\n      0.692697\n      0.911499\n      0.669736\n      0.462638\n      0.730115\n    \n    \n      F9\n      0.903986\n      0.336791\n      0.510718\n      0.783265\n      0.828515\n      1.000000\n      0.273878\n      0.912984\n      0.414064\n      0.582509\n      0.671986\n      0.878874\n      0.308397\n      0.465765\n    \n    \n      HA\n      0.220065\n      0.684979\n      0.467905\n      0.262251\n      0.099369\n      0.273878\n      1.000000\n      0.436015\n      0.176485\n      0.056941\n      0.066821\n      0.586160\n      -0.008439\n      -0.007296\n    \n    \n      MQ\n      0.842701\n      0.283977\n      0.529724\n      0.598765\n      0.721468\n      0.912984\n      0.436015\n      1.000000\n      0.281890\n      0.586963\n      0.503575\n      0.660181\n      0.150111\n      0.239744\n    \n    \n      NK\n      0.573716\n      0.480863\n      0.032038\n      0.625277\n      0.784026\n      0.414064\n      0.176485\n      0.281890\n      1.000000\n      0.365273\n      0.827455\n      0.293515\n      0.395419\n      0.742869\n    \n    \n      OO\n      0.620477\n      0.350657\n      0.591115\n      0.569073\n      0.692697\n      0.582509\n      0.056941\n      0.586963\n      0.365273\n      1.000000\n      0.626051\n      0.590313\n      0.561515\n      0.548304\n    \n    \n      UA\n      0.809874\n      0.457414\n      0.233021\n      0.797339\n      0.911499\n      0.671986\n      0.066821\n      0.503575\n      0.827455\n      0.626051\n      1.000000\n      0.477816\n      0.536968\n      0.926800\n    \n    \n      US\n      0.823713\n      0.489025\n      0.788345\n      0.821757\n      0.669736\n      0.878874\n      0.586160\n      0.660181\n      0.293515\n      0.590313\n      0.477816\n      1.000000\n      0.333396\n      0.242344\n    \n    \n      VX\n      0.425237\n      0.229571\n      0.579750\n      0.700605\n      0.462638\n      0.308397\n      -0.008439\n      0.150111\n      0.395419\n      0.561515\n      0.536968\n      0.333396\n      1.000000\n      0.630278\n    \n    \n      WN\n      0.615664\n      0.519228\n      0.151750\n      0.691805\n      0.730115\n      0.465765\n      -0.007296\n      0.239744\n      0.742869\n      0.548304\n      0.926800\n      0.242344\n      0.630278\n      1.000000\n    \n  \n\n\n\n\nPandas .corr() menghasilkan dataframe dengan nama baris dan kolom yang sama, serta berisi nilai korelasi antara baris dan kolom yang ditinjau (contoh: korelasi antara maskapai AA dan AS adalah 0,334980). Serta, dataframe yang dihasilkan adalah sebuat matriks simetris.\nTentu dengan hanya melihat dataframe di atas, tidak terlihat begitu jelas mana fitur yang memiliki korelasi tinggi dan mana yang yang memiliki korelasi rendah. Oleh karena itu, kita dapat memanfaatkan heatmap.\nPada code di bawah, untuk mempermudah pembacaan heatmap, kita menggunakan parameter vmin, vmax, dan center pada sns.heatmap(). vmin berfungsi untuk mengatur nilai terendah, vmax berfungsi untuk mengatur nilai tertinggi, dan center berfungsi untuk mengatur nilai tengah pada heatmap. Korelasi Pearson menghasilkan nilai antara -1 hingga 1, sehingga kita dapat set ketiga parameter tersebut seperti pada code di bawah.\n\nplt.figure(figsize=(14,10))\n\nsns.heatmap(data=flight_corr, vmin=-1, vmax=1, center=0, annot=True)\nplt.title(\"Pearson Correlation of Each Airline Flight Delays\")\nplt.xlabel(\"Airline\")\nplt.show()\n\n\n\n\nDengan menggunakan heatmap, sekarang terlihat bahwa mana maskapai yang keterlambatannya berkorelasi tinggi dan mana yang rendah. Misal, AA dan EV menghasilkan korelasi yang cukup tinggi positif, yaitu 0.9, yang artinya jika keterlambatan maskapai AA tinggi, begitu juga maskapai EV, dan sebaliknya jika keterlambatan maskapai AA rendah, begitu juga maskapai EV.\nUntuk meyakinkan kita dengan hal tersebut, kita dapat lihat pada materi selanjutnya, yaitu Scatter Plot.\n\n\n\nScatter plot biasa digunakan untuk melihat korelasi antara dua fitur bertipe numerik.\nUntuk menggunakan scatter plot pada seaborn, kita dapat menggunakan sns.scatterplot(), dengan parameter yang sama seperti kita membuat bar plot.\n\n\"\"\"\nMembuat scatter plot untuk melihat \nketerkaitan pada keterlambatan pesawat\nmaskapai EV dan AA\n\"\"\"\n\nsns.scatterplot(data=flight_df, x='EV', y='AA')\nplt.show()\n\n\n\n\nMelalui scatter plot di atas, kita dapat semakin yakin bahwa kesimpulan yang kita ambil dengan melihat heatmap sebelumnya benar.\n\n\"\"\"\nTambahan scatter plot pada maskapai lain yang\nmemiliki korelasi tinggi\n\"\"\"\n\nsns.scatterplot(data=flight_df, x='EV', y='UA')\nplt.show()\n\n\n\n\n\n\"\"\"\nScatter plot pada maskapai yang memiliki\nkorelasi rendah (mendekati 0)\n\"\"\"\n\nsns.scatterplot(data=flight_df, x='UA', y='HA')\nplt.show()\n\n\n\n\nPada heatmap, terlihat bahwa maskapai UA dan HA memiliki korelasi yang rendah, yaitu 0.067. Sehingga, jika kita buat scatter plotnya, menghasilkan plot seperti di atas.\nUntuk memahami scatter plot lebih baik, kita akan menggunakan dataset lainnya, yaitu insurance.csv yang merupakan data berisi biaya asuransi (charges) beberapa orang.\n\ninsurance_df.head()\n\n\n\n\n\n  \n    \n      \n      age\n      sex\n      bmi\n      children\n      smoker\n      region\n      charges\n    \n  \n  \n    \n      0\n      19\n      female\n      27.900\n      0\n      yes\n      southwest\n      16884.92400\n    \n    \n      1\n      18\n      male\n      33.770\n      1\n      no\n      southeast\n      1725.55230\n    \n    \n      2\n      28\n      male\n      33.000\n      3\n      no\n      southeast\n      4449.46200\n    \n    \n      3\n      33\n      male\n      22.705\n      0\n      no\n      northwest\n      21984.47061\n    \n    \n      4\n      32\n      male\n      28.880\n      0\n      no\n      northwest\n      3866.85520\n    \n  \n\n\n\n\nMisal, kita ingin melihat keterkaitan indeks massa tubuh (bmi) seseorang dengan biaya asuransi (charges) orang tersebut. Sama seperti sebelumnya, kita dapat melakukannya seperti pada code di bawah.\n\n# Mengubah palette menjadi default\nsns.set_palette('tab10')\n# Membuat scatter plot antara fitur bmi dan charges\nsns.scatterplot(data=insurance_df, x='bmi', y='charges')\n\nplt.show()\n\n\n\n\nScatter plot di atas menunjukkan bahwa korelasi antara bmi dan charges adalah cenderung positif, tetapi tidak terlalu tinggi. Yang artinya, orang dengan BMI tinggi, cenderung akan membayar biaya asuransi lebih tinggi.\nAgar kita semakin yakin dengan kesimpulan tersebut, kita dapat menambahakn garis regresi pada scatter plot tersebut dengan menggunakan sns.regplot().\n\nsns.regplot(data=insurance_df, x='bmi', y='charges')\nplt.show()\n\n\n\n\nBerdasarkan scatter plot dan garis regresi dihasilkan, terlihat bahwa kesimpulan yang kita ambil benar. Agar semakin yakin lagi, kita juga dapat menghitung langsung korelasi Pearsonnya menggunakan cara sebelumnya, yaitu pandas .corr().\n\ninsurance_df[['bmi', 'charges']].corr()\n\n\n\n\n\n  \n    \n      \n      bmi\n      charges\n    \n  \n  \n    \n      bmi\n      1.000000\n      0.198341\n    \n    \n      charges\n      0.198341\n      1.000000\n    \n  \n\n\n\n\nDengan menggunakan seaborn, kita juga dapat memvisualisasikan scatter plot berdasarkan dengan pewarnaan yang berbeda berdasarkan fitur lainnya yang bertipe kategorik.\nMisal, kita ingin membuat scatter plot antara fitur bmi dan charges dengan pewarnaannya berdasarkan nilai dari fitur smoker, yaitu yes atau no. Kita dapat set parameter hue='smoker' pada sns.scatterplot() seperti pada code di bawah.\n\nsns.scatterplot(data=insurance_df, x='bmi', y='charges', hue='smoker')\nplt.show()\n\n\n\n\nSehingga dihasilkan pewarnaan yang berbeda untuk seseorang yang merupakan perokok (biru) dan yang tidak (orange). Berdasarkan scatter plot di atas, terlihat bahwa korelasi antara bmi dan charges untuk perokok cendering tinggi positif (semakin besar bmi, semakin besar juga charges). Sedangkan, untuk bukan perokok, korelasinya cenderung rendah (semakin besar bmi, tidak terlalu berpengaruh terhadap charges).\nSeperti cara sebelumnya, kita dapat menambahkan garis regresi. Namun, karena kita disini menggunakan hue, terdapat dua cara untuk menambahkan garis regresi, yaitu yang pertama adalah menggunakan sns.regplot() seperti di bawah ini.\n\nsns.regplot(data=insurance_df.query('smoker == \"yes\"'), x='bmi', y='charges') # axes 1\nsns.regplot(data=insurance_df.query('smoker == \"no\"'), x='bmi', y='charges') # axes 2\nplt.show()\n\n\n\n\nPerhatikan bahwa sns.regplot() dipanggil dua kali karena fungsi tersebut tidak memiliki parameter hue.\nUntuk mempermudah, kita dapat menggunakan cara kedua, yaitu menggunakan sns.lmplot(). Cara kerja sns.lmplot() yaitu menggabungkan dua (atau lebih) sns.regplot() dalam satu figur.\n\nsns.lmplot(data=insurance_df, x='bmi', y='charges', hue='smoker')\nplt.show()\n\n\n\n\n\n\n\nBox plot dan swarm plot biasa digunakan untuk melihat keterkaitan antara data kategorik dan data numerik. Swarm plot biasa disebut sebagai “categorical scatter plot”, karena plot yang dihasilkan mirip seperti scatter plot, tetapi untuk data kategorik.\nUntuk menggunakan box plot pada seaborn kita dapat menggunakan sns.boxplot().\nUntuk menggunakan swarm plot pada seaborn kita dapat menggunakan sns.swarmplot().\nMisal, kita ingin melihat keterkaitan antara fitur smoker dan charges menggunakan swarm plot. Maka, kita dapat menggunakan code seperti di bawah ini.\n\nplt.subplots(figsize=(10,6))\n\nsns.swarmplot(data=insurance_df, x='smoker', y='charges', size=3)\nplt.show()\n\n\n\n\nBerdasarkan swarm plot di atas, terlihat bahwa perokok cenderung memiliki biaya asuransi yang lebih tinggi dibandingkan yang bukan perokok. Selain itu, semakin lebar “swarm” pada suatu kategori berarti semakin banyak seseorang dengan nilai charges tersebut.\nApabila kita ingin menggunakan box plot, maka dapat digunakan code seperti di bawah ini.\n\nsns.boxplot(data=insurance_df, x='smoker', y='charges')\nplt.show()\n\n\n\n\nPada box plot, terdapat dua istilah yang umum digunakan, yaitu “box” dan “whiskers”. Pada box plot di atas, “box” merupakan persegi panjang berwarna biru dan orange. Garis di tengah box merupakan nilai mediannya, serta garis bawah dan garis atas box merupakan kuartil bawah (Q1) dan kuartil atas (Q3) secara berurutan. “Whiskers” adalah garis yang merupakan perpanjangan dari box. Ujung dari whiskers atas adalah Q3 + (1.5 x IQR) data, sedangkan ujung whiskers bawah adalah Q1 - (1.5 x IQR) data.\nTitik di luar box dan whiskers tersebut adalah titik yang biasa dijadikan sebagai outlier (penentuan outlier diserahkan ke diri masing-masing, apakah hanya dengan melihat box plot atau dengan menggunakan metode lain, tetapi untuk mempermudah dapat menggunakan box plot).\n\n\n\nSelain box plot dan swarm plot, kita juga dapat melihat persebaran data menggunakan histogram dan density plot. Histogram biasa digunakan untuk melihat persebaran data secara diskrit, sedangkan density plot untuk melihat persebaran data secara kontinu.\nUntuk membuat histogram pada seaborn, kita dapat menggunakan sns.histplot().\nUntuk membuat density plot pada seaborn, kita dapat menggunakan sns.kdeplot().\nMisal, kita ingin melihat persebaran dari fitur charges pada insurance_df. Maka dapat digunakan code seperti di bawah.\n\nplt.subplots(figsize=(12,6))\n\nsns.histplot(data=insurance_df, x='charges')\nplt.show()\n\n\n\n\nBerdasarkan histogram di atas, terlihat bahwa distribusi charges cenderung “skew” atau miring ke kanan. “Skewness” atau tingkat kecondongan merupakan aspek yang penting untuk diperhatikan ketika kita ingin membuat model Machine Learning.\nSeperti scatter plot, kita juga dapat menentukan pewarnaan histogram berdasarkan fitur lainnya dengan menggunakan parameter hue seperti di bawah ini/\n\nplt.subplots(figsize=(12,6))\nsns.histplot(data=insurance_df, x='charges', hue='smoker')\nplt.show()\n\n\n\n\nJika ingin membuat density plot dari fitur charges, kita dapat menggunakan kode seperti di bawah ini. Parameter shade berfungsi untuk memberikan warna di bawah kurva.\n\nplt.subplots(figsize=(12,6))\nsns.kdeplot(data=insurance_df, x='charges', shade=True)\nplt.show()\n\n\n\n\nsns.kdeplot() juga dapat menggunakan parameter hue.\n\nplt.subplots(figsize=(12,6))\nsns.kdeplot(data=insurance_df, x='charges',\n            hue='smoker', shade=True)\nplt.show()\n\n\n\n\nApabila kita ingin menggabungkan histogram dan density plot dalam satu figur, kita dapat menggunakan sns.histplot() dengan parameter kde=True.\n\nplt.subplots(figsize=(12,6))\nsns.histplot(data=insurance_df, x='charges', hue='smoker', kde=True)\nplt.show()\n\n\n\n\n\n\n\nPada seaborn, kita juga dapat membuat dua plot yang berbeda dari dua fitur dalam satu figur yang sama menggunakan sns.jointplot().\nJenis plot yang dihasilkan dapat diatur pada parameter kind. Pilihan jenis kind yang disediakan dapat dilihat pada: https://seaborn.pydata.org/generated/seaborn.jointplot.html\n\nsns.jointplot(data=insurance_df, x='charges', y='bmi', hue='smoker', kind=\"scatter\")\n\nplt.show()\n\n\n\n\n\nsns.jointplot(data=insurance_df, x='charges', y='bmi', hue='smoker', kind=\"hist\")\n\nplt.show()\n\n\n\n\n\nsns.jointplot(data=insurance_df, x='charges', y='bmi', hue='smoker', kind=\"kde\")\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nimage.png\n\n\nsource: https://www.kaggle.com/code/alexisbcook/choosing-plot-types-and-custom-styles"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-04.html",
    "href": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-04.html",
    "title": "Lab Praktikum Departemen Matematika FMIPA UI",
    "section": "",
    "text": "Kembali ke Sains Data\nClustering adalah metode untuk membagi populasi atau titik data ke dalam sejumlah kelompok sedemikian rupa sehingga titik data dalam kelompok yang sama lebih mirip dengan titik data lain dalam kelompok yang sama dan berbeda dengan titik data dalam kelompok lain. Pada dasarnya, ini adalah kumpulan objek berdasarkan kesamaan dan ketidaksamaan di antara mereka.\nsource: https://www.geeksforgeeks.org/clustering-in-machine-learning/\nDataset: https://drive.google.com/file/d/1QWrWOYx2cZyEfYLe652Aj8IMm8mlkMy9/view?usp=sharing\n\n\nK-means clustering adalah algoritma unsupervised learning yang mengelompokkan dataset yang belum dilabel ke dalam kluster yang berbeda berdasarkan kesamaan tertentu\\(^{[1][2][3]}\\). K-means clustering membutuhkan nilai k yang menandakan jumlah kluster yang akan dibentuk\\(^{[1][4]}\\). K-means clustering berusaha untuk meminimalisasi variasi antar kluster dan memaksimalisasi variasi antar kluster\\(^{[2][5]}\\). K-means clustering menggunakan rata-rata dan jarak antara data dan centroid untuk menentukan kluster\\(^{[2][5]}\\). K-means clustering bekerja dengan baik jika kluster memiliki bentuk bola\\(^{[3]}\\).\nsource:\n[1] https://www.trivusi.web.id/2022/06/algoritma-kmeans-clustering.html\n[2] https://raharja.ac.id/2020/04/19/k-means-clustering/\n[3] https://ichi.pro/id/k-means-clustering-algoritma-aplikasi-metode-evaluasi-dan-kelemahan-186933724886154\n[4] https://dqlab.id/k-means-clustering-salah-satu-contoh-teknik-analisis-data-populer\n[5] https://sis.binus.ac.id/2022/01/31/clustering-algoritma-k-means/.\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\n\n\n\ndataset = pd.read_csv('Mall_Customers.csv')\ndataset\n\n\n\n  \n    \n      \n\n\n  \n    \n      \n      CustomerID\n      Genre\n      Age\n      Annual Income (k$)\n      Spending Score (1-100)\n    \n  \n  \n    \n      0\n      1\n      Male\n      19\n      15\n      39\n    \n    \n      1\n      2\n      Male\n      21\n      15\n      81\n    \n    \n      2\n      3\n      Female\n      20\n      16\n      6\n    \n    \n      3\n      4\n      Female\n      23\n      16\n      77\n    \n    \n      4\n      5\n      Female\n      31\n      17\n      40\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      195\n      196\n      Female\n      35\n      120\n      79\n    \n    \n      196\n      197\n      Female\n      45\n      126\n      28\n    \n    \n      197\n      198\n      Male\n      32\n      126\n      74\n    \n    \n      198\n      199\n      Male\n      32\n      137\n      18\n    \n    \n      199\n      200\n      Male\n      30\n      137\n      83\n    \n  \n\n200 rows × 5 columns\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\nX = dataset.iloc[:, [3, 4]].values\nX\n\narray([[ 15,  39],\n       [ 15,  81],\n       [ 16,   6],\n       [ 16,  77],\n       [ 17,  40],\n       [ 17,  76],\n       [ 18,   6],\n       [ 18,  94],\n       [ 19,   3],\n       [ 19,  72],\n       [ 19,  14],\n       [ 19,  99],\n       [ 20,  15],\n       [ 20,  77],\n       [ 20,  13],\n       [ 20,  79],\n       [ 21,  35],\n       [ 21,  66],\n       [ 23,  29],\n       [ 23,  98],\n       [ 24,  35],\n       [ 24,  73],\n       [ 25,   5],\n       [ 25,  73],\n       [ 28,  14],\n       [ 28,  82],\n       [ 28,  32],\n       [ 28,  61],\n       [ 29,  31],\n       [ 29,  87],\n       [ 30,   4],\n       [ 30,  73],\n       [ 33,   4],\n       [ 33,  92],\n       [ 33,  14],\n       [ 33,  81],\n       [ 34,  17],\n       [ 34,  73],\n       [ 37,  26],\n       [ 37,  75],\n       [ 38,  35],\n       [ 38,  92],\n       [ 39,  36],\n       [ 39,  61],\n       [ 39,  28],\n       [ 39,  65],\n       [ 40,  55],\n       [ 40,  47],\n       [ 40,  42],\n       [ 40,  42],\n       [ 42,  52],\n       [ 42,  60],\n       [ 43,  54],\n       [ 43,  60],\n       [ 43,  45],\n       [ 43,  41],\n       [ 44,  50],\n       [ 44,  46],\n       [ 46,  51],\n       [ 46,  46],\n       [ 46,  56],\n       [ 46,  55],\n       [ 47,  52],\n       [ 47,  59],\n       [ 48,  51],\n       [ 48,  59],\n       [ 48,  50],\n       [ 48,  48],\n       [ 48,  59],\n       [ 48,  47],\n       [ 49,  55],\n       [ 49,  42],\n       [ 50,  49],\n       [ 50,  56],\n       [ 54,  47],\n       [ 54,  54],\n       [ 54,  53],\n       [ 54,  48],\n       [ 54,  52],\n       [ 54,  42],\n       [ 54,  51],\n       [ 54,  55],\n       [ 54,  41],\n       [ 54,  44],\n       [ 54,  57],\n       [ 54,  46],\n       [ 57,  58],\n       [ 57,  55],\n       [ 58,  60],\n       [ 58,  46],\n       [ 59,  55],\n       [ 59,  41],\n       [ 60,  49],\n       [ 60,  40],\n       [ 60,  42],\n       [ 60,  52],\n       [ 60,  47],\n       [ 60,  50],\n       [ 61,  42],\n       [ 61,  49],\n       [ 62,  41],\n       [ 62,  48],\n       [ 62,  59],\n       [ 62,  55],\n       [ 62,  56],\n       [ 62,  42],\n       [ 63,  50],\n       [ 63,  46],\n       [ 63,  43],\n       [ 63,  48],\n       [ 63,  52],\n       [ 63,  54],\n       [ 64,  42],\n       [ 64,  46],\n       [ 65,  48],\n       [ 65,  50],\n       [ 65,  43],\n       [ 65,  59],\n       [ 67,  43],\n       [ 67,  57],\n       [ 67,  56],\n       [ 67,  40],\n       [ 69,  58],\n       [ 69,  91],\n       [ 70,  29],\n       [ 70,  77],\n       [ 71,  35],\n       [ 71,  95],\n       [ 71,  11],\n       [ 71,  75],\n       [ 71,   9],\n       [ 71,  75],\n       [ 72,  34],\n       [ 72,  71],\n       [ 73,   5],\n       [ 73,  88],\n       [ 73,   7],\n       [ 73,  73],\n       [ 74,  10],\n       [ 74,  72],\n       [ 75,   5],\n       [ 75,  93],\n       [ 76,  40],\n       [ 76,  87],\n       [ 77,  12],\n       [ 77,  97],\n       [ 77,  36],\n       [ 77,  74],\n       [ 78,  22],\n       [ 78,  90],\n       [ 78,  17],\n       [ 78,  88],\n       [ 78,  20],\n       [ 78,  76],\n       [ 78,  16],\n       [ 78,  89],\n       [ 78,   1],\n       [ 78,  78],\n       [ 78,   1],\n       [ 78,  73],\n       [ 79,  35],\n       [ 79,  83],\n       [ 81,   5],\n       [ 81,  93],\n       [ 85,  26],\n       [ 85,  75],\n       [ 86,  20],\n       [ 86,  95],\n       [ 87,  27],\n       [ 87,  63],\n       [ 87,  13],\n       [ 87,  75],\n       [ 87,  10],\n       [ 87,  92],\n       [ 88,  13],\n       [ 88,  86],\n       [ 88,  15],\n       [ 88,  69],\n       [ 93,  14],\n       [ 93,  90],\n       [ 97,  32],\n       [ 97,  86],\n       [ 98,  15],\n       [ 98,  88],\n       [ 99,  39],\n       [ 99,  97],\n       [101,  24],\n       [101,  68],\n       [103,  17],\n       [103,  85],\n       [103,  23],\n       [103,  69],\n       [113,   8],\n       [113,  91],\n       [120,  16],\n       [120,  79],\n       [126,  28],\n       [126,  74],\n       [137,  18],\n       [137,  83]])\n\n\n\n\n\n\nhelp(KMeans)\n\nHelp on class KMeans in module sklearn.cluster._kmeans:\n\nclass KMeans(_BaseKMeans)\n |  KMeans(n_clusters=8, *, init='k-means++', n_init='warn', max_iter=300, tol=0.0001, verbose=0, random_state=None, copy_x=True, algorithm='lloyd')\n |  \n |  K-Means clustering.\n |  \n |  Read more in the :ref:`User Guide <k_means>`.\n |  \n |  Parameters\n |  ----------\n |  \n |  n_clusters : int, default=8\n |      The number of clusters to form as well as the number of\n |      centroids to generate.\n |  \n |  init : {'k-means++', 'random'}, callable or array-like of shape             (n_clusters, n_features), default='k-means++'\n |      Method for initialization:\n |  \n |      'k-means++' : selects initial cluster centroids using sampling based on\n |      an empirical probability distribution of the points' contribution to the\n |      overall inertia. This technique speeds up convergence. The algorithm\n |      implemented is \"greedy k-means++\". It differs from the vanilla k-means++\n |      by making several trials at each sampling step and choosing the best centroid\n |      among them.\n |  \n |      'random': choose `n_clusters` observations (rows) at random from data\n |      for the initial centroids.\n |  \n |      If an array is passed, it should be of shape (n_clusters, n_features)\n |      and gives the initial centers.\n |  \n |      If a callable is passed, it should take arguments X, n_clusters and a\n |      random state and return an initialization.\n |  \n |  n_init : 'auto' or int, default=10\n |      Number of times the k-means algorithm is run with different centroid\n |      seeds. The final results is the best output of `n_init` consecutive runs\n |      in terms of inertia. Several runs are recommended for sparse\n |      high-dimensional problems (see :ref:`kmeans_sparse_high_dim`).\n |  \n |      When `n_init='auto'`, the number of runs depends on the value of init:\n |      10 if using `init='random'`, 1 if using `init='k-means++'`.\n |  \n |      .. versionadded:: 1.2\n |         Added 'auto' option for `n_init`.\n |  \n |      .. versionchanged:: 1.4\n |         Default value for `n_init` will change from 10 to `'auto'` in version 1.4.\n |  \n |  max_iter : int, default=300\n |      Maximum number of iterations of the k-means algorithm for a\n |      single run.\n |  \n |  tol : float, default=1e-4\n |      Relative tolerance with regards to Frobenius norm of the difference\n |      in the cluster centers of two consecutive iterations to declare\n |      convergence.\n |  \n |  verbose : int, default=0\n |      Verbosity mode.\n |  \n |  random_state : int, RandomState instance or None, default=None\n |      Determines random number generation for centroid initialization. Use\n |      an int to make the randomness deterministic.\n |      See :term:`Glossary <random_state>`.\n |  \n |  copy_x : bool, default=True\n |      When pre-computing distances it is more numerically accurate to center\n |      the data first. If copy_x is True (default), then the original data is\n |      not modified. If False, the original data is modified, and put back\n |      before the function returns, but small numerical differences may be\n |      introduced by subtracting and then adding the data mean. Note that if\n |      the original data is not C-contiguous, a copy will be made even if\n |      copy_x is False. If the original data is sparse, but not in CSR format,\n |      a copy will be made even if copy_x is False.\n |  \n |  algorithm : {\"lloyd\", \"elkan\", \"auto\", \"full\"}, default=\"lloyd\"\n |      K-means algorithm to use. The classical EM-style algorithm is `\"lloyd\"`.\n |      The `\"elkan\"` variation can be more efficient on some datasets with\n |      well-defined clusters, by using the triangle inequality. However it's\n |      more memory intensive due to the allocation of an extra array of shape\n |      `(n_samples, n_clusters)`.\n |  \n |      `\"auto\"` and `\"full\"` are deprecated and they will be removed in\n |      Scikit-Learn 1.3. They are both aliases for `\"lloyd\"`.\n |  \n |      .. versionchanged:: 0.18\n |          Added Elkan algorithm\n |  \n |      .. versionchanged:: 1.1\n |          Renamed \"full\" to \"lloyd\", and deprecated \"auto\" and \"full\".\n |          Changed \"auto\" to use \"lloyd\" instead of \"elkan\".\n |  \n |  Attributes\n |  ----------\n |  cluster_centers_ : ndarray of shape (n_clusters, n_features)\n |      Coordinates of cluster centers. If the algorithm stops before fully\n |      converging (see ``tol`` and ``max_iter``), these will not be\n |      consistent with ``labels_``.\n |  \n |  labels_ : ndarray of shape (n_samples,)\n |      Labels of each point\n |  \n |  inertia_ : float\n |      Sum of squared distances of samples to their closest cluster center,\n |      weighted by the sample weights if provided.\n |  \n |  n_iter_ : int\n |      Number of iterations run.\n |  \n |  n_features_in_ : int\n |      Number of features seen during :term:`fit`.\n |  \n |      .. versionadded:: 0.24\n |  \n |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n |      Names of features seen during :term:`fit`. Defined only when `X`\n |      has feature names that are all strings.\n |  \n |      .. versionadded:: 1.0\n |  \n |  See Also\n |  --------\n |  MiniBatchKMeans : Alternative online implementation that does incremental\n |      updates of the centers positions using mini-batches.\n |      For large scale learning (say n_samples > 10k) MiniBatchKMeans is\n |      probably much faster than the default batch implementation.\n |  \n |  Notes\n |  -----\n |  The k-means problem is solved using either Lloyd's or Elkan's algorithm.\n |  \n |  The average complexity is given by O(k n T), where n is the number of\n |  samples and T is the number of iteration.\n |  \n |  The worst case complexity is given by O(n^(k+2/p)) with\n |  n = n_samples, p = n_features.\n |  Refer to :doi:`\"How slow is the k-means method?\" D. Arthur and S. Vassilvitskii -\n |  SoCG2006.<10.1145/1137856.1137880>` for more details.\n |  \n |  In practice, the k-means algorithm is very fast (one of the fastest\n |  clustering algorithms available), but it falls in local minima. That's why\n |  it can be useful to restart it several times.\n |  \n |  If the algorithm stops before fully converging (because of ``tol`` or\n |  ``max_iter``), ``labels_`` and ``cluster_centers_`` will not be consistent,\n |  i.e. the ``cluster_centers_`` will not be the means of the points in each\n |  cluster. Also, the estimator will reassign ``labels_`` after the last\n |  iteration to make ``labels_`` consistent with ``predict`` on the training\n |  set.\n |  \n |  Examples\n |  --------\n |  \n |  >>> from sklearn.cluster import KMeans\n |  >>> import numpy as np\n |  >>> X = np.array([[1, 2], [1, 4], [1, 0],\n |  ...               [10, 2], [10, 4], [10, 0]])\n |  >>> kmeans = KMeans(n_clusters=2, random_state=0, n_init=\"auto\").fit(X)\n |  >>> kmeans.labels_\n |  array([1, 1, 1, 0, 0, 0], dtype=int32)\n |  >>> kmeans.predict([[0, 0], [12, 3]])\n |  array([1, 0], dtype=int32)\n |  >>> kmeans.cluster_centers_\n |  array([[10.,  2.],\n |         [ 1.,  2.]])\n |  \n |  Method resolution order:\n |      KMeans\n |      _BaseKMeans\n |      sklearn.base.ClassNamePrefixFeaturesOutMixin\n |      sklearn.base.TransformerMixin\n |      sklearn.utils._set_output._SetOutputMixin\n |      sklearn.base.ClusterMixin\n |      sklearn.base.BaseEstimator\n |      abc.ABC\n |      builtins.object\n |  \n |  Methods defined here:\n |  \n |  __init__(self, n_clusters=8, *, init='k-means++', n_init='warn', max_iter=300, tol=0.0001, verbose=0, random_state=None, copy_x=True, algorithm='lloyd')\n |      Initialize self.  See help(type(self)) for accurate signature.\n |  \n |  fit(self, X, y=None, sample_weight=None)\n |      Compute k-means clustering.\n |      \n |      Parameters\n |      ----------\n |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n |          Training instances to cluster. It must be noted that the data\n |          will be converted to C ordering, which will cause a memory\n |          copy if the given data is not C-contiguous.\n |          If a sparse matrix is passed, a copy will be made if it's not in\n |          CSR format.\n |      \n |      y : Ignored\n |          Not used, present here for API consistency by convention.\n |      \n |      sample_weight : array-like of shape (n_samples,), default=None\n |          The weights for each observation in X. If None, all observations\n |          are assigned equal weight.\n |      \n |          .. versionadded:: 0.20\n |      \n |      Returns\n |      -------\n |      self : object\n |          Fitted estimator.\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes defined here:\n |  \n |  __abstractmethods__ = frozenset()\n |  \n |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from _BaseKMeans:\n |  \n |  fit_predict(self, X, y=None, sample_weight=None)\n |      Compute cluster centers and predict cluster index for each sample.\n |      \n |      Convenience method; equivalent to calling fit(X) followed by\n |      predict(X).\n |      \n |      Parameters\n |      ----------\n |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n |          New data to transform.\n |      \n |      y : Ignored\n |          Not used, present here for API consistency by convention.\n |      \n |      sample_weight : array-like of shape (n_samples,), default=None\n |          The weights for each observation in X. If None, all observations\n |          are assigned equal weight.\n |      \n |      Returns\n |      -------\n |      labels : ndarray of shape (n_samples,)\n |          Index of the cluster each sample belongs to.\n |  \n |  fit_transform(self, X, y=None, sample_weight=None)\n |      Compute clustering and transform X to cluster-distance space.\n |      \n |      Equivalent to fit(X).transform(X), but more efficiently implemented.\n |      \n |      Parameters\n |      ----------\n |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n |          New data to transform.\n |      \n |      y : Ignored\n |          Not used, present here for API consistency by convention.\n |      \n |      sample_weight : array-like of shape (n_samples,), default=None\n |          The weights for each observation in X. If None, all observations\n |          are assigned equal weight.\n |      \n |      Returns\n |      -------\n |      X_new : ndarray of shape (n_samples, n_clusters)\n |          X transformed in the new space.\n |  \n |  predict(self, X, sample_weight=None)\n |      Predict the closest cluster each sample in X belongs to.\n |      \n |      In the vector quantization literature, `cluster_centers_` is called\n |      the code book and each value returned by `predict` is the index of\n |      the closest code in the code book.\n |      \n |      Parameters\n |      ----------\n |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n |          New data to predict.\n |      \n |      sample_weight : array-like of shape (n_samples,), default=None\n |          The weights for each observation in X. If None, all observations\n |          are assigned equal weight.\n |      \n |      Returns\n |      -------\n |      labels : ndarray of shape (n_samples,)\n |          Index of the cluster each sample belongs to.\n |  \n |  score(self, X, y=None, sample_weight=None)\n |      Opposite of the value of X on the K-means objective.\n |      \n |      Parameters\n |      ----------\n |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n |          New data.\n |      \n |      y : Ignored\n |          Not used, present here for API consistency by convention.\n |      \n |      sample_weight : array-like of shape (n_samples,), default=None\n |          The weights for each observation in X. If None, all observations\n |          are assigned equal weight.\n |      \n |      Returns\n |      -------\n |      score : float\n |          Opposite of the value of X on the K-means objective.\n |  \n |  transform(self, X)\n |      Transform X to a cluster-distance space.\n |      \n |      In the new space, each dimension is the distance to the cluster\n |      centers. Note that even if X is sparse, the array returned by\n |      `transform` will typically be dense.\n |      \n |      Parameters\n |      ----------\n |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n |          New data to transform.\n |      \n |      Returns\n |      -------\n |      X_new : ndarray of shape (n_samples, n_clusters)\n |          X transformed in the new space.\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from sklearn.base.ClassNamePrefixFeaturesOutMixin:\n |  \n |  get_feature_names_out(self, input_features=None)\n |      Get output feature names for transformation.\n |      \n |      The feature names out will prefixed by the lowercased class name. For\n |      example, if the transformer outputs 3 features, then the feature names\n |      out are: `[\"class_name0\", \"class_name1\", \"class_name2\"]`.\n |      \n |      Parameters\n |      ----------\n |      input_features : array-like of str or None, default=None\n |          Only used to validate feature names with the names seen in :meth:`fit`.\n |      \n |      Returns\n |      -------\n |      feature_names_out : ndarray of str objects\n |          Transformed feature names.\n |  \n |  ----------------------------------------------------------------------\n |  Data descriptors inherited from sklearn.base.ClassNamePrefixFeaturesOutMixin:\n |  \n |  __dict__\n |      dictionary for instance variables (if defined)\n |  \n |  __weakref__\n |      list of weak references to the object (if defined)\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from sklearn.utils._set_output._SetOutputMixin:\n |  \n |  set_output(self, *, transform=None)\n |      Set output container.\n |      \n |      See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`\n |      for an example on how to use the API.\n |      \n |      Parameters\n |      ----------\n |      transform : {\"default\", \"pandas\"}, default=None\n |          Configure output of `transform` and `fit_transform`.\n |      \n |          - `\"default\"`: Default output format of a transformer\n |          - `\"pandas\"`: DataFrame output\n |          - `None`: Transform configuration is unchanged\n |      \n |      Returns\n |      -------\n |      self : estimator instance\n |          Estimator instance.\n |  \n |  ----------------------------------------------------------------------\n |  Class methods inherited from sklearn.utils._set_output._SetOutputMixin:\n |  \n |  __init_subclass__(auto_wrap_output_keys=('transform',), **kwargs) from abc.ABCMeta\n |      This method is called when a class is subclassed.\n |      \n |      The default implementation does nothing. It may be\n |      overridden to extend subclasses.\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from sklearn.base.BaseEstimator:\n |  \n |  __getstate__(self)\n |  \n |  __repr__(self, N_CHAR_MAX=700)\n |      Return repr(self).\n |  \n |  __setstate__(self, state)\n |  \n |  get_params(self, deep=True)\n |      Get parameters for this estimator.\n |      \n |      Parameters\n |      ----------\n |      deep : bool, default=True\n |          If True, will return the parameters for this estimator and\n |          contained subobjects that are estimators.\n |      \n |      Returns\n |      -------\n |      params : dict\n |          Parameter names mapped to their values.\n |  \n |  set_params(self, **params)\n |      Set the parameters of this estimator.\n |      \n |      The method works on simple estimators as well as on nested objects\n |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n |      parameters of the form ``<component>__<parameter>`` so that it's\n |      possible to update each component of a nested object.\n |      \n |      Parameters\n |      ----------\n |      **params : dict\n |          Estimator parameters.\n |      \n |      Returns\n |      -------\n |      self : estimator instance\n |          Estimator instance.\n\n\n\n\nfrom sklearn.cluster import KMeans\nwcss = []\nfor i in range(1, 11):\n    kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 42)\n    kmeans.fit(X)\n    wcss.append(kmeans.inertia_)\nplt.plot(range(1, 11), wcss)\nplt.title('The Elbow Method')\nplt.xlabel('Number of clusters')\nplt.ylabel('WCSS')\nplt.show()\n\n\n\n\n\nwcss\n\n[269981.28,\n 181363.59595959593,\n 106348.37306211122,\n 73679.78903948836,\n 44448.4554479337,\n 37233.814510710006,\n 30259.65720728547,\n 25011.839349156588,\n 21862.092672182895,\n 19672.072849014323]\n\n\nWithin-Cluster Sum-of-Squares criterion:\n\\(\\sum_{i=0}^{n}\\min_{\\mu_j \\in C}(||x_i - \\mu_j||^2)\\)\nsource:\n[1] https://scikit-learn.org/stable/modules/clustering.html#k-means\n[2] https://stats.stackexchange.com/questions/158210/k-means-why-minimizing-wcss-is-maximizing-distance-between-clusters\n\n\n\nNilai Silhouette mengukur seberapa mirip sebuah titik dengan klasternya sendiri (kohesi) dibandingkan dengan klaster lain (pemisahan).\nKisaran nilai Silhouette adalah antara +1 dan -1. Nilai yang tinggi diinginkan dan mengindikasikan bahwa titik tersebut ditempatkan pada klaster yang benar. Jika banyak titik yang memiliki nilai Silhouette negatif, hal ini dapat mengindikasikan bahwa kita telah membuat terlalu banyak atau terlalu sedikit cluster.\n\n\n\n\nimage.png\n\n\n\n\n\nimage.png\n\n\nsource: https://medium.com/analytics-vidhya/how-to-determine-the-optimal-k-for-k-means-708505d204eb\n\nimport sklearn.metrics as metrics\nfor i in range(2,11):\n  labels=KMeans(n_clusters=i,random_state=200).fit(X).labels_\n  print (\"Silhouette score for k(clusters) = \"+str(i)+\" is \"+str(metrics.silhouette_score(X,labels,metric=\"euclidean\",sample_size=1000,random_state=200)))\n\nSilhouette score for k(clusters) = 2 is 0.2968969162503008\nSilhouette score for k(clusters) = 3 is 0.46761358158775423\nSilhouette score for k(clusters) = 4 is 0.4931963109249047\nSilhouette score for k(clusters) = 5 is 0.553931997444648\nSilhouette score for k(clusters) = 6 is 0.5379675585622219\nSilhouette score for k(clusters) = 7 is 0.5367379891273258\nSilhouette score for k(clusters) = 8 is 0.4592958445675391\nSilhouette score for k(clusters) = 9 is 0.45770857148861777\nSilhouette score for k(clusters) = 10 is 0.446735677440187\n\n\n\n\n\n\nkmeans = KMeans(n_clusters = 5, init = 'k-means++', random_state = 42)\ny_kmeans = kmeans.fit_predict(X)\n\n\n\n\n\nplt.scatter(X[y_kmeans == 0, 0], X[y_kmeans == 0, 1], s = 100, c = 'red', label = 'Cluster 1')\nplt.scatter(X[y_kmeans == 1, 0], X[y_kmeans == 1, 1], s = 100, c = 'blue', label = 'Cluster 2')\nplt.scatter(X[y_kmeans == 2, 0], X[y_kmeans == 2, 1], s = 100, c = 'green', label = 'Cluster 3')\nplt.scatter(X[y_kmeans == 3, 0], X[y_kmeans == 3, 1], s = 100, c = 'cyan', label = 'Cluster 4')\nplt.scatter(X[y_kmeans == 4, 0], X[y_kmeans == 4, 1], s = 100, c = 'magenta', label = 'Cluster 5')\nplt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s = 300, c = 'yellow', label = 'Centroids')\nplt.title('Clusters of customers')\nplt.xlabel('Annual Income (k$)')\nplt.ylabel('Spending Score (1-100)')\nplt.legend()\nplt.show()\n\n\n\n\n\nkmeans.cluster_centers_\n\narray([[55.2962963 , 49.51851852],\n       [88.2       , 17.11428571],\n       [26.30434783, 20.91304348],\n       [25.72727273, 79.36363636],\n       [86.53846154, 82.12820513]])\n\n\n\nkmeans.labels_\n\narray([2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3,\n       2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 0,\n       2, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 1, 4, 0, 4, 1, 4, 1, 4,\n       0, 4, 1, 4, 1, 4, 1, 4, 1, 4, 0, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4,\n       1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4,\n       1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4,\n       1, 4], dtype=int32)\n\n\n\n\n\n\n\n\n\nimport scipy.cluster.hierarchy as sch\ndendrogram = sch.dendrogram(sch.linkage(X, method = 'ward'))\nplt.title('Dendrogram')\nplt.xlabel('Customers')\nplt.ylabel('Euclidean distances')\nplt.show()\n\n\n\n\n\nhelp(sch.linkage)\n\nHelp on function linkage in module scipy.cluster.hierarchy:\n\nlinkage(y, method='single', metric='euclidean', optimal_ordering=False)\n    Perform hierarchical/agglomerative clustering.\n    \n    The input y may be either a 1-D condensed distance matrix\n    or a 2-D array of observation vectors.\n    \n    If y is a 1-D condensed distance matrix,\n    then y must be a :math:`\\binom{n}{2}` sized\n    vector, where n is the number of original observations paired\n    in the distance matrix. The behavior of this function is very\n    similar to the MATLAB linkage function.\n    \n    A :math:`(n-1)` by 4 matrix ``Z`` is returned. At the\n    :math:`i`-th iteration, clusters with indices ``Z[i, 0]`` and\n    ``Z[i, 1]`` are combined to form cluster :math:`n + i`. A\n    cluster with an index less than :math:`n` corresponds to one of\n    the :math:`n` original observations. The distance between\n    clusters ``Z[i, 0]`` and ``Z[i, 1]`` is given by ``Z[i, 2]``. The\n    fourth value ``Z[i, 3]`` represents the number of original\n    observations in the newly formed cluster.\n    \n    The following linkage methods are used to compute the distance\n    :math:`d(s, t)` between two clusters :math:`s` and\n    :math:`t`. The algorithm begins with a forest of clusters that\n    have yet to be used in the hierarchy being formed. When two\n    clusters :math:`s` and :math:`t` from this forest are combined\n    into a single cluster :math:`u`, :math:`s` and :math:`t` are\n    removed from the forest, and :math:`u` is added to the\n    forest. When only one cluster remains in the forest, the algorithm\n    stops, and this cluster becomes the root.\n    \n    A distance matrix is maintained at each iteration. The ``d[i,j]``\n    entry corresponds to the distance between cluster :math:`i` and\n    :math:`j` in the original forest.\n    \n    At each iteration, the algorithm must update the distance matrix\n    to reflect the distance of the newly formed cluster u with the\n    remaining clusters in the forest.\n    \n    Suppose there are :math:`|u|` original observations\n    :math:`u[0], \\ldots, u[|u|-1]` in cluster :math:`u` and\n    :math:`|v|` original objects :math:`v[0], \\ldots, v[|v|-1]` in\n    cluster :math:`v`. Recall, :math:`s` and :math:`t` are\n    combined to form cluster :math:`u`. Let :math:`v` be any\n    remaining cluster in the forest that is not :math:`u`.\n    \n    The following are methods for calculating the distance between the\n    newly formed cluster :math:`u` and each :math:`v`.\n    \n      * method='single' assigns\n    \n        .. math::\n           d(u,v) = \\min(dist(u[i],v[j]))\n    \n        for all points :math:`i` in cluster :math:`u` and\n        :math:`j` in cluster :math:`v`. This is also known as the\n        Nearest Point Algorithm.\n    \n      * method='complete' assigns\n    \n        .. math::\n           d(u, v) = \\max(dist(u[i],v[j]))\n    \n        for all points :math:`i` in cluster u and :math:`j` in\n        cluster :math:`v`. This is also known by the Farthest Point\n        Algorithm or Voor Hees Algorithm.\n    \n      * method='average' assigns\n    \n        .. math::\n           d(u,v) = \\sum_{ij} \\frac{d(u[i], v[j])}\n                                   {(|u|*|v|)}\n    \n        for all points :math:`i` and :math:`j` where :math:`|u|`\n        and :math:`|v|` are the cardinalities of clusters :math:`u`\n        and :math:`v`, respectively. This is also called the UPGMA\n        algorithm.\n    \n      * method='weighted' assigns\n    \n        .. math::\n           d(u,v) = (dist(s,v) + dist(t,v))/2\n    \n        where cluster u was formed with cluster s and t and v\n        is a remaining cluster in the forest (also called WPGMA).\n    \n      * method='centroid' assigns\n    \n        .. math::\n           dist(s,t) = ||c_s-c_t||_2\n    \n        where :math:`c_s` and :math:`c_t` are the centroids of\n        clusters :math:`s` and :math:`t`, respectively. When two\n        clusters :math:`s` and :math:`t` are combined into a new\n        cluster :math:`u`, the new centroid is computed over all the\n        original objects in clusters :math:`s` and :math:`t`. The\n        distance then becomes the Euclidean distance between the\n        centroid of :math:`u` and the centroid of a remaining cluster\n        :math:`v` in the forest. This is also known as the UPGMC\n        algorithm.\n    \n      * method='median' assigns :math:`d(s,t)` like the ``centroid``\n        method. When two clusters :math:`s` and :math:`t` are combined\n        into a new cluster :math:`u`, the average of centroids s and t\n        give the new centroid :math:`u`. This is also known as the\n        WPGMC algorithm.\n    \n      * method='ward' uses the Ward variance minimization algorithm.\n        The new entry :math:`d(u,v)` is computed as follows,\n    \n        .. math::\n    \n           d(u,v) = \\sqrt{\\frac{|v|+|s|}\n                               {T}d(v,s)^2\n                        + \\frac{|v|+|t|}\n                               {T}d(v,t)^2\n                        - \\frac{|v|}\n                               {T}d(s,t)^2}\n    \n        where :math:`u` is the newly joined cluster consisting of\n        clusters :math:`s` and :math:`t`, :math:`v` is an unused\n        cluster in the forest, :math:`T=|v|+|s|+|t|`, and\n        :math:`|*|` is the cardinality of its argument. This is also\n        known as the incremental algorithm.\n    \n    Warning: When the minimum distance pair in the forest is chosen, there\n    may be two or more pairs with the same minimum distance. This\n    implementation may choose a different minimum than the MATLAB\n    version.\n    \n    Parameters\n    ----------\n    y : ndarray\n        A condensed distance matrix. A condensed distance matrix\n        is a flat array containing the upper triangular of the distance matrix.\n        This is the form that ``pdist`` returns. Alternatively, a collection of\n        :math:`m` observation vectors in :math:`n` dimensions may be passed as\n        an :math:`m` by :math:`n` array. All elements of the condensed distance\n        matrix must be finite, i.e., no NaNs or infs.\n    method : str, optional\n        The linkage algorithm to use. See the ``Linkage Methods`` section below\n        for full descriptions.\n    metric : str or function, optional\n        The distance metric to use in the case that y is a collection of\n        observation vectors; ignored otherwise. See the ``pdist``\n        function for a list of valid distance metrics. A custom distance\n        function can also be used.\n    optimal_ordering : bool, optional\n        If True, the linkage matrix will be reordered so that the distance\n        between successive leaves is minimal. This results in a more intuitive\n        tree structure when the data are visualized. defaults to False, because\n        this algorithm can be slow, particularly on large datasets [2]_. See\n        also the `optimal_leaf_ordering` function.\n    \n        .. versionadded:: 1.0.0\n    \n    Returns\n    -------\n    Z : ndarray\n        The hierarchical clustering encoded as a linkage matrix.\n    \n    Notes\n    -----\n    1. For method 'single', an optimized algorithm based on minimum spanning\n       tree is implemented. It has time complexity :math:`O(n^2)`.\n       For methods 'complete', 'average', 'weighted' and 'ward', an algorithm\n       called nearest-neighbors chain is implemented. It also has time\n       complexity :math:`O(n^2)`.\n       For other methods, a naive algorithm is implemented with :math:`O(n^3)`\n       time complexity.\n       All algorithms use :math:`O(n^2)` memory.\n       Refer to [1]_ for details about the algorithms.\n    2. Methods 'centroid', 'median', and 'ward' are correctly defined only if\n       Euclidean pairwise metric is used. If `y` is passed as precomputed\n       pairwise distances, then it is the user's responsibility to assure that\n       these distances are in fact Euclidean, otherwise the produced result\n       will be incorrect.\n    \n    See Also\n    --------\n    scipy.spatial.distance.pdist : pairwise distance metrics\n    \n    References\n    ----------\n    .. [1] Daniel Mullner, \"Modern hierarchical, agglomerative clustering\n           algorithms\", :arXiv:`1109.2378v1`.\n    .. [2] Ziv Bar-Joseph, David K. Gifford, Tommi S. Jaakkola, \"Fast optimal\n           leaf ordering for hierarchical clustering\", 2001. Bioinformatics\n           :doi:`10.1093/bioinformatics/17.suppl_1.S22`\n    \n    Examples\n    --------\n    >>> from scipy.cluster.hierarchy import dendrogram, linkage\n    >>> from matplotlib import pyplot as plt\n    >>> X = [[i] for i in [2, 8, 0, 4, 1, 9, 9, 0]]\n    \n    >>> Z = linkage(X, 'ward')\n    >>> fig = plt.figure(figsize=(25, 10))\n    >>> dn = dendrogram(Z)\n    \n    >>> Z = linkage(X, 'single')\n    >>> fig = plt.figure(figsize=(25, 10))\n    >>> dn = dendrogram(Z)\n    >>> plt.show()\n\n\n\n\n\n\nHierarchical clustering adalah keluarga umum dari algoritma clustering yang membangun cluster bersarang dengan menggabungkan atau memisahkannya secara berurutan. Hirarki cluster ini direpresentasikan sebagai sebuah pohon (atau dendogram). Akar dari pohon adalah cluster unik yang mengumpulkan semua sampel, sedangkan daunnya adalah cluster yang hanya memiliki satu sampel.\nObjek AgglomerativeClustering melakukan pengelompokan hirarkis menggunakan pendekatan dari bawah ke atas: setiap pengamatan dimulai dari klasternya sendiri, dan klaster-klaster tersebut digabungkan secara berurutan. Kriteria keterkaitan menentukan metrik yang digunakan untuk strategi penggabungan:\n\nWard meminimalkan jumlah perbedaan kuadrat di dalam semua cluster. Ini adalah pendekatan yang meminimalkan varians dan dalam hal ini mirip dengan fungsi objektif k-means tetapi ditangani dengan pendekatan hirarki aglomeratif.\nMaximum atau complete linkage meminimalkan jarak maksimum antara pengamatan dari pasangan cluster.\nAverage linkage meminimalkan rata-rata jarak antara semua pengamatan dari pasangan cluster.\nSingle linkage meminimalkan jarak antara pengamatan terdekat dari pasangan cluster.\n\nAgglomerativeClustering juga dapat menskalakan ke sejumlah besar sampel ketika digunakan bersama dengan matriks konektivitas, tetapi secara komputasi mahal ketika tidak ada batasan konektivitas yang ditambahkan di antara sampel: ia mempertimbangkan pada setiap langkah semua kemungkinan penggabungan.\nsource : https://scikit-learn.org/stable/modules/clustering.html#hierarchical-clustering\n\nfrom sklearn.cluster import AgglomerativeClustering\nhc = AgglomerativeClustering(n_clusters = 5, affinity = 'euclidean', linkage = 'ward')\ny_hc = hc.fit_predict(X)\n\n\n\n\n\nplt.scatter(X[y_hc == 0, 0], X[y_hc == 0, 1], s = 100, c = 'red', label = 'Cluster 1')\nplt.scatter(X[y_hc == 1, 0], X[y_hc == 1, 1], s = 100, c = 'blue', label = 'Cluster 2')\nplt.scatter(X[y_hc == 2, 0], X[y_hc == 2, 1], s = 100, c = 'green', label = 'Cluster 3')\nplt.scatter(X[y_hc == 3, 0], X[y_hc == 3, 1], s = 100, c = 'cyan', label = 'Cluster 4')\nplt.scatter(X[y_hc == 4, 0], X[y_hc == 4, 1], s = 100, c = 'magenta', label = 'Cluster 5')\nplt.title('Clusters of customers')\nplt.xlabel('Annual Income (k$)')\nplt.ylabel('Spending Score (1-100)')\nplt.legend()\nplt.show()"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-06.html",
    "href": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-06.html",
    "title": "Lab Praktikum Departemen Matematika FMIPA UI",
    "section": "",
    "text": "Kembali ke Sains Data\nPada modul kali ini kita akan mempelajari lebih lanjut implementasi Neural Network menggunakan Keras API serta cara melakukan hyperparameter tuning menggunakan library Keras-Tuner.\nPenjelasan modul serta code pada modul ini akan dibahas lengkap pada sesi praktikum. Penjelasan pada notebook ini hanyalah ringkasan singkat.\n\n\n\n!pip install keras-tuner\nimport tensorflow as tf\nimport keras_tuner as kt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.datasets import fetch_california_housing\nimport matplotlib.pyplot as plt\n\nLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\nCollecting keras-tuner\n  Downloading keras_tuner-1.3.5-py3-none-any.whl (176 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 176.1/176.1 kB 7.5 MB/s eta 0:00:00\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (23.1)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.27.1)\nCollecting kt-legacy\n  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.4)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.12)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2022.12.7)\nInstalling collected packages: kt-legacy, keras-tuner\nSuccessfully installed keras-tuner-1.3.5 kt-legacy-1.0.5\n\n\n\n\n\nKeras memiliki tiga macam API yang dapat digunakan, yaitu Sequential, Functional, dan Subclassing. Ketiganya memiliki kelebihan dan kekurangan masing-masing, terutama di sisi kemudahan dan fleksibilitas.\nSequential API merupakan API yang sangat mudah dipahami bagi semua orang yang ingin mempelajari deep learning, tetapi Sequential tidak cukup fleksibel dalam membuat arsitektur model tingkat lanjut karena sifatnya yang mengharuskan tiap layer terhubung satu sama lain dari input hingga output.\nFunctional API merupakan API yang juga cukup mudah dipahami (sedikit lebih kompleks dibandingkan Sequential), tetapi cukup fleksibel dalam mengimplementasikan beragam arsitektur model.\nSubclassing API merupakan API yang cukup sulit dipahami bagi orang yang baru ingin mempelajari deep learning, tetapi di sisi lain API ini merupakan API terfleksibel pada Keras.\nPada modul ini, hanya akan dibahas Sequential dan Functional API.\nPertama, kita akan membuat dua macam model untuk mengklasifikasikan gambar fashion (computer vision). Pertama, kita akan membuat model ANN yang cukup simple, kemudian kita coba model CNN untuk meningkatkan akurasi.\n\n\nhttps://keras.io/api/datasets/fashion_mnist/\n\nfashion_mnist = tf.keras.datasets.fashion_mnist\n(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n\n\nprint(f'X_train_full shape: {X_train_full.shape}')\nprint(f'y_train_full shape: {y_train_full.shape}')\nprint(f'X_test shape: {X_test.shape}')\nprint(f'y_test shape: {y_test.shape}')\n\nX_train_full shape: (60000, 28, 28)\ny_train_full shape: (60000,)\nX_test shape: (10000, 28, 28)\ny_test shape: (10000,)\n\n\n\nX_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, \n                                                  test_size=1/6, \n                                                  random_state=42)\n\nprint(f'X_train shape: {X_train.shape}')\nprint(f'y_train shape: {y_train.shape}')\nprint(f'X_val shape: {X_val.shape}')\nprint(f'y_val shape: {y_val.shape}')\nprint(f'X_test shape: {X_test.shape}')\nprint(f'y_test shape: {y_test.shape}')\n\nX_train shape: (50000, 28, 28)\ny_train shape: (50000,)\nX_val shape: (10000, 28, 28)\ny_val shape: (10000,)\nX_test shape: (10000, 28, 28)\ny_test shape: (10000,)\n\n\n\nX_train = X_train / 255\nX_val = X_val / 255\nX_test = X_test / 255\n\n\nclass_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n\n\n#@title Slider to look for some image examples {run: \"auto\"}\nidx = 21402 #@param {type:\"slider\", min:0, max:49999, step:1}\n\nplt.imshow(X_train[idx], cmap='gray')\nplt.title(class_names[y_train[idx]])\nplt.axis('OFF')\nplt.show()\n\n\n\n\n\n\n\n\n\n\nmodel_ann_class = tf.keras.Sequential([\n    tf.keras.layers.Flatten(input_shape=(28,28)),\n    tf.keras.layers.Dense(100, activation='relu'),\n    tf.keras.layers.Dense(50, activation='relu'),\n    tf.keras.layers.Dense(10, activation='softmax')\n])\n\nopt = tf.keras.optimizers.Adam(learning_rate=1e-3)\nmodel_ann_class.compile(optimizer=opt, loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\nmodel_ann_class.summary()\n\nModel: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n flatten (Flatten)           (None, 784)               0         \n                                                                 \n dense (Dense)               (None, 100)               78500     \n                                                                 \n dense_1 (Dense)             (None, 50)                5050      \n                                                                 \n dense_2 (Dense)             (None, 10)                510       \n                                                                 \n=================================================================\nTotal params: 84,060\nTrainable params: 84,060\nNon-trainable params: 0\n_________________________________________________________________\n\n\n\ninit_ann_class_weights = model_ann_class.get_weights()\n\n\nprint(type(init_ann_class_weights))\nprint(len(init_ann_class_weights))\nprint(f'First dense w: {init_ann_class_weights[0].shape}')\nprint(f'First dense b: {init_ann_class_weights[1].shape}')\nprint(f'Second dense w: {init_ann_class_weights[2].shape}')\nprint(f'Second dense b: {init_ann_class_weights[3].shape}')\nprint(f'Last dense w: {init_ann_class_weights[4].shape}')\nprint(f'Last dense b: {init_ann_class_weights[5].shape}')\n\n<class 'list'>\n6\nFirst dense w: (784, 100)\nFirst dense b: (100,)\nSecond dense w: (100, 50)\nSecond dense b: (50,)\nLast dense w: (50, 10)\nLast dense b: (10,)\n\n\n\nhistory_ann_class = model_ann_class.fit(X_train, y_train, \n                                        validation_data=(X_val, y_val),\n                                        epochs=50, batch_size=256)\n\nEpoch 1/50\n196/196 [==============================] - 2s 9ms/step - loss: 0.6681 - accuracy: 0.7688 - val_loss: 0.4915 - val_accuracy: 0.8307\nEpoch 2/50\n196/196 [==============================] - 2s 11ms/step - loss: 0.4334 - accuracy: 0.8471 - val_loss: 0.4150 - val_accuracy: 0.8491\nEpoch 3/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.3873 - accuracy: 0.8635 - val_loss: 0.4204 - val_accuracy: 0.8503\nEpoch 4/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.3637 - accuracy: 0.8700 - val_loss: 0.3839 - val_accuracy: 0.8600\nEpoch 5/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.3422 - accuracy: 0.8768 - val_loss: 0.3612 - val_accuracy: 0.8720\nEpoch 6/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.3275 - accuracy: 0.8805 - val_loss: 0.3525 - val_accuracy: 0.8732\nEpoch 7/50\n196/196 [==============================] - 1s 8ms/step - loss: 0.3116 - accuracy: 0.8868 - val_loss: 0.3400 - val_accuracy: 0.8747\nEpoch 8/50\n196/196 [==============================] - 1s 8ms/step - loss: 0.2974 - accuracy: 0.8914 - val_loss: 0.3488 - val_accuracy: 0.8734\nEpoch 9/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.2889 - accuracy: 0.8946 - val_loss: 0.3463 - val_accuracy: 0.8732\nEpoch 10/50\n196/196 [==============================] - 2s 11ms/step - loss: 0.2777 - accuracy: 0.8982 - val_loss: 0.3333 - val_accuracy: 0.8806\nEpoch 11/50\n196/196 [==============================] - 2s 9ms/step - loss: 0.2688 - accuracy: 0.9019 - val_loss: 0.3402 - val_accuracy: 0.8796\nEpoch 12/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.2641 - accuracy: 0.9022 - val_loss: 0.3277 - val_accuracy: 0.8807\nEpoch 13/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.2556 - accuracy: 0.9067 - val_loss: 0.3177 - val_accuracy: 0.8848\nEpoch 14/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.2491 - accuracy: 0.9085 - val_loss: 0.3287 - val_accuracy: 0.8802\nEpoch 15/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.2431 - accuracy: 0.9093 - val_loss: 0.3156 - val_accuracy: 0.8868\nEpoch 16/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.2358 - accuracy: 0.9119 - val_loss: 0.3266 - val_accuracy: 0.8816\nEpoch 17/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.2314 - accuracy: 0.9122 - val_loss: 0.3132 - val_accuracy: 0.8859\nEpoch 18/50\n196/196 [==============================] - 2s 8ms/step - loss: 0.2301 - accuracy: 0.9140 - val_loss: 0.3155 - val_accuracy: 0.8863\nEpoch 19/50\n196/196 [==============================] - 2s 11ms/step - loss: 0.2193 - accuracy: 0.9189 - val_loss: 0.3328 - val_accuracy: 0.8824\nEpoch 20/50\n196/196 [==============================] - 2s 8ms/step - loss: 0.2162 - accuracy: 0.9195 - val_loss: 0.3306 - val_accuracy: 0.8830\nEpoch 21/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.2128 - accuracy: 0.9209 - val_loss: 0.3230 - val_accuracy: 0.8834\nEpoch 22/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.2053 - accuracy: 0.9236 - val_loss: 0.3350 - val_accuracy: 0.8826\nEpoch 23/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.2038 - accuracy: 0.9250 - val_loss: 0.3202 - val_accuracy: 0.8862\nEpoch 24/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.1991 - accuracy: 0.9265 - val_loss: 0.3187 - val_accuracy: 0.8872\nEpoch 25/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.1948 - accuracy: 0.9294 - val_loss: 0.3424 - val_accuracy: 0.8823\nEpoch 26/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.1878 - accuracy: 0.9309 - val_loss: 0.3179 - val_accuracy: 0.8912\nEpoch 27/50\n196/196 [==============================] - 2s 9ms/step - loss: 0.1896 - accuracy: 0.9296 - val_loss: 0.3243 - val_accuracy: 0.8900\nEpoch 28/50\n196/196 [==============================] - 2s 11ms/step - loss: 0.1812 - accuracy: 0.9325 - val_loss: 0.3260 - val_accuracy: 0.8891\nEpoch 29/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.1805 - accuracy: 0.9327 - val_loss: 0.3389 - val_accuracy: 0.8868\nEpoch 30/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.1777 - accuracy: 0.9350 - val_loss: 0.3296 - val_accuracy: 0.8858\nEpoch 31/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.1716 - accuracy: 0.9368 - val_loss: 0.3398 - val_accuracy: 0.8887\nEpoch 32/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.1683 - accuracy: 0.9377 - val_loss: 0.3484 - val_accuracy: 0.8850\nEpoch 33/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.1690 - accuracy: 0.9381 - val_loss: 0.3416 - val_accuracy: 0.8880\nEpoch 34/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.1635 - accuracy: 0.9391 - val_loss: 0.3423 - val_accuracy: 0.8878\nEpoch 35/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.1596 - accuracy: 0.9404 - val_loss: 0.3524 - val_accuracy: 0.8859\nEpoch 36/50\n196/196 [==============================] - 2s 11ms/step - loss: 0.1566 - accuracy: 0.9432 - val_loss: 0.3687 - val_accuracy: 0.8840\nEpoch 37/50\n196/196 [==============================] - 2s 9ms/step - loss: 0.1561 - accuracy: 0.9420 - val_loss: 0.3525 - val_accuracy: 0.8852\nEpoch 38/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.1491 - accuracy: 0.9448 - val_loss: 0.3640 - val_accuracy: 0.8833\nEpoch 39/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.1494 - accuracy: 0.9449 - val_loss: 0.3761 - val_accuracy: 0.8867\nEpoch 40/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.1446 - accuracy: 0.9467 - val_loss: 0.3758 - val_accuracy: 0.8861\nEpoch 41/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.1411 - accuracy: 0.9481 - val_loss: 0.3604 - val_accuracy: 0.8886\nEpoch 42/50\n196/196 [==============================] - 2s 9ms/step - loss: 0.1388 - accuracy: 0.9485 - val_loss: 0.3790 - val_accuracy: 0.8840\nEpoch 43/50\n196/196 [==============================] - 2s 10ms/step - loss: 0.1399 - accuracy: 0.9479 - val_loss: 0.3736 - val_accuracy: 0.8903\nEpoch 44/50\n196/196 [==============================] - 3s 15ms/step - loss: 0.1316 - accuracy: 0.9503 - val_loss: 0.3778 - val_accuracy: 0.8874\nEpoch 45/50\n196/196 [==============================] - 3s 14ms/step - loss: 0.1304 - accuracy: 0.9515 - val_loss: 0.4043 - val_accuracy: 0.8816\nEpoch 46/50\n196/196 [==============================] - 2s 12ms/step - loss: 0.1283 - accuracy: 0.9528 - val_loss: 0.3941 - val_accuracy: 0.8846\nEpoch 47/50\n196/196 [==============================] - 2s 13ms/step - loss: 0.1280 - accuracy: 0.9525 - val_loss: 0.3956 - val_accuracy: 0.8851\nEpoch 48/50\n196/196 [==============================] - 2s 10ms/step - loss: 0.1231 - accuracy: 0.9551 - val_loss: 0.3878 - val_accuracy: 0.8890\nEpoch 49/50\n196/196 [==============================] - 2s 12ms/step - loss: 0.1206 - accuracy: 0.9560 - val_loss: 0.3860 - val_accuracy: 0.8901\nEpoch 50/50\n196/196 [==============================] - 3s 17ms/step - loss: 0.1195 - accuracy: 0.9563 - val_loss: 0.4013 - val_accuracy: 0.8872\n\n\n\nloss = history_ann_class.history['loss']\nval_loss = history_ann_class.history['val_loss']\naccuracy = history_ann_class.history['accuracy']\nval_accuracy = history_ann_class.history['val_accuracy']\nepochs = range(len(loss))\n\nfig, ax = plt.subplots(1, 2, figsize=(8,3))\nax[0].plot(epochs, loss)\nax[0].plot(epochs, val_loss)\nax[0].legend(['loss', 'val_loss'], loc='upper right')\nax[0].set_title('Train Loss vs Val Loss')\nax[1].plot(epochs, accuracy)\nax[1].plot(epochs, val_accuracy)\nax[1].legend(['accuracy', 'val_accuracy'], loc='lower right')\nax[1].set_title('Train Acc vs Val Acc')\nplt.show()\n\n\n\n\n\nmodel_ann_class.evaluate(X_val, y_val)\n\n313/313 [==============================] - 1s 4ms/step - loss: 0.4013 - accuracy: 0.8872\n\n\n[0.4012959599494934, 0.8871999979019165]\n\n\n\nmodel_ann_class.evaluate(X_test, y_test)\n\n313/313 [==============================] - 1s 4ms/step - loss: 0.4228 - accuracy: 0.8853\n\n\n[0.42284178733825684, 0.8852999806404114]\n\n\n\n\n\n\nmodel_ann_class.set_weights(init_ann_class_weights)\n\n\nmodel_ann_class.evaluate(X_val, y_val)\n\n313/313 [==============================] - 1s 2ms/step - loss: 2.4112 - accuracy: 0.0420\n\n\n[2.41121768951416, 0.041999999433755875]\n\n\n\nearly_stop = tf.keras.callbacks.EarlyStopping(patience=5, monitor='val_loss',\n                                              restore_best_weights=True,\n                                              verbose=1)\n\nhistory_ann_class = model_ann_class.fit(X_train, y_train, \n                                        validation_data=(X_val, y_val),\n                                        epochs=50, batch_size=256,\n                                        callbacks=[early_stop])\n\nEpoch 1/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.6287 - accuracy: 0.7787 - val_loss: 0.4691 - val_accuracy: 0.8378\nEpoch 2/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.4224 - accuracy: 0.8508 - val_loss: 0.4133 - val_accuracy: 0.8549\nEpoch 3/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.3808 - accuracy: 0.8663 - val_loss: 0.3827 - val_accuracy: 0.8651\nEpoch 4/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.3479 - accuracy: 0.8757 - val_loss: 0.3823 - val_accuracy: 0.8636\nEpoch 5/50\n196/196 [==============================] - 2s 9ms/step - loss: 0.3341 - accuracy: 0.8803 - val_loss: 0.3610 - val_accuracy: 0.8732\nEpoch 6/50\n196/196 [==============================] - 2s 11ms/step - loss: 0.3199 - accuracy: 0.8852 - val_loss: 0.3534 - val_accuracy: 0.8746\nEpoch 7/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.3079 - accuracy: 0.8888 - val_loss: 0.3383 - val_accuracy: 0.8785\nEpoch 8/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.2965 - accuracy: 0.8933 - val_loss: 0.3290 - val_accuracy: 0.8810\nEpoch 9/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.2862 - accuracy: 0.8964 - val_loss: 0.3333 - val_accuracy: 0.8800\nEpoch 10/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.2756 - accuracy: 0.9001 - val_loss: 0.3313 - val_accuracy: 0.8842\nEpoch 11/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.2686 - accuracy: 0.9023 - val_loss: 0.3282 - val_accuracy: 0.8787\nEpoch 12/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.2642 - accuracy: 0.9035 - val_loss: 0.3204 - val_accuracy: 0.8830\nEpoch 13/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.2615 - accuracy: 0.9050 - val_loss: 0.3247 - val_accuracy: 0.8814\nEpoch 14/50\n196/196 [==============================] - 2s 10ms/step - loss: 0.2525 - accuracy: 0.9069 - val_loss: 0.3182 - val_accuracy: 0.8874\nEpoch 15/50\n196/196 [==============================] - 2s 9ms/step - loss: 0.2407 - accuracy: 0.9117 - val_loss: 0.3150 - val_accuracy: 0.8872\nEpoch 16/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.2378 - accuracy: 0.9132 - val_loss: 0.3320 - val_accuracy: 0.8813\nEpoch 17/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.2334 - accuracy: 0.9138 - val_loss: 0.3242 - val_accuracy: 0.8843\nEpoch 18/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.2265 - accuracy: 0.9167 - val_loss: 0.3242 - val_accuracy: 0.8837\nEpoch 19/50\n196/196 [==============================] - 1s 7ms/step - loss: 0.2218 - accuracy: 0.9181 - val_loss: 0.3242 - val_accuracy: 0.8848\nEpoch 20/50\n196/196 [==============================] - ETA: 0s - loss: 0.2180 - accuracy: 0.9198Restoring model weights from the end of the best epoch: 15.\n196/196 [==============================] - 1s 7ms/step - loss: 0.2180 - accuracy: 0.9198 - val_loss: 0.3237 - val_accuracy: 0.8864\nEpoch 20: early stopping\n\n\n\nloss = history_ann_class.history['loss']\nval_loss = history_ann_class.history['val_loss']\naccuracy = history_ann_class.history['accuracy']\nval_accuracy = history_ann_class.history['val_accuracy']\nepochs = range(len(loss))\n\nfig, ax = plt.subplots(1, 2, figsize=(8,3))\nax[0].plot(epochs, loss)\nax[0].plot(epochs, val_loss)\nax[0].legend(['loss', 'val_loss'], loc='upper right')\nax[0].set_title('Train Loss vs Val Loss')\nax[1].plot(epochs, accuracy)\nax[1].plot(epochs, val_accuracy)\nax[1].legend(['accuracy', 'val_accuracy'], loc='lower right')\nax[1].set_title('Train Acc vs Val Acc')\nplt.show()\n\n\n\n\n\nmodel_ann_class.evaluate(X_val, y_val)\n\n313/313 [==============================] - 1s 4ms/step - loss: 0.3150 - accuracy: 0.8872\n\n\n[0.31500566005706787, 0.8871999979019165]\n\n\n\nmodel_ann_class.evaluate(X_test, y_test)\n\n313/313 [==============================] - 2s 5ms/step - loss: 0.3424 - accuracy: 0.8841\n\n\n[0.342407763004303, 0.8841000199317932]\n\n\n\n\n\n\n\ntf.keras.backend.clear_session()\n\nmodel_cnn = tf.keras.Sequential([\n    tf.keras.layers.Conv2D(filters=32, kernel_size=(5,5),\n                           activation='relu', input_shape=(28,28,1)),\n    tf.keras.layers.MaxPooling2D(pool_size=2),\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(100, activation='relu'),\n    tf.keras.layers.Dense(50, activation='relu'),\n    tf.keras.layers.Dense(10, activation='softmax')\n])\n\nmodel_cnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy',\n                  metrics='accuracy')\n\nmodel_cnn.summary()\n\nModel: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d (Conv2D)             (None, 24, 24, 32)        832       \n                                                                 \n max_pooling2d (MaxPooling2D  (None, 12, 12, 32)       0         \n )                                                               \n                                                                 \n conv2d_1 (Conv2D)           (None, 10, 10, 64)        18496     \n                                                                 \n max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n 2D)                                                             \n                                                                 \n flatten (Flatten)           (None, 1600)              0         \n                                                                 \n dense (Dense)               (None, 100)               160100    \n                                                                 \n dense_1 (Dense)             (None, 50)                5050      \n                                                                 \n dense_2 (Dense)             (None, 10)                510       \n                                                                 \n=================================================================\nTotal params: 184,988\nTrainable params: 184,988\nNon-trainable params: 0\n_________________________________________________________________\n\n\n\nearly_stop = tf.keras.callbacks.EarlyStopping(patience=5, monitor='val_loss',\n                                              restore_best_weights=True,\n                                              verbose=1)\n\nhistory_cnn = model_cnn.fit(X_train, y_train, validation_data=(X_val, y_val),\n                            epochs=100, batch_size=256, \n                            callbacks=[early_stop])\n\nEpoch 1/100\n196/196 [==============================] - 4s 9ms/step - loss: 0.7431 - accuracy: 0.7296 - val_loss: 0.4864 - val_accuracy: 0.8231\nEpoch 2/100\n196/196 [==============================] - 1s 7ms/step - loss: 0.4358 - accuracy: 0.8453 - val_loss: 0.4050 - val_accuracy: 0.8536\nEpoch 3/100\n196/196 [==============================] - 1s 7ms/step - loss: 0.3686 - accuracy: 0.8686 - val_loss: 0.3497 - val_accuracy: 0.8712\nEpoch 4/100\n196/196 [==============================] - 1s 6ms/step - loss: 0.3341 - accuracy: 0.8812 - val_loss: 0.3283 - val_accuracy: 0.8801\nEpoch 5/100\n196/196 [==============================] - 1s 6ms/step - loss: 0.3081 - accuracy: 0.8892 - val_loss: 0.3191 - val_accuracy: 0.8836\nEpoch 6/100\n196/196 [==============================] - 1s 6ms/step - loss: 0.2845 - accuracy: 0.8986 - val_loss: 0.3178 - val_accuracy: 0.8832\nEpoch 7/100\n196/196 [==============================] - 1s 6ms/step - loss: 0.2725 - accuracy: 0.9018 - val_loss: 0.2926 - val_accuracy: 0.8930\nEpoch 8/100\n196/196 [==============================] - 1s 6ms/step - loss: 0.2596 - accuracy: 0.9049 - val_loss: 0.2756 - val_accuracy: 0.8989\nEpoch 9/100\n196/196 [==============================] - 1s 6ms/step - loss: 0.2430 - accuracy: 0.9127 - val_loss: 0.2777 - val_accuracy: 0.8984\nEpoch 10/100\n196/196 [==============================] - 1s 6ms/step - loss: 0.2356 - accuracy: 0.9147 - val_loss: 0.2626 - val_accuracy: 0.9062\nEpoch 11/100\n196/196 [==============================] - 1s 7ms/step - loss: 0.2249 - accuracy: 0.9176 - val_loss: 0.2759 - val_accuracy: 0.9008\nEpoch 12/100\n196/196 [==============================] - 1s 7ms/step - loss: 0.2127 - accuracy: 0.9226 - val_loss: 0.2729 - val_accuracy: 0.9011\nEpoch 13/100\n196/196 [==============================] - 1s 7ms/step - loss: 0.2046 - accuracy: 0.9251 - val_loss: 0.2617 - val_accuracy: 0.9005\nEpoch 14/100\n196/196 [==============================] - 1s 6ms/step - loss: 0.1946 - accuracy: 0.9298 - val_loss: 0.2634 - val_accuracy: 0.9064\nEpoch 15/100\n196/196 [==============================] - 1s 6ms/step - loss: 0.1821 - accuracy: 0.9333 - val_loss: 0.2505 - val_accuracy: 0.9082\nEpoch 16/100\n196/196 [==============================] - 1s 6ms/step - loss: 0.1754 - accuracy: 0.9350 - val_loss: 0.2533 - val_accuracy: 0.9083\nEpoch 17/100\n196/196 [==============================] - 1s 6ms/step - loss: 0.1686 - accuracy: 0.9381 - val_loss: 0.2435 - val_accuracy: 0.9122\nEpoch 18/100\n196/196 [==============================] - 1s 6ms/step - loss: 0.1602 - accuracy: 0.9408 - val_loss: 0.2461 - val_accuracy: 0.9125\nEpoch 19/100\n196/196 [==============================] - 1s 6ms/step - loss: 0.1513 - accuracy: 0.9442 - val_loss: 0.2658 - val_accuracy: 0.9040\nEpoch 20/100\n196/196 [==============================] - 1s 6ms/step - loss: 0.1449 - accuracy: 0.9460 - val_loss: 0.2570 - val_accuracy: 0.9161\nEpoch 21/100\n196/196 [==============================] - 1s 7ms/step - loss: 0.1357 - accuracy: 0.9506 - val_loss: 0.2469 - val_accuracy: 0.9147\nEpoch 22/100\n194/196 [============================>.] - ETA: 0s - loss: 0.1297 - accuracy: 0.9521Restoring model weights from the end of the best epoch: 17.\n196/196 [==============================] - 1s 7ms/step - loss: 0.1298 - accuracy: 0.9521 - val_loss: 0.2894 - val_accuracy: 0.9066\nEpoch 22: early stopping\n\n\n\nloss = history_cnn.history['loss']\nval_loss = history_cnn.history['val_loss']\naccuracy = history_cnn.history['accuracy']\nval_accuracy = history_cnn.history['val_accuracy']\nepochs = range(len(loss))\n\nfig, ax = plt.subplots(1, 2, figsize=(8,3))\nax[0].plot(epochs, loss)\nax[0].plot(epochs, val_loss)\nax[0].legend(['loss', 'val_loss'], loc='upper right')\nax[0].set_title('Train Loss vs Val Loss')\nax[1].plot(epochs, accuracy)\nax[1].plot(epochs, val_accuracy)\nax[1].legend(['accuracy', 'val_accuracy'], loc='lower right')\nax[1].set_title('Train Acc vs Val Acc')\nplt.show()\n\n\n\n\n\nmodel_cnn.evaluate(X_val, y_val)\n\n313/313 [==============================] - 1s 3ms/step - loss: 0.2435 - accuracy: 0.9122\n\n\n[0.2434857189655304, 0.9121999740600586]\n\n\n\nmodel_cnn.evaluate(X_test, y_test)\n\n313/313 [==============================] - 1s 2ms/step - loss: 0.2664 - accuracy: 0.9079\n\n\n[0.26635172963142395, 0.9078999757766724]\n\n\n\ny_pred = tf.argmax(model_cnn.predict(X_test), axis=-1).numpy()\ny_pred[:10], y_test[:10]\n\n313/313 [==============================] - 1s 2ms/step\n\n\n(array([9, 2, 1, 1, 6, 1, 4, 6, 5, 7]),\n array([9, 2, 1, 1, 6, 1, 4, 6, 5, 7], dtype=uint8))\n\n\n\n#@title Wrong Prediction image {run:\"auto\"}\n\nwrong_pred = (y_pred != y_test)\n\nwrong_pred_idx = 8 #@param {type:\"slider\", min:0, max:20, step:1}\n\nprint(f'Prediction: {class_names[y_pred[wrong_pred][wrong_pred_idx]]}')\nprint(f'Truth: {class_names[y_test[wrong_pred][wrong_pred_idx]]}')\n\nplt.imshow(X_test[wrong_pred][wrong_pred_idx], cmap='gray')\nplt.axis('OFF')\nplt.show()\n\nPrediction: Coat\nTruth: Pullover\n\n\n\n\n\n\n\n\n\nSelanjutnya, kita coba untuk membuat model ANN untuk masalah regresi (harga rumah).\n\n\n\nhousing = fetch_california_housing()\nX = housing['data']\ny = housing['target']\n\nprint(f'X shape: {X.shape}')\nprint(f'y shape: {y.shape}')\n\nX shape: (20640, 8)\ny shape: (20640,)\n\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.4,\n                                                    random_state=42)\nX_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=.5,\n                                                random_state=42)\n\nprint(f'X_train shape: {X_train.shape}')\nprint(f'y_train shape: {y_train.shape}')\nprint(f'X_val shape: {X_val.shape}')\nprint(f'y_val shape: {y_val.shape}')\nprint(f'X_test shape: {X_test.shape}')\nprint(f'y_test shape: {y_test.shape}')\n\nX_train shape: (12384, 8)\ny_train shape: (12384,)\nX_val shape: (4128, 8)\ny_val shape: (4128,)\nX_test shape: (4128, 8)\ny_test shape: (4128,)\n\n\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_val = scaler.transform(X_val)\nX_test = scaler.transform(X_test)\n\n\nprint(f'y min: {y_train.min()}')\nprint(f'y max: {y_train.max()}')\n\ny min: 0.14999\ny max: 5.00001\n\n\n\n\n\n\ntf.keras.backend.clear_session()\n\nmodel_reg = tf.keras.Sequential([\n    tf.keras.layers.Dense(30, activation='relu',\n                          input_shape=X_train.shape[1:]),\n    tf.keras.layers.Dense(1, activation='relu')\n])\n\nmodel_reg.compile(optimizer='adam', loss='mse')\n\nmodel_reg.summary()\n\nModel: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n dense (Dense)               (None, 30)                270       \n                                                                 \n dense_1 (Dense)             (None, 1)                 31        \n                                                                 \n=================================================================\nTotal params: 301\nTrainable params: 301\nNon-trainable params: 0\n_________________________________________________________________\n\n\n\nearly_stop = tf.keras.callbacks.EarlyStopping(patience=5, monitor='val_loss',\n                                              restore_best_weights=True,\n                                              verbose=1)\n\nhistory_reg = model_reg.fit(X_train, y_train, validation_data=(X_val, y_val),\n                            epochs=500, callbacks=[early_stop])\n\nEpoch 1/500\n387/387 [==============================] - 2s 3ms/step - loss: 1.1266 - val_loss: 0.6397\nEpoch 2/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.5616 - val_loss: 0.5056\nEpoch 3/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.4695 - val_loss: 0.4661\nEpoch 4/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.4385 - val_loss: 0.4433\nEpoch 5/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.4195 - val_loss: 0.4286\nEpoch 6/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.4072 - val_loss: 0.4212\nEpoch 7/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3966 - val_loss: 0.4100\nEpoch 8/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3869 - val_loss: 0.4032\nEpoch 9/500\n387/387 [==============================] - 1s 4ms/step - loss: 0.3810 - val_loss: 0.3999\nEpoch 10/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3751 - val_loss: 0.3966\nEpoch 11/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3723 - val_loss: 0.3905\nEpoch 12/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3662 - val_loss: 0.3851\nEpoch 13/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3615 - val_loss: 0.3816\nEpoch 14/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3576 - val_loss: 0.3778\nEpoch 15/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3537 - val_loss: 0.3785\nEpoch 16/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3505 - val_loss: 0.3734\nEpoch 17/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3483 - val_loss: 0.3933\nEpoch 18/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3487 - val_loss: 0.3685\nEpoch 19/500\n387/387 [==============================] - 3s 8ms/step - loss: 0.3406 - val_loss: 0.3654\nEpoch 20/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3827 - val_loss: 0.3608\nEpoch 21/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3379 - val_loss: 0.3623\nEpoch 22/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3342 - val_loss: 0.3568\nEpoch 23/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3342 - val_loss: 0.3583\nEpoch 24/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3322 - val_loss: 0.3565\nEpoch 25/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3310 - val_loss: 0.3567\nEpoch 26/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3294 - val_loss: 0.3529\nEpoch 27/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3287 - val_loss: 0.3545\nEpoch 28/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3297 - val_loss: 0.3495\nEpoch 29/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3249 - val_loss: 0.3585\nEpoch 30/500\n387/387 [==============================] - 1s 4ms/step - loss: 0.3247 - val_loss: 0.3511\nEpoch 31/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3226 - val_loss: 0.3478\nEpoch 32/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3234 - val_loss: 0.3475\nEpoch 33/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3231 - val_loss: 0.3502\nEpoch 34/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3316 - val_loss: 0.3473\nEpoch 35/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3212 - val_loss: 0.3471\nEpoch 36/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3192 - val_loss: 0.3448\nEpoch 37/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3176 - val_loss: 0.3443\nEpoch 38/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3195 - val_loss: 0.3426\nEpoch 39/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3180 - val_loss: 0.3437\nEpoch 40/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3148 - val_loss: 0.3434\nEpoch 41/500\n387/387 [==============================] - 1s 4ms/step - loss: 0.3148 - val_loss: 0.3402\nEpoch 42/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3146 - val_loss: 0.3408\nEpoch 43/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3157 - val_loss: 0.3396\nEpoch 44/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3115 - val_loss: 0.3438\nEpoch 45/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3114 - val_loss: 0.3403\nEpoch 46/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3155 - val_loss: 0.3378\nEpoch 47/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3117 - val_loss: 0.3367\nEpoch 48/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3099 - val_loss: 0.3349\nEpoch 49/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3085 - val_loss: 0.3338\nEpoch 50/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3088 - val_loss: 0.3373\nEpoch 51/500\n387/387 [==============================] - 1s 3ms/step - loss: 0.3080 - val_loss: 0.3387\nEpoch 52/500\n387/387 [==============================] - 1s 4ms/step - loss: 0.3094 - val_loss: 0.3539\nEpoch 53/500\n387/387 [==============================] - 2s 6ms/step - loss: 0.3487 - val_loss: 0.3349\nEpoch 54/500\n373/387 [===========================>..] - ETA: 0s - loss: 0.3093Restoring model weights from the end of the best epoch: 49.\n387/387 [==============================] - 2s 6ms/step - loss: 0.3087 - val_loss: 0.3633\nEpoch 54: early stopping\n\n\n\nloss = history_reg.history['loss']\nval_loss = history_reg.history['val_loss']\nepochs = range(len(loss))\n\nplt.plot(epochs, loss)\nplt.plot(epochs, val_loss)\nplt.legend(['loss', 'val_loss'], loc='upper right')\nplt.title('Train Loss vs Val Loss')\nplt.show()\n\n\n\n\n\nmodel_reg.evaluate(X_val, y_val)\n\n129/129 [==============================] - 1s 3ms/step - loss: 0.3338\n\n\n0.33384060859680176\n\n\n\nmodel_reg.evaluate(X_test, y_test)\n\n129/129 [==============================] - 0s 3ms/step - loss: 0.3242\n\n\n0.32420143485069275\n\n\n\ny_pred = model_reg.predict(X_test)\n\nplt.hist(y_pred, color='green', alpha=.6)\nplt.hist(y_test, color='blue', alpha=.6)\nplt.legend(['prediction', 'truth'], loc='upper right')\nplt.show()\n\n129/129 [==============================] - 0s 3ms/step\n\n\n\n\n\n\n\n\n\nBerikut merupakan contoh - contoh penggunaan Functional API. Pada modul ini tidak dibahas banyak karena penggunaannya yang cukup mudah, hanya sedikit berbeda dengan Sequential.\nInformasi lebih lanjut dapat dipelajari pada link berikut: https://keras.io/guides/functional_api/\n\n\nMembuat NN regressor dengan arsitekur yang sama seperti saat menggunakan Sequential API di atas.\n\ntf.keras.backend.clear_session()\n\ninput_layer = tf.keras.layers.Input(shape=X_train.shape[1:])\ndense = tf.keras.layers.Dense(30, activation='relu')(input_layer)\noutput_layer = tf.keras.layers.Dense(1, activation='relu')(dense)\n\nmodel = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n\nmodel.compile(optimizer='adam', loss='mse')\n\nmodel.summary()\n\nModel: \"model\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_1 (InputLayer)        [(None, 8)]               0         \n                                                                 \n dense (Dense)               (None, 30)                270       \n                                                                 \n dense_1 (Dense)             (None, 1)                 31        \n                                                                 \n=================================================================\nTotal params: 301\nTrainable params: 301\nNon-trainable params: 0\n_________________________________________________________________\n\n\n\n\n\nMembuat arsitektur “Wide & Deep”\n\n\n\nimage.png\n\n\nReference: “Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow” by Aurélien Géron\n\ntf.keras.backend.clear_session()\n\ninput_layer = tf.keras.layers.Input(shape=X_train.shape[1:])\nhidden1 = tf.keras.layers.Dense(30, activation=\"relu\")(input_layer)\nhidden2 = tf.keras.layers.Dense(30, activation=\"relu\")(hidden1)\nconcat = tf.keras.layers.Concatenate()([input_layer, hidden2])\noutput = tf.keras.layers.Dense(1)(concat)\n\nmodel = tf.keras.Model(inputs=input_layer, outputs=output,\n                       name='wide_and_deep')\n\nmodel.compile(optimizer='adam', loss='mse')\n\nmodel.summary()\n\nModel: \"wide_and_deep\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_1 (InputLayer)           [(None, 8)]          0           []                               \n                                                                                                  \n dense (Dense)                  (None, 30)           270         ['input_1[0][0]']                \n                                                                                                  \n dense_1 (Dense)                (None, 30)           930         ['dense[0][0]']                  \n                                                                                                  \n concatenate (Concatenate)      (None, 38)           0           ['input_1[0][0]',                \n                                                                  'dense_1[0][0]']                \n                                                                                                  \n dense_2 (Dense)                (None, 1)            39          ['concatenate[0][0]']            \n                                                                                                  \n==================================================================================================\nTotal params: 1,239\nTrainable params: 1,239\nNon-trainable params: 0\n__________________________________________________________________________________________________\n\n\n\n\n\nMembuat arsitektur dengan multiple input\n\n\n\nimage.png\n\n\nReference: “Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow” by Aurélien Géron\n\ntf.keras.backend.clear_session()\n\ninput_A = tf.keras.layers.Input(shape=[5], name=\"wide_input\")\ninput_B = tf.keras.layers.Input(shape=[6], name=\"deep_input\")\nhidden1 = tf.keras.layers.Dense(30, activation=\"relu\")(input_B)\nhidden2 = tf.keras.layers.Dense(30, activation=\"relu\")(hidden1)\nconcat = tf.keras.layers.concatenate([input_A, hidden2])\noutput = tf.keras.layers.Dense(1, name=\"output\")(concat)\n\nmodel = tf.keras.Model(inputs=[input_A, input_B], outputs=[output],\n                       name='multiple_input')\n\nmodel.compile(optimizer='adam', loss='mse')\n\nmodel.summary()\n\nModel: \"multiple_input\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n deep_input (InputLayer)        [(None, 6)]          0           []                               \n                                                                                                  \n dense (Dense)                  (None, 30)           210         ['deep_input[0][0]']             \n                                                                                                  \n wide_input (InputLayer)        [(None, 5)]          0           []                               \n                                                                                                  \n dense_1 (Dense)                (None, 30)           930         ['dense[0][0]']                  \n                                                                                                  \n concatenate (Concatenate)      (None, 35)           0           ['wide_input[0][0]',             \n                                                                  'dense_1[0][0]']                \n                                                                                                  \n output (Dense)                 (None, 1)            36          ['concatenate[0][0]']            \n                                                                                                  \n==================================================================================================\nTotal params: 1,176\nTrainable params: 1,176\nNon-trainable params: 0\n__________________________________________________________________________________________________\n\n\n\n\n\n\nPada bagian terakhir dari modul ini, kita akan mencoba melakukan hyperparameter tuning untuk menentukan arsitektur NN terbaik yang menghasilkan val_loss terendah.\nInformasi lebih lanjut dapat dilihat pada dokumentasi keras-tuner: https://keras.io/api/keras_tuner/\n\ndef build_model_reg(hp):\n    model = tf.keras.Sequential()\n    n_hid_layers = hp.Int('n_hid_layers', 1, 2)\n    for layer in range(n_hid_layers):\n        n_neurons = hp.Int(f'n_neurons_{layer}', 32, 128, step=16)\n        act = hp.Choice(f'activation_{layer}', \n                        ['relu', 'linear', 'sigmoid'])\n        model.add(tf.keras.layers.Dense(n_neurons, activation=act))\n    \n    act_output = hp.Choice('activation_output', ['relu', 'linear'])\n    model.add(tf.keras.layers.Dense(1, activation=act_output))\n\n    lr = hp.Float('learning_rate', 1e-5, 1e-2)\n    opt = tf.keras.optimizers.Adam(learning_rate=lr)\n    model.compile(optimizer=opt, loss='mse')\n\n    return model\n\n\n\n\ntf.keras.backend.clear_session()\n\ntuner = kt.BayesianOptimization(hypermodel=build_model_reg,\n                                objective='val_loss',\n                                max_trials=10,\n                                directory='tuner_dir_0',\n                                project_name='tune_housing_model')\n\ntuner.search_space_summary()\n\nSearch space summary\nDefault search space size: 5\nn_hid_layers (Int)\n{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 2, 'step': 1, 'sampling': 'linear'}\nn_neurons_0 (Int)\n{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 128, 'step': 16, 'sampling': 'linear'}\nactivation_0 (Choice)\n{'default': 'relu', 'conditions': [], 'values': ['relu', 'linear', 'sigmoid'], 'ordered': False}\nactivation_output (Choice)\n{'default': 'relu', 'conditions': [], 'values': ['relu', 'linear'], 'ordered': False}\nlearning_rate (Float)\n{'default': 1e-05, 'conditions': [], 'min_value': 1e-05, 'max_value': 0.01, 'step': None, 'sampling': 'linear'}\n\n\n\ntuner.search(X_train, y_train, validation_data=(X_val, y_val),\n             epochs=100, batch_size=256)\n\nTrial 10 Complete [00h 00m 42s]\nval_loss: 0.27770957350730896\n\nBest val_loss So Far: 0.27770957350730896\nTotal elapsed time: 00h 06m 40s\n\n\n\ntuner.results_summary(3)\n\nResults summary\nResults in tuner_dir_0/tune_housing_model\nShowing 3 best trials\nObjective(name=\"val_loss\", direction=\"min\")\n\nTrial 09 summary\nHyperparameters:\nn_hid_layers: 2\nn_neurons_0: 48\nactivation_0: relu\nactivation_output: linear\nlearning_rate: 0.00724696590440984\nn_neurons_1: 96\nactivation_1: sigmoid\nScore: 0.27770957350730896\n\nTrial 01 summary\nHyperparameters:\nn_hid_layers: 2\nn_neurons_0: 128\nactivation_0: sigmoid\nactivation_output: linear\nlearning_rate: 0.009038408225650444\nn_neurons_1: 64\nactivation_1: relu\nScore: 0.28969764709472656\n\nTrial 02 summary\nHyperparameters:\nn_hid_layers: 1\nn_neurons_0: 80\nactivation_0: relu\nactivation_output: linear\nlearning_rate: 0.004831622738137635\nn_neurons_1: 32\nactivation_1: relu\nScore: 0.3006684482097626\n\n\n\n\n\n\nmodel = build_model_reg(tuner.get_best_hyperparameters()[0])\nmodel.build(input_shape=(None,) + X_train.shape[1:])\n\nmodel.summary()\n\nModel: \"sequential_2\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n dense_6 (Dense)             (None, 48)                432       \n                                                                 \n dense_7 (Dense)             (None, 96)                4704      \n                                                                 \n dense_8 (Dense)             (None, 1)                 97        \n                                                                 \n=================================================================\nTotal params: 5,233\nTrainable params: 5,233\nNon-trainable params: 0\n_________________________________________________________________\n\n\n\nearly_stop = tf.keras.callbacks.EarlyStopping(patience=10, monitor='val_loss',\n                                              restore_best_weights=True,\n                                              verbose=1)\n\nhistory = model.fit(X_train, y_train, validation_data=(X_val, y_val),\n                    epochs=500, batch_size=256, callbacks=[early_stop])\n\nEpoch 1/500\n49/49 [==============================] - 3s 11ms/step - loss: 1.1235 - val_loss: 0.5184\nEpoch 2/500\n49/49 [==============================] - 0s 7ms/step - loss: 0.4471 - val_loss: 0.4324\nEpoch 3/500\n49/49 [==============================] - 0s 6ms/step - loss: 0.3967 - val_loss: 0.4041\nEpoch 4/500\n49/49 [==============================] - 0s 7ms/step - loss: 0.3720 - val_loss: 0.3898\nEpoch 5/500\n49/49 [==============================] - 0s 7ms/step - loss: 0.3610 - val_loss: 0.3772\nEpoch 6/500\n49/49 [==============================] - 0s 6ms/step - loss: 0.3529 - val_loss: 0.3724\nEpoch 7/500\n49/49 [==============================] - 0s 7ms/step - loss: 0.3494 - val_loss: 0.3672\nEpoch 8/500\n49/49 [==============================] - 0s 6ms/step - loss: 0.3378 - val_loss: 0.3561\nEpoch 9/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.3316 - val_loss: 0.3472\nEpoch 10/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.3279 - val_loss: 0.3419\nEpoch 11/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.3230 - val_loss: 0.3534\nEpoch 12/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.3173 - val_loss: 0.3345\nEpoch 13/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.3128 - val_loss: 0.3340\nEpoch 14/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.3110 - val_loss: 0.3310\nEpoch 15/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.3042 - val_loss: 0.3332\nEpoch 16/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.3041 - val_loss: 0.3248\nEpoch 17/500\n49/49 [==============================] - 0s 6ms/step - loss: 0.2975 - val_loss: 0.3290\nEpoch 18/500\n49/49 [==============================] - 0s 6ms/step - loss: 0.2991 - val_loss: 0.3225\nEpoch 19/500\n49/49 [==============================] - 0s 6ms/step - loss: 0.2929 - val_loss: 0.3183\nEpoch 20/500\n49/49 [==============================] - 0s 6ms/step - loss: 0.2927 - val_loss: 0.3366\nEpoch 21/500\n49/49 [==============================] - 0s 6ms/step - loss: 0.2909 - val_loss: 0.3194\nEpoch 22/500\n49/49 [==============================] - 0s 6ms/step - loss: 0.2889 - val_loss: 0.3159\nEpoch 23/500\n49/49 [==============================] - 0s 6ms/step - loss: 0.2871 - val_loss: 0.3114\nEpoch 24/500\n49/49 [==============================] - 0s 6ms/step - loss: 0.2891 - val_loss: 0.3127\nEpoch 25/500\n49/49 [==============================] - 0s 6ms/step - loss: 0.2832 - val_loss: 0.3121\nEpoch 26/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2845 - val_loss: 0.3264\nEpoch 27/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2882 - val_loss: 0.3065\nEpoch 28/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2848 - val_loss: 0.3232\nEpoch 29/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2855 - val_loss: 0.3053\nEpoch 30/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2784 - val_loss: 0.3027\nEpoch 31/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2803 - val_loss: 0.3298\nEpoch 32/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2765 - val_loss: 0.3051\nEpoch 33/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2796 - val_loss: 0.2993\nEpoch 34/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2725 - val_loss: 0.3027\nEpoch 35/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2790 - val_loss: 0.3162\nEpoch 36/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2750 - val_loss: 0.3013\nEpoch 37/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2789 - val_loss: 0.3064\nEpoch 38/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2705 - val_loss: 0.3062\nEpoch 39/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2706 - val_loss: 0.3087\nEpoch 40/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2682 - val_loss: 0.2949\nEpoch 41/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2649 - val_loss: 0.3018\nEpoch 42/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2701 - val_loss: 0.3006\nEpoch 43/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2656 - val_loss: 0.2946\nEpoch 44/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2641 - val_loss: 0.2970\nEpoch 45/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2653 - val_loss: 0.2900\nEpoch 46/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2669 - val_loss: 0.3028\nEpoch 47/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2659 - val_loss: 0.2936\nEpoch 48/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2652 - val_loss: 0.2974\nEpoch 49/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2613 - val_loss: 0.3024\nEpoch 50/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2626 - val_loss: 0.2932\nEpoch 51/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2588 - val_loss: 0.2958\nEpoch 52/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2602 - val_loss: 0.2936\nEpoch 53/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2630 - val_loss: 0.2977\nEpoch 54/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2628 - val_loss: 0.2893\nEpoch 55/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2586 - val_loss: 0.2858\nEpoch 56/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2569 - val_loss: 0.2890\nEpoch 57/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2571 - val_loss: 0.2903\nEpoch 58/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2588 - val_loss: 0.2977\nEpoch 59/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2559 - val_loss: 0.2848\nEpoch 60/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2584 - val_loss: 0.3046\nEpoch 61/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2584 - val_loss: 0.3007\nEpoch 62/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2556 - val_loss: 0.2972\nEpoch 63/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2525 - val_loss: 0.2865\nEpoch 64/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2499 - val_loss: 0.2841\nEpoch 65/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2519 - val_loss: 0.2842\nEpoch 66/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2536 - val_loss: 0.2845\nEpoch 67/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2520 - val_loss: 0.2908\nEpoch 68/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2526 - val_loss: 0.2809\nEpoch 69/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2526 - val_loss: 0.2859\nEpoch 70/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2463 - val_loss: 0.2805\nEpoch 71/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2456 - val_loss: 0.2853\nEpoch 72/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2470 - val_loss: 0.2829\nEpoch 73/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2463 - val_loss: 0.2827\nEpoch 74/500\n49/49 [==============================] - 0s 6ms/step - loss: 0.2457 - val_loss: 0.2794\nEpoch 75/500\n49/49 [==============================] - 0s 6ms/step - loss: 0.2461 - val_loss: 0.2793\nEpoch 76/500\n49/49 [==============================] - 0s 6ms/step - loss: 0.2488 - val_loss: 0.2824\nEpoch 77/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2412 - val_loss: 0.2795\nEpoch 78/500\n49/49 [==============================] - 0s 6ms/step - loss: 0.2423 - val_loss: 0.2789\nEpoch 79/500\n49/49 [==============================] - 0s 6ms/step - loss: 0.2426 - val_loss: 0.2810\nEpoch 80/500\n49/49 [==============================] - 0s 6ms/step - loss: 0.2424 - val_loss: 0.2805\nEpoch 81/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2421 - val_loss: 0.2767\nEpoch 82/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2418 - val_loss: 0.2835\nEpoch 83/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2454 - val_loss: 0.2826\nEpoch 84/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2373 - val_loss: 0.2756\nEpoch 85/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2365 - val_loss: 0.2821\nEpoch 86/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2386 - val_loss: 0.2828\nEpoch 87/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2352 - val_loss: 0.2786\nEpoch 88/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2360 - val_loss: 0.2780\nEpoch 89/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2327 - val_loss: 0.2793\nEpoch 90/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2366 - val_loss: 0.2755\nEpoch 91/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2352 - val_loss: 0.2758\nEpoch 92/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2334 - val_loss: 0.2770\nEpoch 93/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2333 - val_loss: 0.2821\nEpoch 94/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2327 - val_loss: 0.2780\nEpoch 95/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2323 - val_loss: 0.2752\nEpoch 96/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2369 - val_loss: 0.2760\nEpoch 97/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2319 - val_loss: 0.2744\nEpoch 98/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2313 - val_loss: 0.2806\nEpoch 99/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2319 - val_loss: 0.2770\nEpoch 100/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2330 - val_loss: 0.2782\nEpoch 101/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2287 - val_loss: 0.2793\nEpoch 102/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2269 - val_loss: 0.2736\nEpoch 103/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2285 - val_loss: 0.2821\nEpoch 104/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2273 - val_loss: 0.2753\nEpoch 105/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2265 - val_loss: 0.2779\nEpoch 106/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2259 - val_loss: 0.2780\nEpoch 107/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2267 - val_loss: 0.2743\nEpoch 108/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2289 - val_loss: 0.2751\nEpoch 109/500\n49/49 [==============================] - 0s 5ms/step - loss: 0.2259 - val_loss: 0.2879\nEpoch 110/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2296 - val_loss: 0.2814\nEpoch 111/500\n49/49 [==============================] - 0s 4ms/step - loss: 0.2274 - val_loss: 0.2887\nEpoch 112/500\n36/49 [=====================>........] - ETA: 0s - loss: 0.2293Restoring model weights from the end of the best epoch: 102.\n49/49 [==============================] - 0s 5ms/step - loss: 0.2289 - val_loss: 0.2867\nEpoch 112: early stopping\n\n\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(len(loss))\n\nplt.plot(epochs, loss)\nplt.plot(epochs, val_loss)\nplt.legend(['loss', 'val_loss'], loc='upper right')\nplt.title('Train Loss vs Val Loss')\nplt.show()\n\n\n\n\n\nmodel.evaluate(X_val, y_val)\n\n129/129 [==============================] - 0s 2ms/step - loss: 0.2736\n\n\n0.2735856771469116\n\n\n\nmodel.evaluate(X_test, y_test)\n\n129/129 [==============================] - 0s 3ms/step - loss: 0.2652\n\n\n0.2651788592338562\n\n\n\ny_pred = model.predict(X_test)\n\nplt.hist(y_pred, color='green', alpha=.6)\nplt.hist(y_test, color='blue', alpha=.6)\nplt.legend(['prediction', 'truth'], loc='upper right')\nplt.show()\n\n129/129 [==============================] - 0s 1ms/step\n\n\n\n\n\n\n\n\n\n\nhttp://neuralnetworksanddeeplearning.com/ (membahas cara kerja neural network secara matematis, cocok untuk yang suka belajar dengan membaca)\nhttp://introtodeeplearning.com/ (membahas cara kerja neural network hingga CNN, RNN, reinforcement learning, dan lain - lain, cocok untuk yang suka belajar dengan menonton video dan ingin mendalami deep learning lebih lanjut)\nBuku “Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow” by Aurélien Géron (membahas implementasi Machine Learning dan Deep Learning pada library-library yang tertera di judulnya)"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-01.html",
    "href": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-01.html",
    "title": "Lab Praktikum Departemen Matematika FMIPA UI",
    "section": "",
    "text": "Kembali ke Sains Data\n\n\nPada module ini kita akan coba mememahami package pandas, yang merupakan package inti dalam sains-data. kita akan coba melakukan beberapa transformasi data menggunakan pandas.\nsebelum itu, python module di bawah ini yang akan digunakan selama praktikum.\n\nimport numpy as np\nimport pandas as pd\n\n\n\n\npandas.Series sangat mirip dengan array NumPy (bahkan dibangun di atas objek array NumPy). Yang membedakan array NumPy dari sebuah Series adalah bahwa sebuah Series dapat memiliki label index, yang berarti dapat diindeks dengan label, bukan hanya lokasi nomor saja. Selain itu, sebuah Series tidak perlu menyimpan data numerik, ia dapat menyimpan objek Python sembarang.\n\n\nPaling mudah, ktia dapat membuat pd.Series dengan python list\n\nmy_index= ['a','b','c','d','e']\nmy_data= [1,2,3,4,5]\nmy_series= pd.Series(data=my_data, index=my_index)\n\n\nprint(my_series)\nprint(my_series.__class__)\n\na    1\nb    2\nc    3\nd    4\ne    5\ndtype: int64\n<class 'pandas.core.series.Series'>\n\n\n\n\n\nKita juga dapat membuat pd.Series dengan dictionary\n\n# creating a series from a dictionary\nmy_dict= {'a':1, 'b':2, 'c':3, 'd':4, 'e':5}\nmy_series_dict= pd.Series(my_dict)\n\n\nprint(my_series_dict)\nprint(my_series_dict.__class__)\n\na    1\nb    2\nc    3\nd    4\ne    5\ndtype: int64\n<class 'pandas.core.series.Series'>\n\n\n\n\n\n\n# Imaginary Sales Data for 1st and 2nd Quarters for Global Company\nq1 = {'Japan': 80, 'China': 450, 'India': 200, 'USA': 250}\nq2 = {'Brazil': 100,'China': 500, 'India': 210,'USA': 260}\n\n\n# Creating a Series from a Dictionary q1 and q2\nq1_series= pd.Series(q1)\nq2_series= pd.Series(q2)\n\n\nprint(q1_series)\n\nJapan     80\nChina    450\nIndia    200\nUSA      250\ndtype: int64\n\n\nKita dapat mengindeks dengan label\n\n# call values of q1_series based on named index\nprint(q1_series['Japan'])\nprint(q1_series['China'])\nprint(q1_series['India'])\n\n80\n450\n200\n\n\nkita dapat tetap dapat mengindeks dengan integer\n\n# u can also call values of q1_series based on positional index\nprint(q1_series[0])\nprint(q1_series[1])\nprint(q1_series[2])\n\n80\n450\n200\n\n\nhati-hati dalam melakukan indexing dengan label. bisa saja terjadi error jika label tidak ada di dalam pd.series\n\n# remember named index is case sensitive\ntry:\n    print(q1_series['japan'])\nexcept:\n    print('something went wrong')\n\nsomething went wrong\n\n\nOperasi aritmatik sederhana pada pd.Series bersifat broadcasting\n\n# operations with arithmetic on series are broadcasted to all values\nprint(q1_series*2)\n\nJapan    160\nChina    900\nIndia    400\nUSA      500\ndtype: int64\n\n\n\nprint(q1_series+1000)\n\nJapan    1080\nChina    1450\nIndia    1200\nUSA      1250\ndtype: int64\n\n\n\n# operation between series are also broadcasted\nprint(q1_series+q2_series)\n\nBrazil      NaN\nChina     950.0\nIndia     410.0\nJapan       NaN\nUSA       510.0\ndtype: float64\n\n\n\nprint(q1_series.add(q2_series, fill_value=0))\n\nBrazil    100.0\nChina     950.0\nIndia     410.0\nJapan      80.0\nUSA       510.0\ndtype: float64\n\n\n\n\n\n\nSebuah pd.DataFrame terdiri dari beberapa pd.Series yang berbagi nilai indeks.\n\nmy_data= np.random.randint(0,100,12).reshape(4,3)\nmy_data\n\narray([[25, 59, 18],\n       [75, 54, 65],\n       [29, 21,  7],\n       [32, 69, 16]])\n\n\nKita akan membuat pd.Dataframe melalui python list. Perhatikan bahwa kita dapat memberikan nama pada kolom dan baris\n\nmy_index= [\"jakarta\", \"bandung\", \"surabaya\", \"medan\"]\nmy_columns= [\"apple\", \"orange\", \"banana\"]\n\ndf= pd.DataFrame(data=my_data, index=my_index, columns=my_columns)\ndf\n\n\n\n\n\n  \n    \n      \n      apple\n      orange\n      banana\n    \n  \n  \n    \n      jakarta\n      25\n      59\n      18\n    \n    \n      bandung\n      75\n      54\n      65\n    \n    \n      surabaya\n      29\n      21\n      7\n    \n    \n      medan\n      32\n      69\n      16\n    \n  \n\n\n\n\n\ndf_2= pd.DataFrame(data=my_data)\ndf_2\n\n\n\n\n\n  \n    \n      \n      0\n      1\n      2\n    \n  \n  \n    \n      0\n      25\n      59\n      18\n    \n    \n      1\n      75\n      54\n      65\n    \n    \n      2\n      29\n      21\n      7\n    \n    \n      3\n      32\n      69\n      16\n    \n  \n\n\n\n\n\ndf_3= pd.DataFrame(data=my_data, columns=my_columns)\ndf_3\n\n\n\n\n\n  \n    \n      \n      apple\n      orange\n      banana\n    \n  \n  \n    \n      0\n      25\n      59\n      18\n    \n    \n      1\n      75\n      54\n      65\n    \n    \n      2\n      29\n      21\n      7\n    \n    \n      3\n      32\n      69\n      16\n    \n  \n\n\n\n\n\n\nJika berkas .py atau .ipynb Anda berada di lokasi folder yang sama persis dengan berkas .csv yang ingin Anda baca, cukup berikan nama berkas sebagai string, misalnya:\ndf = pd.read_csv('[some_file.csv')\nBerikan s berkas jika Anda berada di direktori yang berbeda. Jalur berkas harus 100% benar agar ini berfungsi. Misalnya:\ndf = pd.read_csv(\"C:\\\\Users\\\\myself\\\\files\\\\some_file.csv\")\nsebelum itu, kalian dapat mendownload data tersebut melalui link berikut\nDownload\n\npwd\n\n'c:\\\\Users\\\\user\\\\Documents\\\\root\\\\personal\\\\github-personal\\\\sains-data-2023\\\\main-module'\n\n\n\ndf_tips= pd.read_csv('./data/tips.csv')\n\n\ndf_tips\n\n\n\n\n\n  \n    \n      \n      total_bill\n      tip\n      sex\n      smoker\n      day\n      time\n      size\n      price_per_person\n      Payer Name\n      CC Number\n      Payment ID\n    \n  \n  \n    \n      0\n      16.99\n      1.01\n      Female\n      No\n      Sun\n      Dinner\n      2\n      8.49\n      Christy Cunningham\n      3560325168603410\n      Sun2959\n    \n    \n      1\n      10.34\n      1.66\n      Male\n      No\n      Sun\n      Dinner\n      3\n      3.45\n      Douglas Tucker\n      4478071379779230\n      Sun4608\n    \n    \n      2\n      21.01\n      3.50\n      Male\n      No\n      Sun\n      Dinner\n      3\n      7.00\n      Travis Walters\n      6011812112971322\n      Sun4458\n    \n    \n      3\n      23.68\n      3.31\n      Male\n      No\n      Sun\n      Dinner\n      2\n      11.84\n      Nathaniel Harris\n      4676137647685994\n      Sun5260\n    \n    \n      4\n      24.59\n      3.61\n      Female\n      No\n      Sun\n      Dinner\n      4\n      6.15\n      Tonya Carter\n      4832732618637221\n      Sun2251\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      239\n      29.03\n      5.92\n      Male\n      No\n      Sat\n      Dinner\n      3\n      9.68\n      Michael Avila\n      5296068606052842\n      Sat2657\n    \n    \n      240\n      27.18\n      2.00\n      Female\n      Yes\n      Sat\n      Dinner\n      2\n      13.59\n      Monica Sanders\n      3506806155565404\n      Sat1766\n    \n    \n      241\n      22.67\n      2.00\n      Male\n      Yes\n      Sat\n      Dinner\n      2\n      11.34\n      Keith Wong\n      6011891618747196\n      Sat3880\n    \n    \n      242\n      17.82\n      1.75\n      Male\n      No\n      Sat\n      Dinner\n      2\n      8.91\n      Dennis Dixon\n      4375220550950\n      Sat17\n    \n    \n      243\n      18.78\n      3.00\n      Female\n      No\n      Thur\n      Dinner\n      2\n      9.39\n      Michelle Hardin\n      3511451626698139\n      Thur672\n    \n  \n\n244 rows × 11 columns\n\n\n\n\n\n\n\n# mengecek nama kolom\ndf_tips.columns\n\nIndex(['total_bill', 'tip', 'sex', 'smoker', 'day', 'time', 'size',\n       'price_per_person', 'Payer Name', 'CC Number', 'Payment ID'],\n      dtype='object')\n\n\n\n# mengecek \ndf_tips.index\n\nRangeIndex(start=0, stop=244, step=1)\n\n\n\ndf_tips.head(5)\n\n\n\n\n\n  \n    \n      \n      total_bill\n      tip\n      sex\n      smoker\n      day\n      time\n      size\n      price_per_person\n      Payer Name\n      CC Number\n      Payment ID\n    \n  \n  \n    \n      0\n      16.99\n      1.01\n      Female\n      No\n      Sun\n      Dinner\n      2\n      8.49\n      Christy Cunningham\n      3560325168603410\n      Sun2959\n    \n    \n      1\n      10.34\n      1.66\n      Male\n      No\n      Sun\n      Dinner\n      3\n      3.45\n      Douglas Tucker\n      4478071379779230\n      Sun4608\n    \n    \n      2\n      21.01\n      3.50\n      Male\n      No\n      Sun\n      Dinner\n      3\n      7.00\n      Travis Walters\n      6011812112971322\n      Sun4458\n    \n    \n      3\n      23.68\n      3.31\n      Male\n      No\n      Sun\n      Dinner\n      2\n      11.84\n      Nathaniel Harris\n      4676137647685994\n      Sun5260\n    \n    \n      4\n      24.59\n      3.61\n      Female\n      No\n      Sun\n      Dinner\n      4\n      6.15\n      Tonya Carter\n      4832732618637221\n      Sun2251\n    \n  \n\n\n\n\n\ndf_tips.tail(5)\n\n\n\n\n\n  \n    \n      \n      total_bill\n      tip\n      sex\n      smoker\n      day\n      time\n      size\n      price_per_person\n      Payer Name\n      CC Number\n      Payment ID\n    \n  \n  \n    \n      239\n      29.03\n      5.92\n      Male\n      No\n      Sat\n      Dinner\n      3\n      9.68\n      Michael Avila\n      5296068606052842\n      Sat2657\n    \n    \n      240\n      27.18\n      2.00\n      Female\n      Yes\n      Sat\n      Dinner\n      2\n      13.59\n      Monica Sanders\n      3506806155565404\n      Sat1766\n    \n    \n      241\n      22.67\n      2.00\n      Male\n      Yes\n      Sat\n      Dinner\n      2\n      11.34\n      Keith Wong\n      6011891618747196\n      Sat3880\n    \n    \n      242\n      17.82\n      1.75\n      Male\n      No\n      Sat\n      Dinner\n      2\n      8.91\n      Dennis Dixon\n      4375220550950\n      Sat17\n    \n    \n      243\n      18.78\n      3.00\n      Female\n      No\n      Thur\n      Dinner\n      2\n      9.39\n      Michelle Hardin\n      3511451626698139\n      Thur672\n    \n  \n\n\n\n\n\ndf_tips.describe().transpose()\n\n\n\n\n\n  \n    \n      \n      count\n      mean\n      std\n      min\n      25%\n      50%\n      75%\n      max\n    \n  \n  \n    \n      total_bill\n      244.0\n      1.978594e+01\n      8.902412e+00\n      3.070000e+00\n      1.334750e+01\n      1.779500e+01\n      2.412750e+01\n      5.081000e+01\n    \n    \n      tip\n      244.0\n      2.998279e+00\n      1.383638e+00\n      1.000000e+00\n      2.000000e+00\n      2.900000e+00\n      3.562500e+00\n      1.000000e+01\n    \n    \n      size\n      244.0\n      2.569672e+00\n      9.510998e-01\n      1.000000e+00\n      2.000000e+00\n      2.000000e+00\n      3.000000e+00\n      6.000000e+00\n    \n    \n      price_per_person\n      244.0\n      7.888197e+00\n      2.914234e+00\n      2.880000e+00\n      5.800000e+00\n      7.255000e+00\n      9.390000e+00\n      2.027000e+01\n    \n    \n      CC Number\n      244.0\n      2.563496e+15\n      2.369340e+15\n      6.040679e+10\n      3.040731e+13\n      3.525318e+15\n      4.553675e+15\n      6.596454e+15\n    \n  \n\n\n\n\n\n\n\n\n\n\n\ndf_tips.head(5)\n\n\n\n\n\n  \n    \n      \n      total_bill\n      tip\n      sex\n      smoker\n      day\n      time\n      size\n      price_per_person\n      Payer Name\n      CC Number\n      Payment ID\n    \n  \n  \n    \n      0\n      16.99\n      1.01\n      Female\n      No\n      Sun\n      Dinner\n      2\n      8.49\n      Christy Cunningham\n      3560325168603410\n      Sun2959\n    \n    \n      1\n      10.34\n      1.66\n      Male\n      No\n      Sun\n      Dinner\n      3\n      3.45\n      Douglas Tucker\n      4478071379779230\n      Sun4608\n    \n    \n      2\n      21.01\n      3.50\n      Male\n      No\n      Sun\n      Dinner\n      3\n      7.00\n      Travis Walters\n      6011812112971322\n      Sun4458\n    \n    \n      3\n      23.68\n      3.31\n      Male\n      No\n      Sun\n      Dinner\n      2\n      11.84\n      Nathaniel Harris\n      4676137647685994\n      Sun5260\n    \n    \n      4\n      24.59\n      3.61\n      Female\n      No\n      Sun\n      Dinner\n      4\n      6.15\n      Tonya Carter\n      4832732618637221\n      Sun2251\n    \n  \n\n\n\n\n\nprint(df_tips[\"size\"] ==3)\nconditional_size = df_tips[\"size\"] ==3\n\n0      False\n1       True\n2       True\n3      False\n4      False\n       ...  \n239     True\n240    False\n241    False\n242    False\n243    False\nName: size, Length: 244, dtype: bool\n\n\n\ndf_tips[conditional_size].head()\n\n\n\n\n\n  \n    \n      \n      total_bill\n      tip\n      sex\n      smoker\n      day\n      time\n      size\n      price_per_person\n      Payer Name\n      CC Number\n      Payment ID\n    \n  \n  \n    \n      1\n      10.34\n      1.66\n      Male\n      No\n      Sun\n      Dinner\n      3\n      3.45\n      Douglas Tucker\n      4478071379779230\n      Sun4608\n    \n    \n      2\n      21.01\n      3.50\n      Male\n      No\n      Sun\n      Dinner\n      3\n      7.00\n      Travis Walters\n      6011812112971322\n      Sun4458\n    \n    \n      16\n      10.33\n      1.67\n      Female\n      No\n      Sun\n      Dinner\n      3\n      3.44\n      Elizabeth Foster\n      4240025044626033\n      Sun9715\n    \n    \n      17\n      16.29\n      3.71\n      Male\n      No\n      Sun\n      Dinner\n      3\n      5.43\n      John Pittman\n      6521340257218708\n      Sun2998\n    \n    \n      18\n      16.97\n      3.50\n      Female\n      No\n      Sun\n      Dinner\n      3\n      5.66\n      Laura Martinez\n      30422275171379\n      Sun2789\n    \n  \n\n\n\n\n\nconditional= (df_tips[\"size\"]==3) & (df_tips[\"total_bill\"]>20)\nprint(conditional)\n\n0      False\n1      False\n2       True\n3      False\n4      False\n       ...  \n239     True\n240    False\n241    False\n242    False\n243    False\nLength: 244, dtype: bool\n\n\n\ndf_tips[conditional].head()\n\n\n\n\n\n  \n    \n      \n      total_bill\n      tip\n      sex\n      smoker\n      day\n      time\n      size\n      price_per_person\n      Payer Name\n      CC Number\n      Payment ID\n    \n  \n  \n    \n      2\n      21.01\n      3.50\n      Male\n      No\n      Sun\n      Dinner\n      3\n      7.00\n      Travis Walters\n      6011812112971322\n      Sun4458\n    \n    \n      19\n      20.65\n      3.35\n      Male\n      No\n      Sat\n      Dinner\n      3\n      6.88\n      Timothy Oneal\n      6568069240986485\n      Sat9213\n    \n    \n      35\n      24.06\n      3.60\n      Male\n      No\n      Sat\n      Dinner\n      3\n      8.02\n      Joseph Mullins\n      5519770449260299\n      Sat632\n    \n    \n      39\n      31.27\n      5.00\n      Male\n      No\n      Sat\n      Dinner\n      3\n      10.42\n      Mr. Brandon Berry\n      6011525851069856\n      Sat6373\n    \n    \n      48\n      28.55\n      2.05\n      Male\n      No\n      Sun\n      Dinner\n      3\n      9.52\n      Austin Fisher\n      6011481668986587\n      Sun4142\n    \n  \n\n\n\n\n\ndf_tips[(df_tips[\"size\"]==3) & (df_tips[\"total_bill\"]>20)].head()\n\n\n\n\n\n  \n    \n      \n      total_bill\n      tip\n      sex\n      smoker\n      day\n      time\n      size\n      price_per_person\n      Payer Name\n      CC Number\n      Payment ID\n    \n  \n  \n    \n      2\n      21.01\n      3.50\n      Male\n      No\n      Sun\n      Dinner\n      3\n      7.00\n      Travis Walters\n      6011812112971322\n      Sun4458\n    \n    \n      19\n      20.65\n      3.35\n      Male\n      No\n      Sat\n      Dinner\n      3\n      6.88\n      Timothy Oneal\n      6568069240986485\n      Sat9213\n    \n    \n      35\n      24.06\n      3.60\n      Male\n      No\n      Sat\n      Dinner\n      3\n      8.02\n      Joseph Mullins\n      5519770449260299\n      Sat632\n    \n    \n      39\n      31.27\n      5.00\n      Male\n      No\n      Sat\n      Dinner\n      3\n      10.42\n      Mr. Brandon Berry\n      6011525851069856\n      Sat6373\n    \n    \n      48\n      28.55\n      2.05\n      Male\n      No\n      Sun\n      Dinner\n      3\n      9.52\n      Austin Fisher\n      6011481668986587\n      Sun4142\n    \n  \n\n\n\n\n\nweekend= [\"Sun\", \"Sat\"]\nconditional_in= df_tips[\"day\"].isin(weekend)\ndf_tips[conditional_in].head()\n\n\n\n\n\n  \n    \n      \n      total_bill\n      tip\n      sex\n      smoker\n      day\n      time\n      size\n      price_per_person\n      Payer Name\n      CC Number\n      Payment ID\n    \n  \n  \n    \n      0\n      16.99\n      1.01\n      Female\n      No\n      Sun\n      Dinner\n      2\n      8.49\n      Christy Cunningham\n      3560325168603410\n      Sun2959\n    \n    \n      1\n      10.34\n      1.66\n      Male\n      No\n      Sun\n      Dinner\n      3\n      3.45\n      Douglas Tucker\n      4478071379779230\n      Sun4608\n    \n    \n      2\n      21.01\n      3.50\n      Male\n      No\n      Sun\n      Dinner\n      3\n      7.00\n      Travis Walters\n      6011812112971322\n      Sun4458\n    \n    \n      3\n      23.68\n      3.31\n      Male\n      No\n      Sun\n      Dinner\n      2\n      11.84\n      Nathaniel Harris\n      4676137647685994\n      Sun5260\n    \n    \n      4\n      24.59\n      3.61\n      Female\n      No\n      Sun\n      Dinner\n      4\n      6.15\n      Tonya Carter\n      4832732618637221\n      Sun2251\n    \n  \n\n\n\n\n\ndf_tips.head()\n\n\n\n\n\n  \n    \n      \n      total_bill\n      tip\n      sex\n      smoker\n      day\n      time\n      size\n      price_per_person\n      Payer Name\n      CC Number\n      Payment ID\n    \n  \n  \n    \n      0\n      16.99\n      1.01\n      Female\n      No\n      Sun\n      Dinner\n      2\n      8.49\n      Christy Cunningham\n      3560325168603410\n      Sun2959\n    \n    \n      1\n      10.34\n      1.66\n      Male\n      No\n      Sun\n      Dinner\n      3\n      3.45\n      Douglas Tucker\n      4478071379779230\n      Sun4608\n    \n    \n      2\n      21.01\n      3.50\n      Male\n      No\n      Sun\n      Dinner\n      3\n      7.00\n      Travis Walters\n      6011812112971322\n      Sun4458\n    \n    \n      3\n      23.68\n      3.31\n      Male\n      No\n      Sun\n      Dinner\n      2\n      11.84\n      Nathaniel Harris\n      4676137647685994\n      Sun5260\n    \n    \n      4\n      24.59\n      3.61\n      Female\n      No\n      Sun\n      Dinner\n      4\n      6.15\n      Tonya Carter\n      4832732618637221\n      Sun2251\n    \n  \n\n\n\n\n\n\n\n\ndf_tips[\"day\"].unique()\n\narray(['Sun', 'Sat', 'Thur', 'Fri'], dtype=object)\n\n\n\ndf_tips.drop_duplicates([\"day\",\"time\"])[[\"day\",\"time\"]]\n\n\n\n\n\n  \n    \n      \n      day\n      time\n    \n  \n  \n    \n      0\n      Sun\n      Dinner\n    \n    \n      19\n      Sat\n      Dinner\n    \n    \n      77\n      Thur\n      Lunch\n    \n    \n      90\n      Fri\n      Dinner\n    \n    \n      220\n      Fri\n      Lunch\n    \n    \n      243\n      Thur\n      Dinner\n    \n  \n\n\n\n\n\n\n\n\n\n\n\nprint(df_tips[\"day\"])\nprint(\"=======\")\nprint(df_tips.day)\n\n0       Sun\n1       Sun\n2       Sun\n3       Sun\n4       Sun\n       ... \n239     Sat\n240     Sat\n241     Sat\n242     Sat\n243    Thur\nName: day, Length: 244, dtype: object\n=======\n0       Sun\n1       Sun\n2       Sun\n3       Sun\n4       Sun\n       ... \n239     Sat\n240     Sat\n241     Sat\n242     Sat\n243    Thur\nName: day, Length: 244, dtype: object\n\n\n\ndf_tips[[\"day\",\"time\"]]\n\n\n\n\n\n  \n    \n      \n      day\n      time\n    \n  \n  \n    \n      0\n      Sun\n      Dinner\n    \n    \n      1\n      Sun\n      Dinner\n    \n    \n      2\n      Sun\n      Dinner\n    \n    \n      3\n      Sun\n      Dinner\n    \n    \n      4\n      Sun\n      Dinner\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      239\n      Sat\n      Dinner\n    \n    \n      240\n      Sat\n      Dinner\n    \n    \n      241\n      Sat\n      Dinner\n    \n    \n      242\n      Sat\n      Dinner\n    \n    \n      243\n      Thur\n      Dinner\n    \n  \n\n244 rows × 2 columns\n\n\n\n\n\n\n\ndf_tips[\"tips_percentage\"]= df_tips[\"tip\"]/df_tips[\"total_bill\"]*100\n\ndf_tips.head()\n\n\n\n\n\n  \n    \n      \n      total_bill\n      tip\n      sex\n      smoker\n      day\n      time\n      size\n      price_per_person\n      Payer Name\n      CC Number\n      Payment ID\n      tips_percentage\n    \n  \n  \n    \n      0\n      16.99\n      1.01\n      Female\n      No\n      Sun\n      Dinner\n      2\n      8.49\n      Christy Cunningham\n      3560325168603410\n      Sun2959\n      5.944673\n    \n    \n      1\n      10.34\n      1.66\n      Male\n      No\n      Sun\n      Dinner\n      3\n      3.45\n      Douglas Tucker\n      4478071379779230\n      Sun4608\n      16.054159\n    \n    \n      2\n      21.01\n      3.50\n      Male\n      No\n      Sun\n      Dinner\n      3\n      7.00\n      Travis Walters\n      6011812112971322\n      Sun4458\n      16.658734\n    \n    \n      3\n      23.68\n      3.31\n      Male\n      No\n      Sun\n      Dinner\n      2\n      11.84\n      Nathaniel Harris\n      4676137647685994\n      Sun5260\n      13.978041\n    \n    \n      4\n      24.59\n      3.61\n      Female\n      No\n      Sun\n      Dinner\n      4\n      6.15\n      Tonya Carter\n      4832732618637221\n      Sun2251\n      14.680765\n    \n  \n\n\n\n\n\n\n\n\ndf_tips.rename(columns={\"tips_percentage\":\"tips_percentage_%\"}, inplace=True)\ndf_tips.head()\n\n\n\n\n\n  \n    \n      \n      total_bill\n      tip\n      sex\n      smoker\n      day\n      time\n      size\n      price_per_person\n      Payer Name\n      CC Number\n      Payment ID\n      tips_percentage_%\n    \n  \n  \n    \n      0\n      16.99\n      1.01\n      Female\n      No\n      Sun\n      Dinner\n      2\n      8.49\n      Christy Cunningham\n      3560325168603410\n      Sun2959\n      5.944673\n    \n    \n      1\n      10.34\n      1.66\n      Male\n      No\n      Sun\n      Dinner\n      3\n      3.45\n      Douglas Tucker\n      4478071379779230\n      Sun4608\n      16.054159\n    \n    \n      2\n      21.01\n      3.50\n      Male\n      No\n      Sun\n      Dinner\n      3\n      7.00\n      Travis Walters\n      6011812112971322\n      Sun4458\n      16.658734\n    \n    \n      3\n      23.68\n      3.31\n      Male\n      No\n      Sun\n      Dinner\n      2\n      11.84\n      Nathaniel Harris\n      4676137647685994\n      Sun5260\n      13.978041\n    \n    \n      4\n      24.59\n      3.61\n      Female\n      No\n      Sun\n      Dinner\n      4\n      6.15\n      Tonya Carter\n      4832732618637221\n      Sun2251\n      14.680765\n    \n  \n\n\n\n\n\n\n\n\n#relocate tips_percentage_% column to the rightmost\ncols= list(df_tips.columns)\ncols= [cols[-1]]+ cols[:-2]\n\ndf_tips= df_tips[cols]\n\n\ndf_tips\n\n\n\n\n\n  \n    \n      \n      tips_percentage_%\n      total_bill\n      tip\n      sex\n      smoker\n      day\n      time\n      size\n      price_per_person\n      Payer Name\n      CC Number\n    \n  \n  \n    \n      0\n      5.944673\n      16.99\n      1.01\n      Female\n      No\n      Sun\n      Dinner\n      2\n      8.49\n      Christy Cunningham\n      3560325168603410\n    \n    \n      1\n      16.054159\n      10.34\n      1.66\n      Male\n      No\n      Sun\n      Dinner\n      3\n      3.45\n      Douglas Tucker\n      4478071379779230\n    \n    \n      2\n      16.658734\n      21.01\n      3.50\n      Male\n      No\n      Sun\n      Dinner\n      3\n      7.00\n      Travis Walters\n      6011812112971322\n    \n    \n      3\n      13.978041\n      23.68\n      3.31\n      Male\n      No\n      Sun\n      Dinner\n      2\n      11.84\n      Nathaniel Harris\n      4676137647685994\n    \n    \n      4\n      14.680765\n      24.59\n      3.61\n      Female\n      No\n      Sun\n      Dinner\n      4\n      6.15\n      Tonya Carter\n      4832732618637221\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      239\n      20.392697\n      29.03\n      5.92\n      Male\n      No\n      Sat\n      Dinner\n      3\n      9.68\n      Michael Avila\n      5296068606052842\n    \n    \n      240\n      7.358352\n      27.18\n      2.00\n      Female\n      Yes\n      Sat\n      Dinner\n      2\n      13.59\n      Monica Sanders\n      3506806155565404\n    \n    \n      241\n      8.822232\n      22.67\n      2.00\n      Male\n      Yes\n      Sat\n      Dinner\n      2\n      11.34\n      Keith Wong\n      6011891618747196\n    \n    \n      242\n      9.820426\n      17.82\n      1.75\n      Male\n      No\n      Sat\n      Dinner\n      2\n      8.91\n      Dennis Dixon\n      4375220550950\n    \n    \n      243\n      15.974441\n      18.78\n      3.00\n      Female\n      No\n      Thur\n      Dinner\n      2\n      9.39\n      Michelle Hardin\n      3511451626698139\n    \n  \n\n244 rows × 11 columns"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-03.html",
    "href": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-03.html",
    "title": "Lab Praktikum Departemen Matematika FMIPA UI",
    "section": "",
    "text": "Kembali ke Sains Data\n\n\n\n\nimport library yang dibutuhkan terlebih dahulu untuk pengolahan dan visualisasi data.\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n\n\n\nUpload dataset yang akan digunakan dan observasi click disini\n\nsalary =  pd.read_csv('Salary_dataset.csv')\nsalary\n\n\n\n\n\n  \n    \n      \n      Unnamed: 0\n      YearsExperience\n      Salary\n    \n  \n  \n    \n      0\n      0\n      1.2\n      39344.0\n    \n    \n      1\n      1\n      1.4\n      46206.0\n    \n    \n      2\n      2\n      1.6\n      37732.0\n    \n    \n      3\n      3\n      2.1\n      43526.0\n    \n    \n      4\n      4\n      2.3\n      39892.0\n    \n    \n      5\n      5\n      3.0\n      56643.0\n    \n    \n      6\n      6\n      3.1\n      60151.0\n    \n    \n      7\n      7\n      3.3\n      54446.0\n    \n    \n      8\n      8\n      3.3\n      64446.0\n    \n    \n      9\n      9\n      3.8\n      57190.0\n    \n    \n      10\n      10\n      4.0\n      63219.0\n    \n    \n      11\n      11\n      4.1\n      55795.0\n    \n    \n      12\n      12\n      4.1\n      56958.0\n    \n    \n      13\n      13\n      4.2\n      57082.0\n    \n    \n      14\n      14\n      4.6\n      61112.0\n    \n    \n      15\n      15\n      5.0\n      67939.0\n    \n    \n      16\n      16\n      5.2\n      66030.0\n    \n    \n      17\n      17\n      5.4\n      83089.0\n    \n    \n      18\n      18\n      6.0\n      81364.0\n    \n    \n      19\n      19\n      6.1\n      93941.0\n    \n    \n      20\n      20\n      6.9\n      91739.0\n    \n    \n      21\n      21\n      7.2\n      98274.0\n    \n    \n      22\n      22\n      8.0\n      101303.0\n    \n    \n      23\n      23\n      8.3\n      113813.0\n    \n    \n      24\n      24\n      8.8\n      109432.0\n    \n    \n      25\n      25\n      9.1\n      105583.0\n    \n    \n      26\n      26\n      9.6\n      116970.0\n    \n    \n      27\n      27\n      9.7\n      112636.0\n    \n    \n      28\n      28\n      10.4\n      122392.0\n    \n    \n      29\n      29\n      10.6\n      121873.0\n    \n  \n\n\n\n\n\nsalary.info()\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 30 entries, 0 to 29\nData columns (total 3 columns):\n #   Column           Non-Null Count  Dtype  \n---  ------           --------------  -----  \n 0   Unnamed: 0       30 non-null     int64  \n 1   YearsExperience  30 non-null     float64\n 2   Salary           30 non-null     float64\ndtypes: float64(2), int64(1)\nmemory usage: 848.0 bytes\n\n\n\n\n\nMelihat jumlah data null pada dataset\n\nsalary.isna().sum()\n\nUnnamed: 0         0\nYearsExperience    0\nSalary             0\ndtype: int64\n\n\nMelihat jumlah data duplikat pada dataset\n\nsalary.duplicated().sum()\n\n0\n\n\nMenghapus kolom ‘Unnamed :0’ dari DataFrame secara permanen\n\nsalary.drop('Unnamed: 0', axis=1, inplace=True)\n\n\nsalary\n\n\n\n\n\n  \n    \n      \n      YearsExperience\n      Salary\n    \n  \n  \n    \n      0\n      1.2\n      39344.0\n    \n    \n      1\n      1.4\n      46206.0\n    \n    \n      2\n      1.6\n      37732.0\n    \n    \n      3\n      2.1\n      43526.0\n    \n    \n      4\n      2.3\n      39892.0\n    \n    \n      5\n      3.0\n      56643.0\n    \n    \n      6\n      3.1\n      60151.0\n    \n    \n      7\n      3.3\n      54446.0\n    \n    \n      8\n      3.3\n      64446.0\n    \n    \n      9\n      3.8\n      57190.0\n    \n    \n      10\n      4.0\n      63219.0\n    \n    \n      11\n      4.1\n      55795.0\n    \n    \n      12\n      4.1\n      56958.0\n    \n    \n      13\n      4.2\n      57082.0\n    \n    \n      14\n      4.6\n      61112.0\n    \n    \n      15\n      5.0\n      67939.0\n    \n    \n      16\n      5.2\n      66030.0\n    \n    \n      17\n      5.4\n      83089.0\n    \n    \n      18\n      6.0\n      81364.0\n    \n    \n      19\n      6.1\n      93941.0\n    \n    \n      20\n      6.9\n      91739.0\n    \n    \n      21\n      7.2\n      98274.0\n    \n    \n      22\n      8.0\n      101303.0\n    \n    \n      23\n      8.3\n      113813.0\n    \n    \n      24\n      8.8\n      109432.0\n    \n    \n      25\n      9.1\n      105583.0\n    \n    \n      26\n      9.6\n      116970.0\n    \n    \n      27\n      9.7\n      112636.0\n    \n    \n      28\n      10.4\n      122392.0\n    \n    \n      29\n      10.6\n      121873.0\n    \n  \n\n\n\n\n\n\n\nMengubah setiap nilai di kolom Salary dan mengubah nama kolomnya di DataFrame secara permanen\n\nsalary['Salary'] = salary['Salary']/1000\nsalary.rename(columns={'Salary' : 'Salary (1000 $)'}, inplace=True)\n\nMelihat statistik deskriptif dari DataFrame\n\nsalary.describe()\n\n\n\n\n\n  \n    \n      \n      YearsExperience\n      Salary (1000 $)\n    \n  \n  \n    \n      count\n      30.000000\n      30.00000\n    \n    \n      mean\n      5.413333\n      76.00400\n    \n    \n      std\n      2.837888\n      27.41443\n    \n    \n      min\n      1.200000\n      37.73200\n    \n    \n      25%\n      3.300000\n      56.72175\n    \n    \n      50%\n      4.800000\n      65.23800\n    \n    \n      75%\n      7.800000\n      100.54575\n    \n    \n      max\n      10.600000\n      122.39200\n    \n  \n\n\n\n\n\nplt.scatter(salary['YearsExperience'],salary['Salary (1000 $)'])\nplt.plot(salary['YearsExperience'],salary['Salary (1000 $)'])\nplt.xlabel('Year Experience')\nplt.ylabel('Salary (1000 $)')\nplt.show()\n\n\n\n\n\nfig, (ax_box, ax_hist) = plt.subplots(2, 1, figsize=(6, 6), sharex='col',\n                                      gridspec_kw={\"height_ratios\": (.15, .85)})\n\nsns.boxplot(data=salary, x='Salary (1000 $)', ax=ax_box, color='crimson')\nsns.histplot(data=salary, x='Salary (1000 $)', ax=ax_hist, binwidth=10.)\nsns.rugplot(data=salary, x='Salary (1000 $)', ax=ax_hist, height=0.05, color='gold', lw=2.)\nplt.tight_layout()\n\n\n\n\n\nfig, (ax_box, ax_hist) = plt.subplots(2, 1, figsize=(6, 6), sharex='col',\n                                      gridspec_kw={\"height_ratios\": (.15, .85)})\n\nsns.boxplot(data=salary, x='YearsExperience', ax=ax_box, color='crimson')\nsns.histplot(data=salary, x='YearsExperience', ax=ax_hist, binwidth=1.)\nsns.rugplot(data=salary, x='YearsExperience', ax=ax_hist, height=0.05, color='gold', lw=2.)\nplt.tight_layout()\n\n\n\n\n\ncorr = salary.corr()\nsns.heatmap(corr, vmin=-1, center=0, vmax=1, annot=True)\nplt.show()\n\n\n\n\n\nplt.subplots(figsize=(6,6))\n\nsns.regplot(data = salary, x='YearsExperience', y='Salary (1000 $)', color='k', marker='+')\nplt.show()\n\n\n\n\n\n\n\nKarena pada dataset ini, fitur yang ada hanya 2, tidak ada masalah dan data sudah rapi, maka untuk step feature engineering akan skip dan lanjut ke tahap modelling.\n\n\n\n\nX = salary[['YearsExperience']]\ny = salary[['Salary (1000 $)']]\n\n\nX\n\n\n\n\n\n  \n    \n      \n      YearsExperience\n    \n  \n  \n    \n      0\n      1.2\n    \n    \n      1\n      1.4\n    \n    \n      2\n      1.6\n    \n    \n      3\n      2.1\n    \n    \n      4\n      2.3\n    \n    \n      5\n      3.0\n    \n    \n      6\n      3.1\n    \n    \n      7\n      3.3\n    \n    \n      8\n      3.3\n    \n    \n      9\n      3.8\n    \n    \n      10\n      4.0\n    \n    \n      11\n      4.1\n    \n    \n      12\n      4.1\n    \n    \n      13\n      4.2\n    \n    \n      14\n      4.6\n    \n    \n      15\n      5.0\n    \n    \n      16\n      5.2\n    \n    \n      17\n      5.4\n    \n    \n      18\n      6.0\n    \n    \n      19\n      6.1\n    \n    \n      20\n      6.9\n    \n    \n      21\n      7.2\n    \n    \n      22\n      8.0\n    \n    \n      23\n      8.3\n    \n    \n      24\n      8.8\n    \n    \n      25\n      9.1\n    \n    \n      26\n      9.6\n    \n    \n      27\n      9.7\n    \n    \n      28\n      10.4\n    \n    \n      29\n      10.6\n    \n  \n\n\n\n\n\ny\n\n\n\n\n\n  \n    \n      \n      Salary (1000 $)\n    \n  \n  \n    \n      0\n      39.344\n    \n    \n      1\n      46.206\n    \n    \n      2\n      37.732\n    \n    \n      3\n      43.526\n    \n    \n      4\n      39.892\n    \n    \n      5\n      56.643\n    \n    \n      6\n      60.151\n    \n    \n      7\n      54.446\n    \n    \n      8\n      64.446\n    \n    \n      9\n      57.190\n    \n    \n      10\n      63.219\n    \n    \n      11\n      55.795\n    \n    \n      12\n      56.958\n    \n    \n      13\n      57.082\n    \n    \n      14\n      61.112\n    \n    \n      15\n      67.939\n    \n    \n      16\n      66.030\n    \n    \n      17\n      83.089\n    \n    \n      18\n      81.364\n    \n    \n      19\n      93.941\n    \n    \n      20\n      91.739\n    \n    \n      21\n      98.274\n    \n    \n      22\n      101.303\n    \n    \n      23\n      113.813\n    \n    \n      24\n      109.432\n    \n    \n      25\n      105.583\n    \n    \n      26\n      116.970\n    \n    \n      27\n      112.636\n    \n    \n      28\n      122.392\n    \n    \n      29\n      121.873\n    \n  \n\n\n\n\nSplit dataset menjadi data train dan data test dengan komposisi pembagian yang sering digunakan\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size=0.2, random_state=42)\nX_train.shape, X_test.shape, y_train.shape, y_test.shape\n\n((24, 1), (6, 1), (24, 1), (6, 1))\n\n\nImport terlebih dahulu package yang akan digunakan untuk modelling\n\nfrom sklearn.linear_model import LinearRegression\nlr = LinearRegression()\nlr.fit(X_train,y_train)\n\nLinearRegression()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LinearRegressionLinearRegression()\n\n\n\ny_pred = lr.predict(X_test)\n\n\nfrom sklearn.metrics import mean_squared_error, r2_score\nprint(mean_squared_error(y_pred,y_test))\nprint(r2_score(y_pred,y_test))\n\n49.830096855908344\n0.8961838737587329\n\n\n \nDimana:\n\\(n\\) : jumlah data\n\\(Y_i\\) : nilai actual\n\\(\\hat{Y}_{i}\\): nilai predict\n\\(RSS\\) : sum of squared residuals\n\\(TSS\\) : total sum of squares\n\nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))\n\n[[115.79121011 112.636     ]\n [ 71.49927809  67.939     ]\n [102.59786866 113.813     ]\n [ 75.26880422  83.089     ]\n [ 55.47879205  64.446     ]\n [ 60.19069971  57.19      ]]\n\n\n\n\n\n\n\n\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\n\n\n\n\n\nheart = pd.read_csv('heart.csv')\nheart\n\n\n\n\n\n  \n    \n      \n      age\n      sex\n      cp\n      trtbps\n      chol\n      fbs\n      restecg\n      thalachh\n      exng\n      oldpeak\n      slp\n      caa\n      thall\n      output\n    \n  \n  \n    \n      0\n      63\n      1\n      3\n      145\n      233\n      1\n      0\n      150\n      0\n      2.3\n      0\n      0\n      1\n      1\n    \n    \n      1\n      37\n      1\n      2\n      130\n      250\n      0\n      1\n      187\n      0\n      3.5\n      0\n      0\n      2\n      1\n    \n    \n      2\n      41\n      0\n      1\n      130\n      204\n      0\n      0\n      172\n      0\n      1.4\n      2\n      0\n      2\n      1\n    \n    \n      3\n      56\n      1\n      1\n      120\n      236\n      0\n      1\n      178\n      0\n      0.8\n      2\n      0\n      2\n      1\n    \n    \n      4\n      57\n      0\n      0\n      120\n      354\n      0\n      1\n      163\n      1\n      0.6\n      2\n      0\n      2\n      1\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      298\n      57\n      0\n      0\n      140\n      241\n      0\n      1\n      123\n      1\n      0.2\n      1\n      0\n      3\n      0\n    \n    \n      299\n      45\n      1\n      3\n      110\n      264\n      0\n      1\n      132\n      0\n      1.2\n      1\n      0\n      3\n      0\n    \n    \n      300\n      68\n      1\n      0\n      144\n      193\n      1\n      1\n      141\n      0\n      3.4\n      1\n      2\n      3\n      0\n    \n    \n      301\n      57\n      1\n      0\n      130\n      131\n      0\n      1\n      115\n      1\n      1.2\n      1\n      1\n      3\n      0\n    \n    \n      302\n      57\n      0\n      1\n      130\n      236\n      0\n      0\n      174\n      0\n      0.0\n      1\n      1\n      2\n      0\n    \n  \n\n303 rows × 14 columns\n\n\n\n\n# Membaca .txt tentang kolom - kolom dataset yang diberikan pada soal\nwith open('about dataset.txt', 'r') as f:\n  print(f.read())\n\nAbout datasets\n1. age - age in years \n2. sex - sex (1 = male; 0 = female) \n3. cp - chest pain type (1 = typical angina; 2 = atypical angina; 3 = non-anginal pain; 0 = asymptomatic) \n4. trestbps - resting blood pressure (in mm Hg on admission to the hospital) \n5. chol - serum cholestoral in mg/dl \n6. fbs - fasting blood sugar > 120 mg/dl (1 = true; 0 = false) \n7. restecg - resting electrocardiographic results (1 = normal; 2 = having ST-T wave abnormality; 0 = hypertrophy) \n8. thalach - maximum heart rate achieved \n9. exang - exercise induced angina (1 = yes; 0 = no) \n10. oldpeak - ST depression induced by exercise relative to rest \n11. slope - the slope of the peak exercise ST segment (2 = upsloping; 1 = flat; 0 = downsloping) \n12. ca - number of major vessels (0-3) colored by flourosopy \n13. thal - 2 = normal; 1 = fixed defect; 3 = reversable defect \n14. output - the predicted attribute - diagnosis of heart disease (0 = less chance of heart attack, 1 = higher chance of heart attack)\n\n\n\n\nheart.info()\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 303 entries, 0 to 302\nData columns (total 14 columns):\n #   Column    Non-Null Count  Dtype  \n---  ------    --------------  -----  \n 0   age       303 non-null    int64  \n 1   sex       303 non-null    int64  \n 2   cp        303 non-null    int64  \n 3   trtbps    303 non-null    int64  \n 4   chol      303 non-null    int64  \n 5   fbs       303 non-null    int64  \n 6   restecg   303 non-null    int64  \n 7   thalachh  303 non-null    int64  \n 8   exng      303 non-null    int64  \n 9   oldpeak   303 non-null    float64\n 10  slp       303 non-null    int64  \n 11  caa       303 non-null    int64  \n 12  thall     303 non-null    int64  \n 13  output    303 non-null    int64  \ndtypes: float64(1), int64(13)\nmemory usage: 33.3 KB\n\n\n\nheart.output.value_counts()\n\n1    165\n0    138\nName: output, dtype: int64\n\n\n\n\n\n\nheart.describe()\n\n\n\n\n\n  \n    \n      \n      age\n      sex\n      cp\n      trtbps\n      chol\n      fbs\n      restecg\n      thalachh\n      exng\n      oldpeak\n      slp\n      caa\n      thall\n      output\n    \n  \n  \n    \n      count\n      303.000000\n      303.000000\n      303.000000\n      303.000000\n      303.000000\n      303.000000\n      303.000000\n      303.000000\n      303.000000\n      303.000000\n      303.000000\n      303.000000\n      303.000000\n      303.000000\n    \n    \n      mean\n      54.366337\n      0.683168\n      0.966997\n      131.623762\n      246.264026\n      0.148515\n      0.528053\n      149.646865\n      0.326733\n      1.039604\n      1.399340\n      0.729373\n      2.313531\n      0.544554\n    \n    \n      std\n      9.082101\n      0.466011\n      1.032052\n      17.538143\n      51.830751\n      0.356198\n      0.525860\n      22.905161\n      0.469794\n      1.161075\n      0.616226\n      1.022606\n      0.612277\n      0.498835\n    \n    \n      min\n      29.000000\n      0.000000\n      0.000000\n      94.000000\n      126.000000\n      0.000000\n      0.000000\n      71.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n    \n    \n      25%\n      47.500000\n      0.000000\n      0.000000\n      120.000000\n      211.000000\n      0.000000\n      0.000000\n      133.500000\n      0.000000\n      0.000000\n      1.000000\n      0.000000\n      2.000000\n      0.000000\n    \n    \n      50%\n      55.000000\n      1.000000\n      1.000000\n      130.000000\n      240.000000\n      0.000000\n      1.000000\n      153.000000\n      0.000000\n      0.800000\n      1.000000\n      0.000000\n      2.000000\n      1.000000\n    \n    \n      75%\n      61.000000\n      1.000000\n      2.000000\n      140.000000\n      274.500000\n      0.000000\n      1.000000\n      166.000000\n      1.000000\n      1.600000\n      2.000000\n      1.000000\n      3.000000\n      1.000000\n    \n    \n      max\n      77.000000\n      1.000000\n      3.000000\n      200.000000\n      564.000000\n      1.000000\n      2.000000\n      202.000000\n      1.000000\n      6.200000\n      2.000000\n      4.000000\n      3.000000\n      1.000000\n    \n  \n\n\n\n\n\npd.plotting.scatter_matrix(heart[['age', 'trtbps', 'chol', 'thalachh', 'oldpeak']], figsize=(15,12)) # plot data yang numerik dan kontinu\nplt.show()\n\n\n\n\nPlot diatas saya ingin melihat korelasi secara kasar antara fitur - fitur yang numerik dan kontinu, melalui scatter plot, serta range nilai datanya melalui histogramnya.\nMelalui scatter plot dapat kita lihat bahwa kita belum bisa menyimpulkan korelasi antara fitur - fitur, karena persebarannya sebagian besar sangat acak. Melalui histogram dapat dilihat bahwa range nilainya cukup berjauhan (oldpeak 0 sampai 6, sedangkan chol 100 sampai 500+), sehingga perlu dilakukan standarisasi pada data numerik nantinya dengan StandardScaler\n\ncorr = heart.corr()\nplt.subplots(figsize=(10,10))\nsns.heatmap(corr, vmin=-1, center=0, vmax=1, annot=True)\nplt.show()\n\n\n\n\n\n\n\n\nX = heart.drop('output',axis=1).copy()\ny = heart.iloc[:,[-1]]\n\n\nX\n\n\n\n\n\n  \n    \n      \n      age\n      sex\n      cp\n      trtbps\n      chol\n      fbs\n      restecg\n      thalachh\n      exng\n      oldpeak\n      slp\n      caa\n      thall\n    \n  \n  \n    \n      0\n      63\n      1\n      3\n      145\n      233\n      1\n      0\n      150\n      0\n      2.3\n      0\n      0\n      1\n    \n    \n      1\n      37\n      1\n      2\n      130\n      250\n      0\n      1\n      187\n      0\n      3.5\n      0\n      0\n      2\n    \n    \n      2\n      41\n      0\n      1\n      130\n      204\n      0\n      0\n      172\n      0\n      1.4\n      2\n      0\n      2\n    \n    \n      3\n      56\n      1\n      1\n      120\n      236\n      0\n      1\n      178\n      0\n      0.8\n      2\n      0\n      2\n    \n    \n      4\n      57\n      0\n      0\n      120\n      354\n      0\n      1\n      163\n      1\n      0.6\n      2\n      0\n      2\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      298\n      57\n      0\n      0\n      140\n      241\n      0\n      1\n      123\n      1\n      0.2\n      1\n      0\n      3\n    \n    \n      299\n      45\n      1\n      3\n      110\n      264\n      0\n      1\n      132\n      0\n      1.2\n      1\n      0\n      3\n    \n    \n      300\n      68\n      1\n      0\n      144\n      193\n      1\n      1\n      141\n      0\n      3.4\n      1\n      2\n      3\n    \n    \n      301\n      57\n      1\n      0\n      130\n      131\n      0\n      1\n      115\n      1\n      1.2\n      1\n      1\n      3\n    \n    \n      302\n      57\n      0\n      1\n      130\n      236\n      0\n      0\n      174\n      0\n      0.0\n      1\n      1\n      2\n    \n  \n\n303 rows × 13 columns\n\n\n\n\ny\n\n\n\n\n\n  \n    \n      \n      output\n    \n  \n  \n    \n      0\n      1\n    \n    \n      1\n      1\n    \n    \n      2\n      1\n    \n    \n      3\n      1\n    \n    \n      4\n      1\n    \n    \n      ...\n      ...\n    \n    \n      298\n      0\n    \n    \n      299\n      0\n    \n    \n      300\n      0\n    \n    \n      301\n      0\n    \n    \n      302\n      0\n    \n  \n\n303 rows × 1 columns\n\n\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n\nheart.columns\n\nIndex(['age', 'sex', 'cp', 'trtbps', 'chol', 'fbs', 'restecg', 'thalachh',\n       'exng', 'oldpeak', 'slp', 'caa', 'thall', 'output'],\n      dtype='object')\n\n\n\nsc = StandardScaler()\ncol = ['age', 'trtbps', 'chol', 'thalachh', 'oldpeak']\nX_train.loc[:,col] = sc.fit_transform(X_train.loc[:,col])\n\n\nX_train\n\n\n\n\n\n  \n    \n      \n      age\n      sex\n      cp\n      trtbps\n      chol\n      fbs\n      restecg\n      thalachh\n      exng\n      oldpeak\n      slp\n      caa\n      thall\n    \n  \n  \n    \n      132\n      -1.356798\n      1\n      1\n      -0.616856\n      0.914034\n      0\n      1\n      0.532781\n      0\n      -0.920864\n      2\n      0\n      2\n    \n    \n      202\n      0.385086\n      1\n      0\n      1.169491\n      0.439527\n      0\n      0\n      -1.753582\n      1\n      -0.193787\n      2\n      0\n      3\n    \n    \n      196\n      -0.921327\n      1\n      2\n      1.169491\n      -0.300704\n      0\n      1\n      -0.139679\n      0\n      2.350982\n      1\n      0\n      2\n    \n    \n      75\n      0.058483\n      0\n      1\n      0.276318\n      0.059921\n      0\n      0\n      0.487950\n      0\n      0.351521\n      1\n      0\n      2\n    \n    \n      176\n      0.602822\n      1\n      0\n      -0.795490\n      -0.319684\n      1\n      1\n      0.443119\n      1\n      0.351521\n      2\n      2\n      3\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      188\n      -0.485856\n      1\n      2\n      0.574042\n      -0.262744\n      0\n      1\n      0.577611\n      0\n      -0.375556\n      1\n      1\n      3\n    \n    \n      71\n      -0.376988\n      1\n      2\n      -2.165023\n      -0.376625\n      0\n      1\n      0.174136\n      1\n      -0.920864\n      2\n      1\n      3\n    \n    \n      106\n      1.582631\n      1\n      3\n      1.764940\n      -0.243763\n      1\n      0\n      -0.856969\n      0\n      -0.829979\n      1\n      1\n      2\n    \n    \n      270\n      -0.921327\n      1\n      0\n      -0.616856\n      0.040941\n      0\n      0\n      -0.274171\n      0\n      -0.193787\n      2\n      0\n      3\n    \n    \n      102\n      0.929425\n      0\n      1\n      0.574042\n      -0.983994\n      0\n      1\n      1.294902\n      0\n      -0.920864\n      2\n      2\n      2\n    \n  \n\n242 rows × 13 columns\n\n\n\n\nX_test.loc[:,col] = sc.transform(X_test.loc[:,col])\nX_test\n\n\n\n\n\n  \n    \n      \n      age\n      sex\n      cp\n      trtbps\n      chol\n      fbs\n      restecg\n      thalachh\n      exng\n      oldpeak\n      slp\n      caa\n      thall\n    \n  \n  \n    \n      179\n      0.276218\n      1\n      0\n      1.169491\n      0.553408\n      0\n      0\n      -1.708752\n      1\n      -0.375556\n      1\n      1\n      1\n    \n    \n      228\n      0.493954\n      1\n      3\n      2.360389\n      0.781172\n      0\n      0\n      0.398289\n      0\n      -0.739095\n      1\n      0\n      3\n    \n    \n      111\n      0.276218\n      1\n      2\n      1.169491\n      -2.293633\n      1\n      1\n      1.025918\n      0\n      -0.739095\n      2\n      1\n      3\n    \n    \n      246\n      0.167350\n      0\n      0\n      0.216773\n      3.077785\n      0\n      0\n      -0.005187\n      1\n      0.805944\n      1\n      2\n      3\n    \n    \n      60\n      1.800367\n      0\n      2\n      -1.212304\n      0.344625\n      1\n      0\n      -0.901800\n      0\n      -0.920864\n      2\n      1\n      2\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      249\n      1.582631\n      1\n      2\n      0.574042\n      0.135842\n      0\n      0\n      -0.184510\n      0\n      0.896828\n      1\n      3\n      3\n    \n    \n      104\n      -0.485856\n      1\n      2\n      -0.080952\n      -0.965014\n      0\n      1\n      0.577611\n      0\n      -0.920864\n      2\n      0\n      2\n    \n    \n      300\n      1.473764\n      1\n      0\n      0.812222\n      -1.021955\n      1\n      1\n      -0.408663\n      0\n      2.169213\n      1\n      2\n      3\n    \n    \n      193\n      0.602822\n      1\n      0\n      0.871767\n      0.667290\n      0\n      0\n      -0.363832\n      1\n      1.623905\n      1\n      2\n      3\n    \n    \n      184\n      -0.485856\n      1\n      0\n      1.169491\n      -0.072941\n      0\n      0\n      -0.991461\n      0\n      1.442136\n      1\n      0\n      3\n    \n  \n\n61 rows × 13 columns\n\n\n\n\n\n\n\nlog_regr = LogisticRegression()\nsvc = SVC()\ndt = DecisionTreeClassifier()\nrf = RandomForestClassifier()\n\n\nkfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n# melakukan cross validation pada masing-masing metode\nlr_score = cross_val_score(log_regr, X_train, y_train, cv=kfold, scoring='f1').mean()\nsvc_score = cross_val_score(svc, X_train, y_train, cv=kfold, scoring='f1').mean()\ndt_score = cross_val_score(dt, X_train, y_train, cv=kfold, scoring='f1').mean()\nrf_score = cross_val_score(rf, X_train, y_train, cv=kfold, scoring='f1').mean()\n\n\nfor i in [lr_score, svc_score, dt_score, rf_score]:\n    print(i)\n\n0.838821143443002\n0.8530945548368415\n0.7278904812545365\n0.8365591551305837\n\n\n\n\n\n\nparams = {'C':[0.01,0.05,0.1,0.7,0.5,1,5,10,50,100],     # hyperparameter yang akan dievaluasi untuk SVC\n             'kernel':['poly','rbf']}\n\ngrid_search = GridSearchCV(svc, params, cv=kfold, scoring='f1')\ngrid_search.fit(X_train,y_train)\n\n\ngrid_search.best_params_, grid_search.cv_results_['mean_test_score'].max()\n\n({'C': 0.7, 'kernel': 'rbf'}, 0.8596614105205573)\n\n\n\nmodel = grid_search.best_estimator_\nmodel.fit(X_train,y_train)\n\nC:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n\n\nSVC(C=0.7)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.SVCSVC(C=0.7)\n\n\n\ny_pred = model.predict(X_test)\ny_pred\n\narray([0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0,\n       0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0], dtype=int64)\n\n\n\n\n\n\nf1_score(y_test,y_pred)\n\n0.8923076923076922\n\n\n\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n\ndef evaluation_parametrics(name,y_val, y_pred):\n    \n    print(\"\\n------------------------{}------------------------\\n\".format(name))\n\n    cm_test = confusion_matrix(y_val, y_pred)\n    t1 = ConfusionMatrixDisplay(cm_test)    \n    print(\"\\nClassification Report for Data Test\\n\")\n    print(classification_report(y_val, y_pred))   \n    print(\"--------------------------------------------------------------------------\")\n\n    t1.plot()\n\n\nevaluation_parametrics(\"Machine Learning - Classification\", y_test, y_pred)\n\n\n------------------------Machine Learning - Classification------------------------\n\n\nClassification Report for Data Test\n\n              precision    recall  f1-score   support\n\n           0       0.89      0.86      0.88        29\n           1       0.88      0.91      0.89        32\n\n    accuracy                           0.89        61\n   macro avg       0.89      0.88      0.88        61\nweighted avg       0.89      0.89      0.89        61\n\n--------------------------------------------------------------------------\n\n\n\n\n\n\n\n\nimage.png\n\n\nPerbandingan data actual dan data prediksi\n\nprint(np.concatenate((y_test.values.reshape(len(y_test),1),y_pred.reshape(len(y_pred),1)),1))\n\n[[0 0]\n [0 1]\n [1 1]\n [0 0]\n [1 1]\n [1 1]\n [1 1]\n [0 0]\n [0 0]\n [1 1]\n [1 1]\n [1 0]\n [1 1]\n [0 0]\n [1 1]\n [1 1]\n [1 1]\n [0 0]\n [0 0]\n [0 0]\n [1 1]\n [0 0]\n [0 0]\n [1 1]\n [1 1]\n [0 1]\n [0 1]\n [1 1]\n [0 0]\n [1 1]\n [1 0]\n [0 0]\n [0 0]\n [1 0]\n [1 1]\n [0 0]\n [1 1]\n [1 1]\n [1 1]\n [1 1]\n [1 1]\n [1 1]\n [1 1]\n [1 1]\n [1 1]\n [0 0]\n [0 1]\n [1 1]\n [0 0]\n [0 0]\n [0 0]\n [0 0]\n [1 1]\n [1 1]\n [0 0]\n [0 0]\n [0 0]\n [1 1]\n [0 0]\n [0 0]\n [0 0]]\n\n\n\n\n\n\nfrom sklearn.inspection import permutation_importance\nresult = permutation_importance(model, X_test, y_test, n_repeats=10,\n                                scoring='f1', random_state=42)\n\n\nresult_sorted = []\ncolumns_sorted = []\n\nfor res, col in sorted(zip(result.importances_mean, X_test.columns.values), reverse=True):\n  result_sorted.append(res)\n  columns_sorted.append(col)\n\nsns.barplot(x = result_sorted, y = columns_sorted)\nplt.show()\n\n\n\n\n\n\n\nSimpan model ke dalam file dan model siap digunakan untuk predict\n\nimport joblib\njoblib.dump(model,'model_SVC.pkl')\n\n['model_SVC.pkl']"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/module-tahun-lalu.html",
    "href": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/module-tahun-lalu.html",
    "title": "Lab Praktikum Departemen Matematika FMIPA UI",
    "section": "",
    "text": "Module 2021/2022\nKembali ke Sains Data\nberikut ini adalah module pengajaran sains-data tahun 2021/2022. https://drive.google.com/open?id=1x2SR_L3pWH0W8Z0IUbL1ifBOcMSkWVYe"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-05.html",
    "href": "semuahalaman/modulprak/2023/genap/sainsdata/main-module/week-05.html",
    "title": "Lab Praktikum Departemen Matematika FMIPA UI",
    "section": "",
    "text": "Kembali ke Sains Data\n\nTensorFlow: Python-based, free, open source machine learning platform developed by Google that enables manipulation of mathematical expressions over numerical tensors, computes gradients automatically, supports CPUs, GPUs, TPUs, allows easy distribution of computation across machines, and can be exported to other runtimes for easy deployment in practical settings.\nKeras: a deep learning API for Python, built on top of TensorFlow, known for its convenient model definition and training, initially developed for research with fast experimentation, and can run on various hardware types, including GPU, TPU, and CPU, and scale to multiple machines seamlessly while prioritizing developer experience.\n\n\n\n\n\n# !pip install tensorflow # uncomment if you don't have tensorflow installed\nimport tensorflow as tf\nimport tensorflow.keras as keras\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\n\n\n\n# All-ones or all-zeros tensors\n\nx = tf.ones(shape = (2,1)) # 2x3 matrix of ones, similar to np.ones((2,1))\nprint(x)\n\nx = tf.zeros(shape = (2,1)) # 2x3 matrix of zeros, similar to np.zeros((2,1))\nprint(x)\n\n\ntf.Tensor(\n[[1.]\n [1.]], shape=(2, 1), dtype=float32)\ntf.Tensor(\n[[0.]\n [0.]], shape=(2, 1), dtype=float32)\n\n\n\nx.__class__\n\ntensorflow.python.framework.ops.EagerTensor\n\n\n\n# Random tensors\n\n# create a tensor with random values from a normal distribution\nx = tf.random.normal(shape = (2,3), mean = 0, stddev = 1)\nprint(x)\n\n# create a tensor with random values from a uniform distribution\nx = tf.random.uniform(shape = (2,3), minval = 0, maxval = 1)\nprint(x)\n\ntf.Tensor(\n[[ 0.63700163  1.8413717   0.12851602]\n [-1.0153099  -1.3446143   1.6644784 ]], shape=(2, 3), dtype=float32)\ntf.Tensor(\n[[0.838336   0.8172778  0.42057896]\n [0.21810079 0.07237494 0.9222772 ]], shape=(2, 3), dtype=float32)\n\n\n\n# numpy array are assignable while tensors are not\nx = np.random.normal(loc = 0, scale = 1, size = (2,3))\nx[0,0] = 100\nprint(x)\n\n[[ 1.00000000e+02 -1.25304057e+00 -1.18967720e+00]\n [ 4.74877369e-01 -8.13430401e-02 -4.57822064e-01]]\n\n\n\n# numpy array are assignable while tensors are not\nx = tf.ones(shape = (2,3))\nx[0,0] = 100\nprint(x)\n\nTypeError: 'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment\n\n\n\n# Creating a TensorFlow variable\nv = tf.Variable(initial_value = tf.random.normal(shape = (2,3)))\nprint(v)\nprint()\n\nv.assign(tf.zeros(shape = (2,3)))\nprint(v)\n\n<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\narray([[-0.10799041,  2.325188  , -0.20042379],\n       [ 0.48759696,  0.53195345,  0.29525948]], dtype=float32)>\n\n<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\narray([[0., 0., 0.],\n       [0., 0., 0.]], dtype=float32)>\n\n\n\n# Assigning a value to a subset of a TensorFlow variable\nv[0,0].assign(100)\nprint(v)\n\n<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\narray([[100.,   0.,   0.],\n       [  0.,   0.,   0.]], dtype=float32)>\n\n\n\n# adding to the current value\nv.assign_add(tf.ones(shape = (2,3)))\nprint(v)\n\n<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\narray([[101.,   1.,   1.],\n       [  1.,   1.,   1.]], dtype=float32)>\n\n\n\n# just like numpy, TensorFlow offers a large collection of tensor operations to express\n# mathematical formulas.\na = tf.ones((2, 2))\nb = tf.square(a)\nc = tf.sqrt(a)\nd = b + c\ne = tf.matmul(a, b)\ne *= d\nprint(e)\n\ntf.Tensor(\n[[4. 4.]\n [4. 4.]], shape=(2, 2), dtype=float32)\n\n\nSo far, TensorFlow seems to look a lot like NumPy. But here’s something NumPy can’t do: retrieve the gradient of any differentiable expression with respect to any of its inputs. Just open a GradientTape scope, apply some computation to one or several input tensors, and retrieve the gradient of the result with respect to the inputs\n\n# Using the GradientTape\ninput_var = tf.Variable(initial_value = 3.0)\nwith tf.GradientTape() as tape:\n    result = tf.square(input_var)\ngrad = tape.gradient(result, input_var)\nprint(grad)\n\ntf.Tensor(6.0, shape=(), dtype=float32)\n\n\n\n# Using GradientTape with constant tensor inputs\ninput_var = tf.constant(3.0)\nwith tf.GradientTape() as tape:\n    tape.watch(input_var)\n    result = tf.square(input_var)\ngrad = tape.gradient(result, input_var)\nprint(grad)\n\ntf.Tensor(6.0, shape=(), dtype=float32)\n\n\n\n# Using nested gradient tapes to compute second-order gradients\ntime = tf.Variable(0.0)\nwith tf.GradientTape() as outer_tape:\n    with tf.GradientTape() as inner_tape:\n        position = 4.9 * time ** 2\n    speed = inner_tape.gradient(position, time) \nacceleration = outer_tape.gradient(speed, time)\n\nprint(speed)\nprint(acceleration)\n\n\ntf.Tensor(0.0, shape=(), dtype=float32)\ntf.Tensor(9.8, shape=(), dtype=float32)\n\n\n\n\n\n\n# Generating two classes of random points in a 2D plane\nnum_samples_per_class, num_classes = 1000, 2\nnegative_samples = np.random.multivariate_normal(mean = [0,3], cov = [[1,0.5],[0.5,1]], size = num_samples_per_class)\npositive_samples = np.random.multivariate_normal(mean = [3,0], cov = [[1,0.5],[0.5,1]], size = num_samples_per_class)\n\ninputs = np.vstack((negative_samples, positive_samples)).astype(np.float32)\ntargets = np.vstack((np.zeros((num_samples_per_class, 1), dtype = 'float32'), np.ones((num_samples_per_class, 1), dtype = 'float32')))\n\n\nimport matplotlib.pyplot as plt\nplt.scatter(inputs[:, 0], inputs[:, 1], c=targets[:, 0])\nplt.show()\n\n\n\n\n\n# Creating the linear classifier variables\ninput_dim = 2\noutput_dim = 1\nW = tf.Variable(tf.random.normal(shape = (input_dim, output_dim)))\nb = tf.Variable(tf.random.normal(shape = (output_dim,)))\n\n\n\n# the forward pass\ndef model(inputs):\n    return tf.sigmoid(tf.matmul(inputs, W) + b)\n    \n# The mean squared error loss function\n\ndef entropy_loss(targets, predictions):\n    per_sample_losses = - targets * tf.math.log(predictions) - (1 - targets) * tf.math.log(1 - predictions)\n    return tf.reduce_mean(per_sample_losses)\n\n\n# training step \nlearning_rate = 0.1\ndef training_step(inputs, targets):\n    with tf.GradientTape() as tape:\n        predictions = model(inputs)\n        loss = square_loss(targets, predictions)\n        grad_loss_wrt_W, grad_loss_wrt_b = tape.gradient(loss, [W, b])\n        W.assign_sub(learning_rate * grad_loss_wrt_W)\n        b.assign_sub(learning_rate * grad_loss_wrt_b)\n        return loss\n\n\n\n\n\n# training loop/process/epoch\nfor step in range(100):\n    loss = training_step(inputs, targets)\n    print(f\"Loss at step {step}: {loss:.4f}\")\n\nLoss at step 0: 0.0495\nLoss at step 1: 0.0473\nLoss at step 2: 0.0454\nLoss at step 3: 0.0436\nLoss at step 4: 0.0420\nLoss at step 5: 0.0406\nLoss at step 6: 0.0392\nLoss at step 7: 0.0380\nLoss at step 8: 0.0369\nLoss at step 9: 0.0358\nLoss at step 10: 0.0348\nLoss at step 11: 0.0339\nLoss at step 12: 0.0330\nLoss at step 13: 0.0322\nLoss at step 14: 0.0315\nLoss at step 15: 0.0308\nLoss at step 16: 0.0301\nLoss at step 17: 0.0295\nLoss at step 18: 0.0289\nLoss at step 19: 0.0283\nLoss at step 20: 0.0278\nLoss at step 21: 0.0273\nLoss at step 22: 0.0268\nLoss at step 23: 0.0263\nLoss at step 24: 0.0259\nLoss at step 25: 0.0255\nLoss at step 26: 0.0251\nLoss at step 27: 0.0247\nLoss at step 28: 0.0243\nLoss at step 29: 0.0240\nLoss at step 30: 0.0236\nLoss at step 31: 0.0233\nLoss at step 32: 0.0230\nLoss at step 33: 0.0227\nLoss at step 34: 0.0224\nLoss at step 35: 0.0221\nLoss at step 36: 0.0218\nLoss at step 37: 0.0215\nLoss at step 38: 0.0213\nLoss at step 39: 0.0210\nLoss at step 40: 0.0208\nLoss at step 41: 0.0205\nLoss at step 42: 0.0203\nLoss at step 43: 0.0201\nLoss at step 44: 0.0198\nLoss at step 45: 0.0196\nLoss at step 46: 0.0194\nLoss at step 47: 0.0192\nLoss at step 48: 0.0190\nLoss at step 49: 0.0188\nLoss at step 50: 0.0186\nLoss at step 51: 0.0185\nLoss at step 52: 0.0183\nLoss at step 53: 0.0181\nLoss at step 54: 0.0179\nLoss at step 55: 0.0178\nLoss at step 56: 0.0176\nLoss at step 57: 0.0174\nLoss at step 58: 0.0173\nLoss at step 59: 0.0171\nLoss at step 60: 0.0170\nLoss at step 61: 0.0168\nLoss at step 62: 0.0167\nLoss at step 63: 0.0166\nLoss at step 64: 0.0164\nLoss at step 65: 0.0163\nLoss at step 66: 0.0162\nLoss at step 67: 0.0160\nLoss at step 68: 0.0159\nLoss at step 69: 0.0158\nLoss at step 70: 0.0157\nLoss at step 71: 0.0155\nLoss at step 72: 0.0154\nLoss at step 73: 0.0153\nLoss at step 74: 0.0152\nLoss at step 75: 0.0151\nLoss at step 76: 0.0150\nLoss at step 77: 0.0149\nLoss at step 78: 0.0148\nLoss at step 79: 0.0147\nLoss at step 80: 0.0146\nLoss at step 81: 0.0145\nLoss at step 82: 0.0144\nLoss at step 83: 0.0143\nLoss at step 84: 0.0142\nLoss at step 85: 0.0141\nLoss at step 86: 0.0140\nLoss at step 87: 0.0139\nLoss at step 88: 0.0138\nLoss at step 89: 0.0137\nLoss at step 90: 0.0136\nLoss at step 91: 0.0135\nLoss at step 92: 0.0135\nLoss at step 93: 0.0134\nLoss at step 94: 0.0133\nLoss at step 95: 0.0132\nLoss at step 96: 0.0131\nLoss at step 97: 0.0131\nLoss at step 98: 0.0130\nLoss at step 99: 0.0129\n\n\n\npredictions = model(inputs)\nprint(predictions)\nplt.scatter(inputs[:, 0], inputs[:, 1], c=predictions[:, 0] > 0.5)\nplt.show()\n\ntf.Tensor(\n[[0.04117302]\n [0.02456259]\n [0.00931301]\n ...\n [0.9823857 ]\n [0.9144001 ]\n [0.98359877]], shape=(2000, 1), dtype=float32)\n\n\n\n\n\n\n\n\nSo, the APIs that we will often use when building a neural network in Keras are keras.layers and keras.models.\nSimply put, each keras.layers is responsible for data processing (taking input and producing output), while keras.models is the API for connecting one keras.layers to another.\n\n# Using the Keras Sequential API to build a linear classifier\nmodel = keras.Sequential([\n    keras.layers.InputLayer(input_shape  = (2,)), # input layers (stateless layer)\n    keras.layers.Dense(units = 10, activation = 'relu'), # FC  layer (stateful layer)\n    keras.layers.Dense(units = 1, activation = 'sigmoid'), # FC layer (stateful layer)\n])\n\n\n\n# plotting the model\nkeras.utils.plot_model(model, show_shapes = True, show_layer_names = True, rankdir = 'TB', expand_nested = False, dpi = 96)\n\n\n\n\nOnce the model architecture is defined, you still have to choose three more things:\n\nLoss function (objective function)—The quantity that will be minimized during training. It represents a measure of success for the task at hand\nOptimizer—Determines how the network will be updated based on the loss function. It implements a specific variant of stochastic gradient descent (SGD).\nMetrics—The measures of success you want to monitor during training and validation, such as classification accuracy. Unlike the loss, training will not optimize directly for these metrics. As such, metrics don’t need to be differentiable.\n\nOnce you’ve picked your loss, optimizer, and metrics, you can use the built-in compile() and fit() methods to start training your model.\nThe compile() method configures the training process\n\n# we can pass strings to the loss and metrics arguments\nmodel.compile(optimizer=\"rmsprop\",\n              loss=\"sparse_binary_crossentropy\",\n              metrics=[\"accuracy\"])\n\n# or we can pass loss and metrics objects (both produce the same result)\nmodel.compile(optimizer=keras.optimizers.RMSprop(),\n              loss=keras.losses.BinaryCrossentropy(),\n              metrics=[keras.metrics.BinaryAccuracy()])\n\n\n# benefit of using objects is that we can configure them\n# dont run this code\n\nclass my_custom_loss(keras.losses.Loss):\n    pass\n\nclass my_custom_metric_1(keras.metrics.Metric):\n    pass\n\nclass my_custom_metric_2(keras.metrics.Metric):\n    pass \n\nmodel.compile(optimizer=keras.optimizers.RMSprop(learning_rate=1e-4),\n              loss=my_custom_loss,\n              metrics=[my_custom_metric_1, my_custom_metric_2]\n)\n\nThe built-in loss functions and metrics can be found in keras.losses and keras.metrics documentation.\nAfter compile(), the next method is fit(), which implements the training loop itself. The key arguments of fit() include the data to train on, which is typically passed as NumPy arrays or a TensorFlow Dataset object. The number of epochs to train for is also specified, indicating how many times the training loop should iterate over the passed data. Additionally, the batch size to use within each epoch of mini-batch gradient descent is specified, indicating the number of training examples considered to compute the gradients for one weight update step.\nThe fit() method returns a History object, which contains a record of the loss and metric values observed during training. This record is stored as a dictionary, with keys being the name of the metrics and values being a list of values recorded at each epoch.\n\nmodel.compile(optimizer=\"rmsprop\",\n              loss=\"binary_crossentropy\",\n              metrics=[\"accuracy\"])\n\n\nx_train = inputs\ny_train = targets\nhistory = model.fit(x_train, y_train, batch_size=64, epochs=3, validation_split=0.2)\n\nEpoch 1/3\n25/25 [==============================] - 1s 17ms/step - loss: 0.1882 - accuracy: 0.9937 - val_loss: 0.2297 - val_accuracy: 0.9825\nEpoch 2/3\n25/25 [==============================] - 0s 5ms/step - loss: 0.1431 - accuracy: 0.9956 - val_loss: 0.1806 - val_accuracy: 0.9875\nEpoch 3/3\n25/25 [==============================] - 0s 5ms/step - loss: 0.1119 - accuracy: 0.9969 - val_loss: 0.1423 - val_accuracy: 0.9875\n\n\n\nhistory.history\n\n# plotting the loss and accuracy curves\nplt.plot(history.history['loss'], label = 'training loss')\nplt.plot(history.history['val_loss'], label = 'validation loss')\nplt.legend()\n\n<matplotlib.legend.Legend at 0x1a6347daf50>\n\n\n\n\n\n\n\n\ninstead of using model(new_data) to make predictions, we use model.predict(new_data) to make predictions on new data.\n\nnew_inputs = np.random.uniform(low = -1, high = 3, size = (256, 2))\npredictions = model.predict(new_inputs, batch_size=128)\n\n2/2 [==============================] - 0s 5ms/step\n\n\n\nprint(predictions)\n\n[[0.08076628]\n [0.09871415]\n [0.461069  ]\n [0.1276516 ]\n [0.4253592 ]\n [0.11114225]\n [0.25637963]\n [0.6989103 ]\n [0.30173382]\n [0.9123289 ]\n [0.2240395 ]\n [0.86962867]\n [0.2930864 ]\n [0.7623196 ]\n [0.8919245 ]\n [0.85015684]\n [0.9198693 ]\n [0.3118358 ]\n [0.29436693]\n [0.41225567]\n [0.62281114]\n [0.20957854]\n [0.2546269 ]\n [0.14533882]\n [0.39954668]\n [0.72597396]\n [0.72029203]\n [0.14848693]\n [0.89544886]\n [0.23350693]\n [0.13677543]\n [0.6027528 ]\n [0.04975716]\n [0.62043774]\n [0.12495781]\n [0.41638136]\n [0.40849304]\n [0.75599575]\n [0.10711117]\n [0.7210298 ]\n [0.16202773]\n [0.58192235]\n [0.08633437]\n [0.652066  ]\n [0.2231856 ]\n [0.24822547]\n [0.12730986]\n [0.29572365]\n [0.49881336]\n [0.26938245]\n [0.38568485]\n [0.541473  ]\n [0.36511543]\n [0.8816863 ]\n [0.19856545]\n [0.16809542]\n [0.6914996 ]\n [0.8430513 ]\n [0.63214254]\n [0.58684945]\n [0.39648739]\n [0.53129727]\n [0.28006184]\n [0.08559055]\n [0.59670126]\n [0.59945154]\n [0.14749527]\n [0.06490649]\n [0.8320455 ]\n [0.05914058]\n [0.3041497 ]\n [0.09569068]\n [0.6649947 ]\n [0.94342   ]\n [0.09614404]\n [0.3644968 ]\n [0.14465587]\n [0.26501516]\n [0.9422459 ]\n [0.65699536]\n [0.43875617]\n [0.8261676 ]\n [0.3133958 ]\n [0.08528826]\n [0.8137045 ]\n [0.39755583]\n [0.7245124 ]\n [0.8646786 ]\n [0.45526022]\n [0.1089195 ]\n [0.8604254 ]\n [0.1271291 ]\n [0.79923344]\n [0.567212  ]\n [0.6395396 ]\n [0.21270584]\n [0.31966135]\n [0.7625292 ]\n [0.08406034]\n [0.19414133]\n [0.08797505]\n [0.7415017 ]\n [0.22738719]\n [0.10201294]\n [0.59394836]\n [0.15788662]\n [0.17561007]\n [0.49508384]\n [0.5141838 ]\n [0.23656489]\n [0.06821493]\n [0.64166445]\n [0.64123726]\n [0.1364974 ]\n [0.48136458]\n [0.23007919]\n [0.4225439 ]\n [0.09589957]\n [0.59364146]\n [0.11582101]\n [0.6668776 ]\n [0.4442284 ]\n [0.55769634]\n [0.2534748 ]\n [0.16375524]\n [0.614452  ]\n [0.30898425]\n [0.17131504]\n [0.26918182]\n [0.7705017 ]\n [0.17490432]\n [0.8457906 ]\n [0.10823403]\n [0.6434072 ]\n [0.49629235]\n [0.74100196]\n [0.1309076 ]\n [0.51234263]\n [0.24122484]\n [0.28107983]\n [0.48853737]\n [0.5556593 ]\n [0.20772368]\n [0.14975631]\n [0.81019986]\n [0.66698325]\n [0.24100578]\n [0.05778646]\n [0.3698141 ]\n [0.91120934]\n [0.13073047]\n [0.8811323 ]\n [0.39972985]\n [0.85394675]\n [0.66812456]\n [0.48931998]\n [0.4537211 ]\n [0.24272834]\n [0.46721923]\n [0.18894011]\n [0.15586214]\n [0.9342805 ]\n [0.30149692]\n [0.4530156 ]\n [0.15281224]\n [0.934635  ]\n [0.3286551 ]\n [0.39501598]\n [0.2766213 ]\n [0.76871574]\n [0.67721754]\n [0.27642325]\n [0.6427387 ]\n [0.40615624]\n [0.48434645]\n [0.10460112]\n [0.9212326 ]\n [0.4006667 ]\n [0.24021053]\n [0.08514579]\n [0.21338533]\n [0.15677902]\n [0.30154642]\n [0.89081264]\n [0.7027856 ]\n [0.9134173 ]\n [0.53125733]\n [0.8643418 ]\n [0.18493299]\n [0.14839399]\n [0.08097934]\n [0.775004  ]\n [0.10088727]\n [0.06921735]\n [0.57083726]\n [0.15554827]\n [0.52106285]\n [0.32004246]\n [0.8300294 ]\n [0.11779615]\n [0.38728583]\n [0.6445805 ]\n [0.53003836]\n [0.37730247]\n [0.27931693]\n [0.9237554 ]\n [0.11332725]\n [0.81208193]\n [0.71356636]\n [0.06837884]\n [0.51704925]\n [0.0962389 ]\n [0.48069826]\n [0.41898265]\n [0.6878413 ]\n [0.39789453]\n [0.45776066]\n [0.08413587]\n [0.3788709 ]\n [0.7022963 ]\n [0.17948987]\n [0.25018048]\n [0.855532  ]\n [0.37432045]\n [0.49866596]\n [0.8766561 ]\n [0.10196138]\n [0.17670257]\n [0.6918482 ]\n [0.47626173]\n [0.11777903]\n [0.16932143]\n [0.7426942 ]\n [0.4911234 ]\n [0.8153233 ]\n [0.05526225]\n [0.34923232]\n [0.8453157 ]\n [0.06809001]\n [0.05592364]\n [0.11232523]\n [0.07958123]\n [0.1647198 ]\n [0.25184157]\n [0.27640557]\n [0.66381747]\n [0.6710669 ]\n [0.16793445]\n [0.9276973 ]\n [0.4350676 ]\n [0.27129552]\n [0.22650854]\n [0.76537824]\n [0.89772046]\n [0.3098401 ]\n [0.79777443]]\n\n\n\n# check the shape of the predictions\nprint(predictions.shape)\n\n(256, 1)\n\n\n\n# get class predictions\npredictions_class = np.round(predictions)\nprint(predictions_class)\n\n[[0.]\n [0.]\n [0.]\n [0.]\n [0.]\n [0.]\n [0.]\n [1.]\n [0.]\n [1.]\n [0.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [0.]\n [0.]\n [1.]\n [0.]\n [0.]\n [0.]\n [0.]\n [1.]\n [1.]\n [0.]\n [1.]\n [0.]\n [0.]\n [1.]\n [0.]\n [1.]\n [0.]\n [0.]\n [0.]\n [1.]\n [0.]\n [1.]\n [0.]\n [1.]\n [0.]\n [1.]\n [0.]\n [0.]\n [0.]\n [0.]\n [0.]\n [0.]\n [0.]\n [1.]\n [0.]\n [1.]\n [0.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [0.]\n [0.]\n [1.]\n [1.]\n [0.]\n [0.]\n [1.]\n [0.]\n [0.]\n [0.]\n [1.]\n [1.]\n [0.]\n [0.]\n [0.]\n [0.]\n [1.]\n [1.]\n [0.]\n [1.]\n [0.]\n [0.]\n [1.]\n [0.]\n [1.]\n [1.]\n [0.]\n [0.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [0.]\n [0.]\n [1.]\n [0.]\n [0.]\n [0.]\n [1.]\n [0.]\n [0.]\n [1.]\n [0.]\n [0.]\n [0.]\n [1.]\n [0.]\n [0.]\n [1.]\n [1.]\n [0.]\n [0.]\n [0.]\n [0.]\n [0.]\n [1.]\n [0.]\n [1.]\n [0.]\n [1.]\n [0.]\n [0.]\n [1.]\n [0.]\n [0.]\n [0.]\n [1.]\n [0.]\n [1.]\n [0.]\n [1.]\n [0.]\n [1.]\n [0.]\n [1.]\n [0.]\n [0.]\n [0.]\n [1.]\n [0.]\n [0.]\n [1.]\n [1.]\n [0.]\n [0.]\n [0.]\n [1.]\n [0.]\n [1.]\n [0.]\n [1.]\n [1.]\n [0.]\n [0.]\n [0.]\n [0.]\n [0.]\n [0.]\n [1.]\n [0.]\n [0.]\n [0.]\n [1.]\n [0.]\n [0.]\n [0.]\n [1.]\n [1.]\n [0.]\n [1.]\n [0.]\n [0.]\n [0.]\n [1.]\n [0.]\n [0.]\n [0.]\n [0.]\n [0.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [0.]\n [0.]\n [1.]\n [0.]\n [0.]\n [1.]\n [0.]\n [1.]\n [0.]\n [1.]\n [0.]\n [0.]\n [1.]\n [1.]\n [0.]\n [0.]\n [1.]\n [0.]\n [1.]\n [1.]\n [0.]\n [1.]\n [0.]\n [0.]\n [0.]\n [1.]\n [0.]\n [0.]\n [0.]\n [0.]\n [1.]\n [0.]\n [0.]\n [1.]\n [0.]\n [0.]\n [1.]\n [0.]\n [0.]\n [1.]\n [0.]\n [0.]\n [0.]\n [1.]\n [0.]\n [1.]\n [0.]\n [0.]\n [1.]\n [0.]\n [0.]\n [0.]\n [0.]\n [0.]\n [0.]\n [0.]\n [1.]\n [1.]\n [0.]\n [1.]\n [0.]\n [0.]\n [0.]\n [1.]\n [1.]\n [0.]\n [1.]]\n\n\n\n\n\nFor those interested in learning more about TensorFlow and Keras, I personally believe that the documentation available on the web is good enough. However, if you prefer reading a book, I recommend “Deep Learning with Python” by Francois Chollet, the creator of Keras. This book essentially summarizes the content of the documentation in a more cohesive and structured manner.\n\n\n\n\nChollet, F. (2021). Deep Learning with Python. Manning Publications.\nTensorFlow. (n.d.). Retrieved from https://www.tensorflow.org/\nKeras. (n.d.). Retrieved from https://keras.io/"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/pdnum/tugas-pd/tugas-akhir.html",
    "href": "semuahalaman/modulprak/2023/genap/pdnum/tugas-pd/tugas-akhir.html",
    "title": "Lab Praktikum Departemen Matematika FMIPA UI",
    "section": "",
    "text": "Tugas Akhir\nKembali ke Persamaan Diferensial Numerik\nTulisan di bawah ini adalah salinan dari: https://linevoom.line.me/post/1168595921012325899\n[TUGAS AKHIR PRAKTIKUM SAINS DATA dan PDNUM]\nSelamat sore, warga Departemen Matematika!\nBerikut ini adalah tugas praktikum yang harus dikerjakan bagi mahasiswa yang mengambil mata kuliah Sains Data dan PDNum.\nhttps://drive.google.com/drive/folders/10hEyh6MTFnrx2kwC4IEL74cOCo-_NoNQ\nTugas dikerjakan secara individu dengan ketentuan yang sudah tentukan di masing masing tugas yang tertera pada tautan di atas.\nTugas dikumpulkan paling lambat pada hari Rabu, 21 Juni 2023 pukul 23.59 WIB melalui tautan berikut.\nSains Data: https://forms.gle/4i2tj8Zf7v7kDPoG7\nPDNum: https://forms.gle/m8s6iqyufpH9g3fUA\nDemikian informasi yang dapat kami sampaikan. Jika ada pertanyaan lebih lanjut, silakan hubungi kontak berikut.\nNarahubung:\n■ Justin (LINE: iamjustin10)\n■ Carles (LINE: Carles_octavianus)\n■ Tulus (LINE: tlsnew)"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/pdnum/tugas-pd/tugas-01.html",
    "href": "semuahalaman/modulprak/2023/genap/pdnum/tugas-pd/tugas-01.html",
    "title": "Lab Praktikum Departemen Matematika FMIPA UI",
    "section": "",
    "text": "Kembali ke Persamaan Diferensial Numerik\n\n\n\nTugas ini dikerjakan secara individu.\nTerdapat satu (1) soal yang harus dijawab.\nFile yang harus diunggah terdiri dari:\n\n\nbeberapa function file sesuai kebutuhan. Penamaan untuk function file dibebaskan, selama masih relevan dengan isi fungsinya (dilarang menamakan function file “adamsorde5.m” jika isinya adalah metode Runge-Kutta).\nsatu (1) script file untuk jawaban. Penamaannya adalah “soal.m” untuk soal yang diberikan.\nsatu (1) file PDF untuk penjelasan keseluruhan soal. Penjelasan diketik dalam Word atau sejenisnya dengan format penamaan “Penjelasan.pdf”.\n\n\nSemua file disatukan dalam satu file .zip dengan format penamaan:\n\n[Nama][NPM][Kelas SIAK]_Tugas 1_Prak PDNum.zip\nContoh: “Cristiano Ronaldo_2101234567_C_Tugas 1_Prak PDNum.zip”\n\nBatas pengumpulan tugas ini adalah Selasa, 21 Maret 2023, pukul 23.59 WIB.\n\nTugas dikumpulkan melalui gform sesuai dengan kelas masing-masing:\nLink: https://bit.ly/Tugas1PrakPDNum\n*mohon perhatikan waktu pengumpulan yang tertera dan kumpulkan tugas secara tepat waktu.\n\nDilarang melakukan plagiarisme. Jika terdapat mahasisya yang terindikasi melakukan plagiarisme, maka mahasiswa tersebut memperoleh nilai 0 untuk tugas ini.\nApabila ada pertanyaan, harap huibungi CP:\n\nTulus Setiawan (WA/LINE: tlsnew/081213679316) Diberikan suatu initial value problem\n\n\n\n\\[\n\\begin{aligned}\n& y^{\\prime}=\\frac{y^{2}}{1+t}, \\quad 1 \\leq t \\leq 2 \\\\\n& y(1)=-(\\ln 2)^{-1}\n\\end{aligned}\n\\]\nDiketahui solusi eksak dari IVP tersebut adalah:\n\\[\ny(t)=-\\frac{1}{\\ln (t+1)}\n\\]\n\nGunakan tiga metode one-step pilihan Anda untuk mengaproksimasi dan membandingkan solusi dari IVP tersebut menggunakan stepsize \\(h=0.05\\).\nBuatlah grafik perbandingan dari metode tersebut."
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/pdnum/tugas-pd/tugas-02.html",
    "href": "semuahalaman/modulprak/2023/genap/pdnum/tugas-pd/tugas-02.html",
    "title": "Lab Praktikum Departemen Matematika FMIPA UI",
    "section": "",
    "text": "Kembali ke Persamaan Diferensial Numerik\n\n\n\nTugas ini dikerjakan secara individu.\nTerdapat satu (1) soal yang harus dijawab.\nFile yang harus diunggah terdiri dari:\n\nbeberapa function file sesuai kebutuhan. Penamaan untuk function file dibebaskan, selama masih relevan dengan isi fungsinya (dilarang menamakan function file “adamsorde5.m” jika isinya adalah metode Runge-Kutta).\nsatu (1) script file untuk jawaban. Penamaannya adalah “soal.m” untuk soal yang diberikan.\nsatu (1) file PDF untuk penjelasan keseluruhan soal. Penjelasan diketik dalam Word atau sejenisnya dengan format penamaan “Penjelasan.pdf”.\n\nSemua file disatukan dalam satu file .zip dengan format penamaan:\n[Nama]_[NPM]_[Kelas SIAK]_Tugas 2_Prak PDNum.zip\nContoh: “Cristiano-Ronaldo_2101234567_C_Tugas 2_Prak PDNum.zip”\nBatas pengumpulan tugas ini adalah Minggu, 16 April 2023, pukul 23.59 WIB.\nTugas dikumpulkan melalui gform sesuai dengan kelas masing-masing:\nLink: https://bit.ly/Tugas2PrakPDNum (akses menggunakan akun @sci atau @ui)\nDilarang melakukan plagiarisme. Jika terdapat mahasisya yang terindikasi melakukan plagiarisme, maka mahasiswa tersebut memperoleh nilai 0 untuk tugas ini.\nApabila ada yang ingin ditanyakan anda dapat bertanya pada kolom komentar atau, silakan mengontak salah satu kontak berikut:\n\nLINE: iamjustin10 (Justin)\n\n\n\n\n\nArthur adalah seorang pelajar yang menyukai matematika dan pemrograman. Suatu hari, saat Arthur sedang membaca kitab Burden, dia menemukan algoritma Adams predictor-corrector dan menyadari jika cara kerja dari metode tersebut merupakan gabungan dari metode one-step Runge-Kutta orde 4, metode multistep eksplisit Adams-Bashforth 4-step, dan metode multistep implisit Adams-Moulton 3-step.\nArthur penasaran apakah metode predictor-corrector ini bisa dibuat dengan metode yang berbeda dari jenis yang sama. Dia pun mencoba mengubah metode multistep eksplisit dan implisitnya dengan Adams-Bashforth 5-step dan Adams-Moulton 4-step, dengan harapan aproksimasinya akan lebih akurat.\nBantulah Arthur dalam membuat algoritma dari metode buatannya, dan bandingkan dengan metode Adams predictor-corrector sebelumnya. Ujilah menggunakan IVP:\n\\(y^{\\prime}=y-t^2+1,\\; 0\\leq t\\leq2,\\; y(0)=0.5\\)\ndengan stepsize \\(h=0.1\\), jika diketahui solusi eksak dari IVP tersebut adalah\n\\(y(t)=(t+1)^2-0.5 e^t\\)"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/pdnum/tugas-pd/tugas-03.html",
    "href": "semuahalaman/modulprak/2023/genap/pdnum/tugas-pd/tugas-03.html",
    "title": "Lab Praktikum Departemen Matematika FMIPA UI",
    "section": "",
    "text": "Kembali ke Persamaan Diferensial Numerik\n\n\n\nTugas ini dikerjakan secara individu.\nTerdapat satu (1) soal yang harus dijawab.\nFile yang harus diunggah terdiri dari:\n\nbeberapa function file sesuai kebutuhan. Penamaan untuk function file dibebaskan, selama masih relevan dengan isi fungsinya (dilarang menamakan function file “adamsorde5.m” jika isinya adalah metode Runge-Kutta).\nsatu (1) script file untuk jawaban. Penamaannya adalah “soal.m” untuk soal yang diberikan.\nsatu (1) file PDF untuk penjelasan keseluruhan soal. Penjelasan diketik dalam Word atau sejenisnya dengan format penamaan “Penjelasan.pdf”.\n\nSemua file disatukan dalam satu file .zip dengan format penamaan:\n\n[Nama]_[NPM]_[Kelas SIAK]_Tugas 1_Prak PDNum.zip\nContoh: “Cristiano-Ronaldo_2101234567_C_Tugas 1_Prak PDNum.zip”\n\nBatas pengumpulan tugas ini adalah 16 April 2023, pukul 23.59 WIB.\n\nTugas dikumpulkan melalui gform sesuai dengan kelas masing-masing:\nLink: ristek.link/Tugas3PrakPDNum\n\nDilarang melakukan plagiarisme. Jika terdapat mahasisya yang terindikasi melakukan plagiarisme, maka mahasiswa tersebut memperoleh nilai 0 untuk tugas ini.\nApabila ada yang ingin ditanyakan anda dapat bertanya pada kolom komentar atau, silakan mengontak salah satu kontak berikut:\n\nLINE: Carles_Octavianus (carles)\n\n\n\n\n\n\n\nUbahlah 2 metode persamaan differential numerik (dapat berupa metode single-step ataupun multi-step) favorit (selain runge-kutta tentunya) menjadi metode yang dapat menyelesaikan sistem persamaan differensial.\ngunakan kedua metode tersebut unutk menyelesaikan persamaan differensial berikut:\n\\(y^{\\prime \\prime}-2 y^{\\prime}+y=t e^t-t, \\quad 0 \\leq t \\leq 1, \\quad y(0)=y^{\\prime}(0)=0\\), dengan \\(h=0.1\\) dengan solusi analitiknya: \\(y(t)=\\frac{1}{6} t^3 e^t-t e^t+2 e^t-t-2\\)\ndan Buatlah grafik perbandingan dari metode tersebut."
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/pdnum/module/week-04.html",
    "href": "semuahalaman/modulprak/2023/genap/pdnum/module/week-04.html",
    "title": "Lab Praktikum Departemen Matematika FMIPA UI",
    "section": "",
    "text": "Kembali ke Persamaan Diferensial Numerik\n\n\n\n\nBentuk umum sistem Persamaan Diferensial:\n\\(u'_1 = f_1(t,u_1,u_2,...,u_m)\\)\n\\(u'_2 = f_2(t,u_1,u_2,...,u_m)\\)\n\\(...\\)\n\\(u'_m = f_m(t,u_1,u_2,...,u_m)\\)\ndimana:\n\\(a \\leq t \\leq b\\)\n\\(u_1(a)=a_1, u_2(a)=a_2, ..., u_m(a)=a_m\\) (initial value)\n\n\n\nPada modul ini, akan dibahas mengenai metode Runge-Kutta untuk menyelesaikan sistem persamaan diferensial. Berikut merupakan code dari metode Runge-Kutta untuk sistem persamaan diferensial pada Octave yang perlu disimpan pada function file.\nfunction [t, w1, w2] = rkfs(f1, f2, a, b, n, alph1, alph2)\n  h = (b - a)/n;\n  t = w1 = w2 = [];\n  t(1) = a;\n  w1(1) = alph1;\n  w2(1) = alph2;\n  for i = 1:n\n    k11 = h * f1(t(i), w1(i), w2(i));\n    k12 = h * f2(t(i), w1(i), w2(i));\n\n    k21 = h * f1((t(i)+(h/2)), (w1(i)+(k11/2)), (w2(i)+(k12/2)));\n    k22 = h * f2((t(i)+(h/2)), (w1(i)+(k11/2)), (w2(i)+(k12/2)));\n\n    k31 = h * f1((t(i)+(h/2)), (w1(i)+(k21/2)), (w2(i)+(k22/2)));\n    k32 = h * f2((t(i)+(h/2)), (w1(i)+(k21/2)), (w2(i)+(k22/2)));\n\n    k41 = h * f1((t(i)+h), (w1(i)+k31), (w2(i)+k32));\n    k42 = h * f2((t(i)+h), (w1(i)+k31), (w2(i)+k32));\n\n    w1(i+1) = w1(i) + (k11 + 2*k21 + 2*k31 + k41)/6;\n    w2(i+1) = w2(i) + (k12 + 2*k22 + 2*k32 + k42)/6;\n    t(i+1) = a + i*h;\n  endfor\nendfunction\n\n\n\n\\(u'_1 = -4u_1+3u_2+6, \\;u_1(0)=0\\)\n\\(u'_2 = -2.4u_1+1.6u_2+3.6, \\;u_2(0)=0\\)\nAkan diuji dengan \\(h=0.1\\) dan \\(0\\leq t \\leq 0.5\\)\nSolusi eksak:\n\\(u_1(t)=-3.375e^{-2t}+1.875e^{-0.4t}+1.5\\)\n\\(u_2(t) = -2.25e^{-2t}+2.25e^{-0.4t}\\)\nBerikut adalah code script file untuk menjalankan function metode Runge-Kutta untuk sistem PD di atas:\nf1 = @(t, y1, y2) (-4*y1 + 3*y2 + 6);\nf2 = @(t, y1, y2) (-2.4*y1 + 1.6*y2 + 3.6);\n\na = 0;\nb = 0.5;\nn = 5;\nalph1 = 0;\nalph2 = 0;\n\n[t, w1, w2] = rkfs(f1, f2, a, b, n, alph1, alph2);\n\nsln1 = @(t) (-3.375*exp(-2*t) + 1.875*exp(-0.4*t) + 1.5);\nsln2 = @(t) (-2.25*exp(-2*t) + 2.25*exp(-0.4*t));\n\nw1ex = w2ex = [];\nfor i = 1:length(t)\n  w1ex(i) = sln1(t(i));\n  w2ex(i) = sln2(t(i));\nendfor\n\n[t', w1', w2', w1ex', w2ex']\n\nhold on;\nfplot(sln1, [0, 0.5], 'r');\nfplot(sln2, [0, 0.5], 'b');\nscatter(t, w1, 'r');\nscatter(t, w2, 'b');\nlegend('u1', 'u2');\nlegend('location', 'northwest');\nJika kita run script file tersebut, maka program akan mengeluarkan dua macam output, yaitu tabel serta plot perbandingan solusi eksak dan aproksimasi seperti di bawah ini:\n\n\n\nimage.png\n\n\n\n\n\nimage-3.png\n\n\n\n\n\n\n\n\nLinear Shooting merupakan metode untuk menyelesaikan masalah PD berbentuk:\n\\(-y'' + p(x)y' + q(x)y + r(x) = 0, \\;a\\leq x\\leq b\\)\n\\(y(a)=\\alpha, \\;y(b)=\\beta\\)\n\n\n\nfunction [x_i, w_1i, w_2i] = linshoot(p, q, r, a, b, n, alpha, beta)\n  h = (b - a)/n;\n  u = [alpha ; 0];\n  v = [0 ; 1];\n  x_i = w_1i = w_2i = [];\n  for i = 1:n\n    x = a + (i-1)*h;\n\n    k_11 = h * u(2,i);\n    k_12 = h * (p(x)*u(2,i) + q(x)*u(1,i) + r(x));\n\n    k_21 = h * (u(2,i)+(k_12/2));\n    k_22 = h * (p(x+(h/2))*(u(2,i)+(k_12/2)) + q(x+(h/2))*(u(1,i)+(k_11/2)) + r(x+(h/2)));\n\n    k_31 = h * (u(2,i)+(k_22/2));\n    k_32 = h * (p(x+(h/2))*(u(2,i)+(k_22/2)) + q(x+(h/2))*(u(1,i)+(k_21/2)) + r(x+(h/2)));\n\n    k_41 = h * (u(2,i)+k_32);\n    k_42 = h * (p(x+h)*(u(2,i)+k_32) + q(x+h)*(u(1,i)+k_31) + r(x+h));\n\n    u(1,i+1) = u(1,i) + ((k_11 + 2*k_21 + 2*k_31 + k_41)/6);\n    u(2,i+1) = u(2,i) + ((k_12 + 2*k_22 + 2*k_32 + k_42)/6);\n\n    kp_11 = h * v(2,i);\n    kp_12 = h * (p(x)*v(2,i) + q(x)*v(1,i));\n\n    kp_21 = h * (v(2,i) + (kp_12/2));\n    kp_22 = h * (p(x+(h/2))*(v(2,i)+(kp_12/2)) + q(x+(h/2))*(v(1,i)+(kp_11/2)));\n\n    kp_31 = h * (v(2,i)+(kp_22/2));\n    kp_32 = h * (p(x+(h/2))*(v(2,i)+(kp_22/2)) + q(x+(h/2))*(v(1,i)+(kp_21/2)));\n\n    kp_41 = h * (v(2,i)+kp_32);\n    kp_42 = h * (p(x+h)*(v(2,i)+kp_32) + q(x+h)*(v(1,i)+kp_31));\n\n    v(1,i+1) = v(1,i) + (kp_11 + 2*kp_21 + 2*kp_31 + kp_41)/6;\n    v(2,i+1) = v(2,i) + (kp_12 + 2*kp_22 + 2*kp_32 + kp_42)/6;\n  endfor\n\n  w = [alpha ; ((beta - u(1,(n+1))) / v(1,(n+1)))];\n  x_i(1) = a;\n  w_1i(1) = w(1,1);\n  w_2i(1) = w(2,1);\n\n  for i = 2:(n+1)\n    W1 = u(1,i) + w(2,1)*v(1,i);\n    W2 = u(2,i) + w(2,1)*v(2,i);\n    x = a + (i-1)*h;\n    x_i(i) = x;\n    w_1i(i) = W1;\n    w_2i(i) = W2;\n  endfor\nendfunction\n\n\n\n\\(y'' = -\\frac{2}{x}y' + \\frac{2}{x^2}y + \\frac{\\sin(\\ln(x))}{x^2}, \\; 1\\leq x\\leq 2\\)\n\\(y(1)=1,\\; y(2)=2\\)\ndengan \\(n=10\\)\ndan solusi eksak:\n\\(y=c_1x+\\frac{c_2}{x^2} - \\frac{3}{10}\\sin(\\ln(x))-\\frac{1}{10}cos(\\ln(x))\\)\n\\(c_2 = \\frac{1}{70}(8-12\\sin(\\ln(2)) - 4\\cos(\\ln(2)))\\)\n\\(c_1 = \\frac{11}{10}-c_2\\)\nBerikut code script file untuk permasalahan di atas menggunakan metode linear shooting:\np = @(x) (-2*(x^(-1)));\nq = @(x) (2*(x^(-2)));\nr = @(x) (sin(log(x))*(x^(-2)));\na = 1;\nb = 2;\nalph = 1;\nbet = 2;\n\n[xi, w1i, w2i] = linshoot(p, q, r, a, b, 10, alph, bet);\n\nc2 = (8-12*sin(log(2)) - 4*cos(log(2)))/70;\nc1 = (11/10) - c2;\nsln = @(x) (c1*x + (c2*x^(-2)) - (3/10)*sin(log(x)) - (1/10)*cos(log(x)));\nw = [];\nfor i = 1:length(xi)\n  w(i) = sln(xi(i));\nendfor\n\n[xi', w1i', w']\n\nhold on;\nfplot(sln, [1,2], 'k');\nscatter(xi, w1i, '-r');\nlegend('Eksak', 'Aproksimasi');\nlegend('location', 'northwest');\nJika kita run script file tersebut, maka program akan mengeluarkan dua macam output, yaitu tabel serta plot perbandingan solusi eksak dan aproksimasi seperti di bawah ini:\n\n\n\nimage.png\n\n\n\n\n\nimage-2.png\n\n\n\n\n\n\n\n\nNonlinear Shooting digunakan untuk menyelesaikan masalah PD berbentuk:\n\\(y'' = f(x, y, y'), \\; a\\leq x \\leq b\\)\n\\(y(a)=\\alpha, \\; y(b)=\\beta\\)\ndimana, \\(f\\) merupakan fungsi nonlinear\n\n\n\nfunction [x_i, w_1i, w_2i] = nonlinshoot(f, fy, fyp, a, b, n, alpha, beta, m, tol)  % m adalah maksimum iterasi\n  h = (b - a)/n;\n  k = 1;\n  tk = (beta - alpha)/(b - a);\n  x_i = w_1i = w_2i = [];\n  while k <= m\n    w = [alpha;tk];\n    u = [0,1];\n    for i = 1:n\n      x = a + (i-1)*h;\n\n      k_11 = h*w(2,i);\n      k_12 = h*f(x, w(1,i), w(2,i));\n\n      k_21 = h*(w(2,i)+(k_12/2));\n      k_22 = h*f((x+(h/2)), (w(1,i)+(k_11/2)), (w(2,i)+(k_12/2)));\n\n      k_31 = h*(w(2,i)+(k_22/2));\n      k_32 = h*f((x+(h/2)), (w(1,i)+(k_21/2)), (w(2,i)+(k_22/2)));\n\n      k_41 = h*(w(2,i)+k_32);\n      k_42 = h*f((x+h), (w(1,i)+k_31), (w(2,i)+k_32));\n\n      w(1,i+1) = w(1,i) + ((k_11 + 2*k_21 + 2*k_31 + k_41)/6);\n      w(2,i+1) = w(2,i) + ((k_12 + 2*k_22 + 2*k_32 + k_42)/6);\n\n      kp_11 = h*u(2);\n      kp_12 = h*(fy(x, w(1,i), w(2,i))*u(1) + fyp(x, w(1,i), w(2,i))*u(2));\n\n      kp_21 = h*(u(2) + (kp_12/2));\n      kp_22 = h*(fy((x+(h/2)), w(1,i), w(2,i))*u(1) + fyp((x+(h/2)), w(1,i), w(2,i))*(u(2) + (kp_12/2)));\n\n      kp_31 = h*(u(2)+(kp_22/2));\n      kp_32 = h*(fy((x+(h/2)), w(1,i), w(2,i))*(u(1) + (kp_21/2)) + fyp((x+(h/2)), w(1,i), w(2,i))*(u(2) + (kp_22/2)));\n\n      kp_41 = h*(u(2)+kp_32);\n      kp_42 = h*(fy((x+h), w(1,i), w(2,i))*(u(1)+kp_31) + fyp((x+h), w(1,i), w(2,i))*(u(2) + kp_32));\n\n      u(1) = u(1) + (kp_11 + 2*kp_21 + 2*kp_31 + kp_41)/6;\n      u(2) = u(2) + (kp_12 + 2*kp_22 + 2*kp_32 + kp_42)/6;\n    endfor\n\n  if abs(w(1,n+1) - beta) <= tol       % jika sudah mencapai batas toleransi maka program berhenti\n    for i = 1:(n+1)\n      x = a+(i-1)*h;\n      x_i(i) = x;\n      w_1i(i) = w(1,i);\n      w_2i(i) = w(2,i);\n    endfor\n    return\n  endif\n  tk = tk-((w(1,n+1) - beta)/u(1));\n  k = k + 1;\n  endwhile\n  disp('max iteration')\nendfunction\n\n\n\n\\(y'' = \\frac{1}{8}(32+2x^3-yy'), \\; 1\\leq x \\leq 3\\)\n\\(y(1) = 17, \\; y(3)=43/3\\)\ndengan \\(n=20\\), \\(m=10\\), dan toleransi \\(=10^{-5}\\)\ndan solusi eksak:\n\\(y(x)=x^2 + \\frac{16}{x}\\)\nBerikut code script file untuk permasalahan di atas menggunakan metode linear shooting:\nf = @(x, y, yp) ((1/8)*(32 + 2*x^3 - y*yp));\nfy = @(x, y, yp) (-yp/8);\nfyp = @(x, y, yp) (-y/8);\na = 1;\nb = 3;\nn = 20;\nalph = 17;\nbet = 43/3;\nm = 10;\ntol = 10^(-5);\n\n[xi, w1i, w2i] = nonlinshoot(f, fy, fyp, a, b, n, alph, bet, m, tol);\n\nsln = @(x) ((x^2) + (16/x));\nw = [];\nfor i = 1:length(xi)\n  w(i) = sln(xi(i));\nendfor\n\n[xi', w1i', w']\n\nhold on;\nfplot(sln, [1,3], 'k');\nscatter(xi, w1i, 'r');\nlegend('Eksak', 'Aproksimasi');\nJika kita run script file tersebut, maka program akan mengeluarkan dua macam output, yaitu tabel serta plot perbandingan solusi eksak dan aproksimasi seperti di bawah ini:\n\n\n\nimage.png\n\n\n\n\n\nimage-2.png"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/pdnum/module/week-02p2.html",
    "href": "semuahalaman/modulprak/2023/genap/pdnum/module/week-02p2.html",
    "title": "Lab Praktikum Departemen Matematika FMIPA UI",
    "section": "",
    "text": "Kembali ke Persamaan Diferensial Numerik\n\n\nMetode Euler metode paling dasar dalam mencari solusi dari permasalahan nilai awal dari suatu PD. Metode ini dikembangkan dari Teorema Taylor:\nMetode Euler metode paling dasar dalam mencari solusi dari permasalahan nilai awal dari suatu PD. Metode ini dikembangkan dari Teorema Taylor:\n\\[\ny\\left(t_{i+1}\\right)=y\\left(t_i\\right)+\\left(t_{i+1}-t_I\\right) y^{\\prime}\\left(t_i\\right)+\\cdots\n\\]\nMisalkan kita mempunyai suatu persamaan diferensial dengan nilai awal:\n\\[\n\\begin{gathered}\ny^{\\prime}=f(t, y), a \\leq t \\leq b \\\\\ny(a)=\\alpha\n\\end{gathered}\n\\]\nmaka solusi secara numeriknya adalah \\(w_i= y(t_i)\\), dengan:\n\\[\n\\begin{gathered}\nw_1=\\alpha \\\\\nw_{i+1}=w_i+h f\\left(t_i, w_i\\right), \\quad i=1,2, \\ldots, n\n\\end{gathered}\n\\]\ndengan \\(n+1\\in \\mathbb{N}\\) menyatakan banyaknya titik nantinya.\nSolusi kita akan berupa titik yang nantinya dapat menggunakan interpolasi untuk nilai yang tidak dimuat di \\(w_i\\)\nAlgoritma untuk metode Euler adalah sebagai berikut:\n\nfunction [t, w] = euler(f, a, b, n, alpha)\n  h = (b - a) / n;\n  t = zeros(n + 1, 1);\n  w = zeros(n + 1, 1);\n  t(1) = a;\n  w(1) = alpha;\n  for i = 1: n\n    t(i + 1) = t(i) + h;\n    m1 = f(t(i), w(i));\n    w(i + 1) = w(i) + h * m1;\n  endfor\nendfunction\n\nDisini, inputnya adalah: - \\(\\mathrm{f}=\\mathrm{E}(t, y)\\) merupakan suatu fungsi, - a dan b berturut-turut batas bawah dan batas atas dari \\(t\\) - \\(\\mathrm{n}\\) merupakan pembagi untuk step size dan \\(\\mathrm{n}+1\\) yang digunakan sebagai banyaknya titik, dan - alpha merupakan nilai awal Sekarang akan kita coba gunakan untuk menyelesaikan suatu PD. Misal diberikan PD sebagai berikut: \\[\n\\begin{aligned}\n& y^{\\prime}=y-t^2+1,0 \\leq t \\leq 2 \\\\\n& y(0)=0.5\n\\end{aligned}\n\\]\nmaka kita dapat mendefinisikan f=@(t, y)\\left(y-t^{\\wedge} 2+1\\right), a=0, b=2, dan alpha \\(=0.5\\) (@ disini menyatakan fungsi anonim yang cara kerjanya mirip dengan fungsi lambda pada Python), sehingga untuk \\(n=10\\), diperoleh kode sebagai berikut:\n\nf = @(t, y) (y-t^2 + 1);\na = 0;\nb = 2;\nn = 10;\nalpha= 0.5;\n[t_euler, w_euler] = euler(f, a, b, n, alpha)\n\nUntuk visualisasinya, kita akan membuat plot dari hasil yang kita peroleh. Sebagai referensi, solusi eksak dari PD tersebut adalah \\(y(t)=(t+1)^2- 0.5 e^t\\)\nKita tambahkan kode berikut pada file:$\n\nsln = @(t) (t + 1)^2 - 0.5 * exp(t);\nfplot(sln, [0, 2], 'b');\nhold on;\nscatter(t_euler, w_euler, 'r');\nlegend('Solusi eksak', 'Metode Euler');\ntitle(\"Metode Euler\")\n\nSaat dijalankan, akan muncul jendela pop-up yang berisi plot yang telah dibuat.\n\n\n\ngambar pop up plot\n\n\nPenjelasan: * sln berisi fungsi referensi kita untuk di-plot dan dibandingkan. * fplot(f, [a, b]) akan menampilkan plot dari suatu fungsi f dengan domain [a, b]. Argumen tambahan ‘b’ memberi warna biru pada plot. * hold on akan menahan plot yang ada agar kita bisa menampilkan banyak plot sekaligus. * scatter(x, y) akan menampilkan x-y scatter plot. * legend memberi legenda pada plot yang telah dibuat. Legenda tersebut dimasukkan berurutan mulai dari plot yang didefinsikan terlebih dahulu * title memberi judul pada plot\n\n\n\n\nMetode midpoint \\[\n\\begin{gathered}\nw_1=\\alpha \\\\\nw_{i+1}=w_i+h f\\left(t_i+\\frac{h}{2}, w_i+\\frac{h}{2} f\\left(t_i, w_i\\right)\\right)\n\\end{gathered}\n\\]\nMetode Euler modifikasi \\[\n\\begin{gathered}\nw_1=\\alpha \\\\\nw_{i+1}=w_i+\\frac{h}{2}\\left(f\\left(t_i, w_i\\right)+f\\left(t_{i+1}, w_i+h f\\left(t_i, w_i\\right)\\right)\\right)\n\\end{gathered}\n\\]\nMetode Heun (tidak umum digunakan) \\[\n\\begin{gathered}\nw_1=\\alpha \\\\\nw_{i+1}=w_i+\\frac{h}{4}\\left(f\\left(t_i, w_i\\right)+3 f\\left(t_i+\\frac{2 h}{3}, w_i+\\frac{2 h}{3} f\\left(t_i+\\frac{h}{3}, w_i+\\frac{h}{3} f\\left(t_i, w_i\\right)\\right)\\right)\\right)\n\\end{gathered}\n\\]\nMetode Runge-Kutta orde 4 \\[\n\\begin{aligned}\n& w_1=\\alpha \\\\\n& m_1=h f\\left(t_i, w_i\\right) \\\\\n& m_2=h f\\left(t_i+\\frac{h}{2}, w_i+\\frac{m_1}{2}\\right) \\\\\n& m_3=h f\\left(t_i+\\frac{h}{2}, w_i+\\frac{m_2}{2}\\right) \\\\\n& m_4=h f\\left(t_{i+1}, w_i+m_3\\right) \\\\\n& w_{i+1}=w_i+\\frac{m_1+2 m_2+2 m_3+m_4}{6}\n\\end{aligned}\n\\]\n\nBerikut adalah list algoritmanya.\n\nfunction [t, w] = midpoint(f, a, b, n, alpha)\n  h = (b - a) / n;\n  t = zeros(n + 1, 1);\n  w = zeros(n + 1, 1);\n  t(1) = a;\n  w(1) = alpha;\n  for i = 1: n\n    t(i + 1) = t(i) + h;\n    m1 = f(t(i), w(i));\n    m2 = f(t(i) + (h / 2), w(i) + (h / 2) * m1);\n    w(i + 1) = w(i) + h * m2;\n  endfor\nendfunction\n\n\nfunction [t, w] = modeuler(f, a, b, n, alpha)\n  h = (b - a) / n;\n  t = zeros(n + 1, 1);\n  w = zeros(n + 1, 1);\n  t(1) = a;\n  w(1) = alpha;\n  for i = 1: n\n    t(i + 1) = t(i) + h;\n    m1 = f(t(i), w(i));\n    m2 = f(t(i + 1), w(i) + h * m1);\n    w(i + 1) = w(i) + h * (m1 + m2) / 2;\n  endfor\nendfunction\n\n\nfunction [t, w] = heun(f, a, b, n, alpha)\n  h = (b - a) / n;\n  t = zeros(n + 1, 1);\n  w = zeros(n + 1, 1);\n  t(1) = a;\n  w(1) = alpha;\n  for i = 1: n\n    t(i + 1) = t(i) + h;\n    m1 = f(t(i), w(i));\n    m2 = f(t(i) + (h / 3), w(i) + (h / 3) * m1);\n    m3 = f(t(i) + (2 * h / 3), w(i) + (2 * h / 3) * m2);\n    m4 = m1 + 3 * m3;\n    w(i + 1) = w(i) + (h / 4) * m4;\n  endfor\nendfunction\n\n\nfunction [t, w] = rko4(f, a, b, n, alpha)\n  h = (b - a) / n;\n  t = zeros(n + 1, 1);\n  w = zeros(n + 1, 1);\n  t(1) = a;\n  w(1) = alpha;\n  for i = 1: n\n    t(i + 1) = t(i) + h;\n    k1 = h * f(t(i), w(i));\n    k2 = h * f(t(i) + (h / 2), w(i) + (k1 / 2));\n    k3 = h * f(t(i) + (h / 2), w(i) + (k2 / 2));\n    k4 = h * f(t(i + 1), w(i) + k3);\n    w(i + 1) = w(i) + (k1 + 2 * k2 + 2 * k3 + k4) / 6;\n  endfor\nendfunction\n\n\nf = @(t, y) (y - t ^ 2 + 1);\na = 0;\nb = 2;\nalpha = 0.5;\n[t1, w1] = midpoint(f, a, b, 10, alpha);\n[t2, w2] = modeuler(f, a, b, 10, alpha);\n[t3, w3] = heun(f, a, b, 10, alpha);\n[t4, w4] = rko4(f, a, b, 10, alpha);\n\nsln = @(t) (t + 1) ^ 2 - 0.5 * exp(t);\n\nfplot(sln, [0, 2], 'k');\nhold on;\nscatter(t1, w1, 'r');\nscatter(t2, w2, 'g');\nscatter(t3, w3, 'b');\nscatter(t4, w4, 'm');\nlegend('Fungsi eksak', 'Midpoint', 'Modified Euler', 'Heun',\n'Runge-Kutta orde 4');\nlegend(\"location\", \"northwest\");\ntitle('Perbandingan metode Runge-Kutta');\n\n\n\n\ngambar pop up plot"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/pdnum/module/week-05.html",
    "href": "semuahalaman/modulprak/2023/genap/pdnum/module/week-05.html",
    "title": "Lab Praktikum Departemen Matematika FMIPA UI",
    "section": "",
    "text": "Week-05 (Finite Difference Methods)\nKembali ke Persamaan Diferensial Numerik\nyang akan dibahas - Metode Beda Hingga untuk Masalah Linear\n\nMetode Beda Hingga untuk Masalah Nonlinear\n\nMetode ini digunakan untuk mengaproksimasi masalah linear dalam bentuk:\n\\[\\begin{gathered}\ny^{\\prime \\prime}=p(x) y^{\\prime}+q(x) y+r(x), \\quad a \\leq x \\leq b \\\\\ny(a)=\\alpha, y(b)=\\beta\n\\end{gathered}\\]\n\\[\\begin{gathered}\nw_{0}=\\alpha, \\quad w_{n+1}=\\beta \\\\\n-\\left(1+\\frac{h}{2} p\\left(x_{i}\\right)\\right) w_{i-1}+\\left(2+h^{2} q\\left(x_{i}\\right)\\right) w_{i}-\\left(1-\\frac{h}{2} p\\left(x_{i}\\right)\\right) w_{i+1}=-h^{2} r\\left(x_{i}\\right)\n\\end{gathered}\\]\nBentuk tersebut dapat dibuat sebagai suatu SPL:\n\\[\nA \\mathbf{w}=\\mathbf{b}\n\\]\n\n\\(\\mathbf{w}=\\left[\\begin{array}{c}w_{1} \\\\ w_{2} \\\\ \\vdots \\\\ w_{N-1} \\\\ w_{N}\\end{array}\\right], \\quad\\) and \\(\\quad \\mathbf{b}=\\left[\\begin{array}{c}-h^{2} r\\left(x_{1}\\right)+\\left(1+\\frac{h}{2} p\\left(x_{1}\\right)\\right) w_{0} \\\\ -h^{2} r\\left(x_{2}\\right) \\\\ \\vdots \\\\ -h^{2} r\\left(x_{N-1}\\right) \\\\ -h^{2} r\\left(x_{N}\\right)+\\left(1-\\frac{h}{2} p\\left(x_{N}\\right)\\right) w_{N+1}\\end{array}\\right]\\).\nSPL tersebut akan diselesaikan dengan metode faktorisasi Crout (lihat algoritma 6.7). (basicly ini nyari inverse A secara linear, makanya runtime dari algortima ini adalah \\(O(n)\\))\nAlgoritma dari metode beda hingga linear:\nfunction [xt,w]=linfdm(p,q,r,a_boundary,b_boundary,alpha,beta,n)\n  h=(b_boundary-a_boundary)/(n+1); %stepsize\n  a=zeros(n,1); %diagonal sistem persamaannya\n  b=zeros(n,1); % right diagonal sistem persamaannya\n  c=zeros(n,1); %left diagonal sistem persamaannya\n  d=zeros(n,1); %vektor b (Ay=b) pada sistem persamaannya\n  l=zeros(n,1); % main diagonal of lower triangle matrix\n  u=zeros(n,1); %right diagonal of upper triangle matrix\n  z= zeros(n,1); %solution of Lz=b\n  w=zeros(n+1,1); %solusi aproksimasi dengan linear fdm\n  xt=[a_boundary:h:b_boundary]; %mesh_point\n  x=a_boundary+h;\n\n  %konstruksi matrix tridiagonalnya\n  a(1)=2+(h^2)*q(x);\n  b(1)= -1+(h/2)*p(x);\n  d(1)=-h^2*r(x) +(1+(h/2)*p(x))*alpha;\n\n  for i = 2:n-1\n    x= a_boundary+i*h;\n    a(i)=2+h^2*q(x); %diagonal\n    b(i)=-1+(h/2)*p(x);\n    c(i)=-1-(h/2)*p(x);\n    d(i)=-h^2*r(x);\n  endfor\n\n  x=b_boundary-h;\n  a(n)=2+h^2*q(x);\n  c(n)=-1-(h/2)*p(x);\n  d(n)=-h^2*r(x)+(1-(h/2)*p(x))*beta;\n\n  %matriks tridiagonalnya sudah didapatkan,\n  %akan diselesaikan dengan LU Decomposition (crout factorization)\n\n  l(1)= a(1);\n  u(1)=b(1)/a(1);\n  z(1)=d(1)/l(1);\n\n  for i= 2:n-1\n    l(i)=a(i)-c(i)*u(i-1);\n    u(i)=b(i)/l(i);\n    z(i)=(d(i)-c(i)*z(i-1))/l(i);\n\n  endfor\n\n  l(n)=a(n)-c(n)*u(n-1);\n  z(n)=(d(n)-c(n)*z(n-1))/l(n);\n\n  %konstruksi akhir w-nya\n  w(n+1)=beta;\n  w(n)=z(n);\n  for i = n-1:-1:1\n    w(i)=z(i)-u(i)*w(i+1);\n  endfor\n\n  w=[alpha;w];\n  xt=transpose(xt);\n\nendfunction\nAkan kita uji dengan masalah syarat batas:\n\\[\n\\begin{aligned}\ny^{\\prime \\prime} & =-\\frac{4}{x} y^{\\prime}-\\frac{2}{x^2} y+\\frac{2 \\ln x}{x^2}, \\quad 1 \\leq x \\leq 2 \\\\\ny(1) & =\\frac{1}{2}, \\quad y(2)=\\ln 2\n\\end{aligned}\n\\] Solusi eksak: \\[\ny(x)=\\frac{4}{x}-\\frac{2}{x^2}+\\ln x-\\frac{3}{2}\n\\]\np= @(x) (-4/x); %function p(x)\nq= @(x) (-2/x^2);%function q(x)\nr=@(x) 2*log(x)/(x^2); %function r(x)\na_boundary=1; %batas kiri domain\nb_boundary=2; %batas kanan domain\nn=19; %banyaknya partisi (agar h=0.05 pilih n=19)\nalpha=0.5; %y(a)=alpha\nbeta=log(2); %y(b)=beta\n[x_grid,w]=linfdm(p,q,r,a_boundary,b_boundary,alpha,beta,n) %memangil fungsinya\n\nf_anal=@(x)4./x -2./(x.^2) +log(x)-1.5;\nsol_anal=f_anal(x_grid)\nerror=abs(sol_anal-w);\n\n[x_grid,w,sol_anal,error]\n\n\n%bikint tabel dan grafiknya :D\n\nfplot(f_anal, [a_boundary,b_boundary],'b')\nhold on;\nscatter(x_grid,w,'r')\nlegend('solusi analitik', 'solusi linear FDM');\nlegend(\"location\", \"northwest\");\nMetode ini digunakan untuk mengaproksimasi masalah linear dalam bentuk:\n\\[\n\\begin{gathered}\ny^{\\prime \\prime}=f\\left(x, y, y^{\\prime}\\right), \\quad a \\leq x \\leq b \\\\\ny(a)=\\alpha, y(b)=\\beta\n\\end{gathered}\n\\]\nAproksimasi menggunakan metode ini serupa dengan saat menggunakan metode beda hingga linear, dengan perbedaan kita juga menambahkan metode Newton dalam penyelesaiannya.\nAlgoritma dari metode beda hingga nonlinear:\nfunction [t_grid,w]=nonlinear_FDM_naive(f,f_y,f_yprime,a,b,n,alpha,beta,max_iter,TOL)\n  h=(b-a)/(n+1); %sepsize\n  w=zeros(n,1); %vektor solusi aproksimasi\n  t_grid=[a:h:b]; %mesh_poitnya\n  J=zeros(n,n); %matriks jacobian\n  F=zeros(n,1); %vektor fungsi  F=(f_1,f_2,...,f_n) yang dievaluasi di x_k\n\n  for i=1:n %inisialisasi solusi awal\n    w(i)=alpha+i*(beta-alpha)/(b-a)*h;\n  endfor\n  k=1;\n  while k<=max_iter %lakukan iterasi jika masih belum didapat kriteria stopnya\n\n    %solve nonlinear sistem tersebut dengan metode newton\n    x=a+h;\n    %kontruksi matriks Jacobian, dan vektor F-nya\n    t=(w(2)-alpha)/(2*h);\n    J(1,1)=2+h^2*f_y(x,w(1),t); %main diagoanal\n    J(1,2)=-1+(h/2)*f_yprime(x,w(1),t); %right diagonal\n    F(1)=(2*w(1)-w(2)-alpha+h^2*f(x,w(1),t));\n    for i =2:n-1\n      x=a+i*h;\n      t=(w(i+1)-w(i-1))/(2*h);\n      J(i,i)=2+h^2*f_y(x,w(i),t); %main diagoanal\n      J(i,i+1)=-1+(h/2)*f_yprime(x,w(i),t); %main diagoanal\n      J(i,i-1)=-1-(h/2)*f_yprime(x,w(i),t); %left diagoanal\n      F(i)=(2*w(i)-w(i+1)-w(i-1)+h^2*f(x,w(i),t));\n    endfor\n     x=b-h;\n     t=(beta-w(n-1))/(2*h);\n     J(n,n)=2+h^2*f_y(x,w(n),t); %main diagonal\n     J(n,n-1)=-1-(h/2)*f_yprime(x,w(n),t); %right diagonal\n     F(n)=(2*w(n)-w(n-1)-beta+h^2*f(x,w(n),t));\n\n\n\n    v=inverse(J)*F; %vector v adalah product dari J^-1 F\n    w= w-v; % lakukan update nilai pada w\n\n    if norm(v,2)<= TOL %kriteria stop jika norm(v)<=toleransinya\n      break;\n     else\n        k=k+1; %jika belum memenuhi kriteria stop terus lanjut iterasinya (memperbaiki nilai w)\n    endif\n  endwhile\n  w=[alpha ; w ; beta]; %konstruksi akhir w\n  t_grid=transpose(t_grid); % %transpose meshpoint\n  % untuk konsistensi dimensi saja\n\nendfunction\n\nGunakan metode beda hingga nonlinear dengan \\(h=0.1\\) dan toleransi \\(10^{-4}\\) untuk mengaproksimasi BVP berikut: \\[\n\\begin{aligned}\ny^{\\prime \\prime} & =y^{\\prime}+2(y-\\ln x)^3-\\frac{1}{x}, \\quad 2 \\leq x \\leq 3 \\\\\ny(2) & =\\frac{1}{2}+\\ln 2, \\quad y(3)=\\frac{1}{3}+\\ln 3\n\\end{aligned}\n\\] Solusi eksak: \\[\ny(x)=\\frac{1}{x}+\\ln x\n\\]\n\nf=@(x,y,yp) yp+2*(y-log(x))^3-1/x ; %fungsi f pada y=f(x,y,y')\nf_y=@(x,y,yp) 6*(y-log(x))^2; %turunan fungsi f terhadap y\nf_yp=@(x,y,yp) 1; %turunan fungsi f terhadap yprime\na=2; %left boundary\nb=3; %right boundary\nalpha=0.5+log(2); %y(a)\nbeta=1/3+ log(3); %y(b)\nn=9; %banyaknya partisi (pilih n=9 sehingga h=0.1)\nmaxiter=30; %masksimal iterasi newton methodnya\nTOL=10^(-4); %toleransi nilai (untuk kriteria stop)\n\n%memanggil fungsi nonlinear_FDM_naive\n[x_grid,w]=nonlinear_FDM_naive(f,f_y,f_yp,a,b,n,alpha,beta,maxiter,TOL)\nf_anal= @(x) 1./x +log(x); %sol analitik\n\n%membuat grafiknya\nfplot(f_anal, [a,b],'b')\nhold on;\nscatter(x_grid,w,'r')\nlegend('solusi analitik', 'solusi linear FDM');\nlegend(\"location\", \"northwest\");\n\n\n\n\n%membuat tabel saja.\n\nsol_anal=f_anal(x_grid); %sol analitik di meshpoint\nerror=abs(w-sol_anal); %error\n[x_grid,w,sol_anal,error]"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/pdnum/module/week-06.html",
    "href": "semuahalaman/modulprak/2023/genap/pdnum/module/week-06.html",
    "title": "Lab Praktikum Departemen Matematika FMIPA UI",
    "section": "",
    "text": "Week-06 (Skema Beda Hingga)\nKembali ke Persamaan Diferensial Numerik\n\nModul Skema Beda Hingga I.pdf\nModul Skema Beda Hingga II.pdf\nModul Skema Beda Hingga Transport.pdf"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/pdnum/module/week-02.html",
    "href": "semuahalaman/modulprak/2023/genap/pdnum/module/week-02.html",
    "title": "Lab Praktikum Departemen Matematika FMIPA UI",
    "section": "",
    "text": "Kembali ke Persamaan Diferensial Numerik\n\n\nDalam pemrograman, seringkali pengguna diminta memberi suatu input, entah suatu nilai, string, dll., ke program, lalu program tersebut akan menggunakan input tersebut sebagai nilai dari suatu variabel. Hal ini juga dapat dilakukan pada Octave. Untuk membuat Octave meminta input dari user, gunakan syntax input(prompt), dengan prompt adalah string yang berisi pesan dalam input.\n\n    A = input(\"Masukkan suatu angka:\")\n\nJika tidak ingin membuat pesan input, cukup isi “” sebagai prompt\n\n    A = input(\"\")\n\nPerlu diketahui bahwa input yang diberikan pengguna akan dievaluasi sebagai ekspresi. Jadi, bisa saja input yang diberikan akan dievaluasi sebagai kode Octave. Sebagai contoh, jika kita memasukkan operasi bilangan pada inpu ….\n\nB = input(\"Operasi bilangan: \")\n\n… , maka operasi tersebut akan dievaluasi dan memberikan hasil operasinya. Jika kita memasukkan kode Octave, seperti meng-assign suatu variabel …\n\nC = input(\"Assign variabel: \")\n\n…, maka nilai dari variabel yagn di-assign akan masuk ke variabel input …\n\nx\n\nsekaligus variabel yang di-assign di dalam input. Jika kalian ingin agar input yang dimasukkan tidak dievaluasi, input tersebut dapat diubah terlebih dahulu menjadi string.\n\n D = input(\"Masukkan suatu string: \")\n\n\ntypeinfo(D) % untuk menentukan tipe data variabel\n\nBisa juga dengan menambah argumen pada input() menjadi input(prompt, “s”). Jika menambahkan argumen, maka apapun input yang kalian masukkan akan menjadi string tanpa perlu menggunakan tanda petik.\n\nE = input(\"Masukkan suatu string: \", \"s\")\n\n\ntypeinfo(E)\n\nSelain menggunakan input(), kita juga bisa menggunakan syntax menu(title, op1, op2, …). Syntax tersebut akan memunculkan kotak dialog dengan judul title dan pilihan op1, op2, dst. (sesuai yang dimasukkan). Syntax ini sangat berguna untuk program-program interaktif karena mempunyai GUI sendiri.\n\nF = menu(\"Pilih salah satu\", \"Pilihan 1\", \"Pilihan 2\", \"Pilihan 3\")\n\nTergantung pilihan kalian, variabel yang mengandung menu() akan diisi bilangan dari 1 hingga n tergantung banyaknya pilihan.\nUntuk output, mungkin cukup untuk memanggil variabel itu sendiri, seperti…\n\nC\n\n…, namun kalian juga bisa hanya memunculkan nilai dari variabelnya tanpa sekaligus memunculkan variabel tersebut dengan menggunakan syntax disp(). Syntax ini digunakan jika yang di-output hanya suatu variabel atau string simpel, dll.\n\ndisp(C)\n\n\ndisp(\"Ini adalah string\")\n\nJika yang ingin dimunculkan adalah pesan yang membutuhkan banyak formatting, kalian bisa menggunakan syntax printf(). Syntax tersebut dapat melakukan formatting pesan agar dapat menerima variabel selain string.\n\nx=input(\"masukkan nilai x: \")\n\n\nprintf(\"Ini adalah string %d\", x)\n\nPada contoh di atas, kita ingin agar variabel x dapat di-output bersama dengan pesan string. Kita menggunakan %d agar nilai x dapat di-print sebagai bilangan desimal. Jika variabelnya berisi string, maka gunakan %s. Jika variabelnya berisi float, gunakan %f untuk print dalam bentuk desimal, atau %.nf untuk sekaligus mengatur angka di belakang koma sebanyak n.\n\nprintf(\"pi = %.3f\", pi)\n\nJika float tersebut ingin di-print dalam notasi saintifik, gunakan %e atau %E. Keduanya hanya berbeda di hasil output yang berupa E (besar) ataupun e (kecil).\n\nprintf(\"pi = %.3e\", pi)\n\nJika ingin print karakter persen itu sendiri (%), gunakan %%.\nJika ada lebih dari satu formatting di satu printf(), maka variabelnya juga harus dimasukkan secara berurutan.\n\nprintf(\"pi = %.3f dan e = %.3e\", pi, e)\n\n\n\n\nSeperti halnya bahas pemrograman, Octave pun juga memiliki conditional statements. Secara umum, conditional statement pada Octave berbentuk:\n\ncond\n  body\nendcond\n\nPada potongan kode di atas, cond adalah jenis conditional statement yagn digunakan, bisa berupa if, for, dan lainnya, body berisi kode yang dijalankan ketika cond terpenuhi, dan endcond adalah bagian penutup dari conditional statement, bisa berupa endif, endfor, dan lainnya tergantung cond apa yang digunakan.\nOperasi dasar yang digunakan pada conditional statements adalah operasi perbandingan, dimana pada dasarnya, dua atau lebih nilai dibandingkan dengan operator dan dicek apakah memenuhi atau tidak. Jika memenuhi, maka nilainya 1, dan jika tidak, maka nilainya 0. Ada 6 operator dasar untuk perbandingan:\n- sama dengan (==)\n- lebih dari (>)\n- kurang dari (<)\n- lebih dari atau sama dengan (>=)\n- kurang dari atau sama dengan (<=)\n- tidak sama dengan (!= atau ~=)\n\n2<3\n\n\n4==5\n\nSelain operator di atas, ada juga syntax untuk perbandingan:\n- isequal(a, b, c, ...) mengecek apakah a, b, dan c semuanya sama.\n- strcmp(s1, s2) mengecek apakah s1 dan s2 adalah string yang sama.\n- strncmp(s1, s2, n) mengecek apakah n karakter pertama pada s1 dan s2 sama.\n- strcmpi(s1, s2) mirip strcmp(), namun tidak case-sensitive.\n- strncmpi(s1, s2, n) mirip strncmp(), namun tidak case-sensitive.\n\nisequal(1, 3, 5)\n\n\nstrcmp(\"ayam\", \"Ayam\")\n\n\nstrcmpi(\"ayam\", \"Ayam\")\n\n\nstrncmp(\"sayamakan\", \"saya makan\", 4)\n\nBerikut beberapa jenis conditional statement pada Octave. Kode-kode ini akan ditulis di editor.\nIf adalah conditional statement dasar dalam decision-making melalui perbandingan nilai. If memiliki 3 bentuk. Bentuk pertama:\n\nif (cond)\n  body;\nendif\n\nBentuk ini adalah bentuk paling simpel dalam menggunakan if. Jika cond bernilai 1, maka body dieksekusi, dan sebaliknya. Contoh:\n\nx = input( \"Masukkan nilai x: \")\nif x > 0\n    printf(\"%d adalah bilangan positif.\\n\", x);\nendif\n\nBukanlah if jika tidak ada else. Untuk menggunakannya, cukup menyelipkan bagian else layaknya if sehingga menjadi:\n\nif (cond)\n  body1;\nelse\n  body2;\nendif\n\nContoh:\n\nx = input(\"Masukkan x: \");\nif mod(x, 2) == 0\n  printf(\"x genap.\\n\");\nelse\n  printf(\"x ganjil.\\n\");\nendif\n\nKita pun juga dapat membuat lebih dari 2 condition selain if dan else. Cukup tambahkan bagian elseif. Kita dapat menambahkan berapapun banyaknya elseif sesuka hati (dan komputer), selama bagian akhirnya adalah else.\n\nif (cond1)\n  body1;\nelseif (cond2)\n  body2;\nelse\n  body3;\nendif\n\nUntuk beberapa kasus, lebih jelas jika kita menggunakan model kode seperti di atas. Namun, terkadang kita ingin membuat program berjalan sesuai input, dan jika menggunakan if-else, kodenya akan terlihat jelek. Maka, kita juga bisa menggantinya dengan kode switch. Bentuk umum dari switch adalah:\n\nswitch (var)\n  case lab1\n    body1;\n  case lab2\n    body2;\n  otherwise\n    body3;\nendswitch\n\nPada kode di atas, var akan dicocokkan dengan lab1, lab2, dst. yang sesuai. Jika tidak ada yang sesuai, kode akan masuk ke bagian otherwise. Layaknya elseif, kita juga dapat menambahkan berapapun banyaknya case sesuka hati, selama terdapat paling tidak satu case (bahkan bagian otherwise opsional).\nContoh:\n\nmnu = input(\"Masukkan metode: \");\nswitch (mnu)\n  case 1\n    printf(\"Bisection.\\n\")\n  case 2\n    printf(\"Regula Falsi.\\n\")\n  otherwise\n    printf(\"Input tidak valid.\\n\")\nendswitch\n\nJika case berisi array, kode akan masuk case tersebut jika var sesuai dengan salah satu elemen di array tersebut.\n\nA = 7;\nswitch (A)\n  case {6, 7}\n    printf(\"A adalah 6 atau 7\");\n  otherwise\n    printf(\"A bukanlah 6 ataupun 7\");\nendswitch\n\nBentuk umum dari for adalah:\n\n\n\n\n\n\nfor var = expr\n  body;\nendfor\n\nBiasanya isi dari expr adalah a:b, yang menyebabkan var diiterasi dari a hingga b. Secara umum, for akan meng-assign tiap kolom pada expr ke var (bentuk range a:b secara umum adalah vektor baris, sehingga iterasi kolom pada a:b adalah dari a hingga b). Contoh:\n\nfib = ones(1, 10); % ones(1, 10) = matriks 1x10 berisi 1.\nfor i = 3: 10\n  fib(i) = fib(i-1) + fib(i-2);\nendfor\ndisp(fib)\n\nKarena iterasinya antar kolom, maka jika expr adalah suatu matriks, maka var akan diiterasi sebagai vektor kolom. Contoh:\n\nfor i = [1, 2, 3; 4, 5, 6; 7, 8, 9]\n  i\nendfor\n\nBentuk umum dari while adalah:\n\n\n\n\nwhile (cond)\n  body;\nendwhile\n\nSerupa dengan if, while akan menjalankan body jika cond bernilai taknol. Namun, akan diulang terus hingga cond bernilai nol, baru berhenti.\n\nfib = ones(1, 10);\ni = 3;\nwhile i <= 10\n  fib(i) = fib(i-1) + fib(i-2);\n  i++;\nendwhile\ndisp(fib)\n\nPada contoh di atas, penting untuk memasukkan bagian i++ agar suatu saat nilai i akan lebih dari 10. Hati-hati menggunakan while, karena dapat mengakibatkan infinite loop.\n\n\n\nBentuk umum dari do adalah:\n\ndo\n  body\nuntil (cond)\n\nSekilas, do terlihat serupa dengan while. Yang membedakannya adalah do akan terus menjalankan body ketika cond bernilai 0 dan berhenti ketika cond bernilai taknol. Kondisi cond pada do juga berada di akhir, sehingga body pasti akan dijalankan paling tidak sekali. Perbedaan kecil selanjutnya adalah do tidak memakai enddo seperti layaknya endif, endwhile, dan sejenisnya.\n\nfib = ones(1, 10);\ni = 2;\ndo\n  i++;\n  fib(i) = fib(i-1) + fib(i-2);\nuntil i == 10\ndisp(fib)\n\n\n\n\nbreak dan continue adalah dua statement yang digunakan dan hanya digunakan dalam loop. Statement break akan langsung mengeluarkan program dari loop, sedangkan continue akan langsung menuju iterasi selanjutnya tanpa menyelesaikan sisa kode pada badan loop.\nContoh perbedaan break dan continue:\n\na = [];\nfor i = 1:10\n  if mod(i, 5) == 0\n    break;\n  endif\n  a = [a, i];\nendfor\ndisp(a)\n\n\na = [];\nfor i = 1:10\n  if mod(i, 5) == 0\n    continue;\n  endif\n  a = [a, i];\nendfor\ndisp(a)\n\n\n\n\nSebelum kita lanjutkan, kita harus terlebih dahulu mengetahui tentang function file dan script file.\nFunction file adalah file yang dapat digunakan oleh Octave untuk memanggil fungsi yang telah didefinisikan di dalamnya. Function file ini berguna jika kalian ingin menggunakan fungsi tersebut secara berkala.\nScript file adalah file yang berisi kumpulan perintah Octave, layaknya script pemrograman. Script file berguna untuk pemrograman dan menjalankan/menyimpan suatu urutan perintah, sehingga bisa dijalankan kembali nantinya. Untuk selanjutnya, script file akan disebut “program”.\nPermasalahannya, kedua jenis file tersebut mempunyai ekstensi yang serupa (.m), namun function file tidak dapat dijalankan layaknya program.\nMisal kita mempunyai fungsi yang ingin disimpan dalam program bernama testfile.m (untuk sekarang kita akan abaikan dulu maksud dari tiap bagian dari fungsi ini. Intinya fungsi ini akan menampilkan variabel message yang kita masukkan.\n\nfunction test(message)\n  printf(\"%s\\n\", message);\nendfunction\n\ntest(\"AyatoBoba\");\n\nJika program tersebut dijalankan, akan muncul pesan peringatan…\nwarning: function name 'test' does not agree with function filename...\n…dan mungkin saja akan diikuti error lain. Jika kalian ingin membuat program, jangan gunakan function di line pertama yang dieksekusi.\nSekarang kita modifikasi testfile.m di atas.\n\n1;\nfunction test(message)\n  printf(\"%s\\n\", message);\nendfunction\n\ntest(\"AyatoBoba\");\n\nDi sini, kita menambahkan line yang tidak berpengaruh apa-apa dalam program kita sebelum line pendefinisian fungsi. Untuk membedakan function file dengan program, Octave mengecek perintah pertama yang dieksekusi. Jika perintah tersebut adalah pendefinisian fungsi, maka file tersebut akan dianggap sebagai function file, dan jika bukan, maka file tersebut akan dianggap sebagai program.\nSekarang kita masuk ke fungsi, pendefinisian, dan embel-embelnya. Fungsi adalah suatu bagian dari program yang nantinya akan dipanggil. Fungsi sangat berguna jika bagian program\ntersebut nantinya akan digunakan berkali-kali. Fungsi juga berguna agar pengorganisasian kode program lebih bagus. Syntax untuk pendefinisian fungsi adalah:\nfunction name body endfunction ```\nPotongan kode di atas akan membuat fungsi name dengan body adalah isi dari fungsi tersebut. Untuk memanggil fungsi tersebut, cukup dengan memanggil name. Contoh:\n\nfunction bangun\n  printf(\"BANGUN!!!!!\\n\");\nendfunction\n\nbangun;\n\nPada kedua contoh di atas, fungsinya tidak benar-benar memberikan suatu value, melainkan hanya sekedar output. Dalam kebanyakan kasus, kita menggunakan fungsi agar bisa mendapatkan suatu nilai yang dapat di-assign ke suatu variabel. Agar kita bisa mendapatkan value, maka kita harus meng-assign variabel untuk return. Strukturnya menjadi:\n\nfunction retval = name (args)\n  body\nendfunction\n\nretval adalah variabel lokal (namanya tidak harus retval) yang akan digunakan sebagai return value sehingga dapat di-assign. retval bisa berupa variabel, jika kita ingin me-return satu value, ataupun bisa berupa list dari variabel jika ingin me-return lebih dari satu value. Contoh return satu nilai:\n\nfunction x = quadratic(a)\n  x = a^2;\nendfunction\n\ny = quadratic(2);\ndisp(y);\n\ncontoh return lebih dari satu nilai:\n\nfunction [am, gm] = AMGM(v)\n  am = sum(v) / length(v);\n  gm = nthroot(prod(v), length(v));\nendfunction\n\n\nV = [1, 2, 3, 4, 5, 6, 7, 8, 9];\n[amean, gmean] = AMGM(V);\nprintf(\"Arithmetic mean of %s is %g\\n\", mat2str(V), amean);\nprintf(\"Geometric mean of %s is %g\\n\", mat2str(V), gmean);\n\nOctave juga mempunyai syntax return sendiri. Namun, return pada Octave tidak digunakan untuk me-return suatu value, melainkan untuk keluar dari fungsi (serupa dengan break pada loop).\n\n\n\n\nKak ojan: untuk module tahun lalu-nya :D."
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/pdnum/module/week-03.html",
    "href": "semuahalaman/modulprak/2023/genap/pdnum/module/week-03.html",
    "title": "Lab Praktikum Departemen Matematika FMIPA UI",
    "section": "",
    "text": "Kembali ke Persamaan Diferensial Numerik\n\n\nMetode-metode sebelumnya, seperi Euler, Runge-Kutta, dan kawan-kawannya adalah metode jenis one-step, karena kita hanya menggunakan informasi dari satu nilai \\(t_{i}\\). Pada modul berikut akan dijelaskan mengenai metode multistep, dimana kita menggunakan lebih dari satu nilai \\(t_{i}\\) untuk membuat aproksimasi.\nTerdapat dua jenis metode multistep, yaitu:\n\nMultistep eksplisit, dimana kita mengaproksimasi nilai pada \\(t_{i+1}\\) menggunakan nilai \\(t\\) sebelumnya.\nMultistep implisit, dimana kita mengaproksimasi nilai pada \\(t_{i+1}\\) menggunakan nilai pada \\(t\\) sebelumnya, sekaligus nilai pada \\(t_{i+1}\\) itu sendiri.\n\nUntuk bagian awal, kita hanya akan menggunakan multistep eksplisit, dan multistep implisit akan dijelaskan kemudian menggunakan cara lain.\n\n\nMetode \\(n\\)-step Adams-Bashforth menggunakan \\(n\\) titik sebelumnya untuk mengaproksimasi nilai. Karena metode ini adalah metode multistep, maka \\(n\\) nilai awalnya pun harus diperoleh terlebih dahulu. Misal kita ingin menggunakan metode Adams-Bashforth orde 3 , maka \\(w_{1}, w_{2}\\), dan \\(w_{3}\\) harus ada terlebih dahulu sebelum dilanjutkan ke metode Adams-Bashforth. Nilai-nilai awal tersebut dapat diperoleh dari metode-metode one-step sebelumnya, seperti metode Runge-Kutta, yang akan kita gunakan.\nBerikut rumus untuk metode \\(n\\)-step Adams-Bashforth, masing-masing sesuai dengan jumlah step nya.\n\nTwo-step Adams Bashforth\n\n\\[\n\\begin{gathered}\nw_{0}=\\alpha, \\quad w_{1}=\\alpha_{1}, \\\\\nw_{i+1}=w_{i}+\\frac{h}{2}\\left[3 f\\left(t_{i}, w_{i}\\right)-f\\left(t_{i-1}, w_{i-1}\\right)\\right]\n\\end{gathered}\n\\]\n\nThree-step Adams-Bashforth\n\n\\[\n\\begin{gathered}\nw_{0}=\\alpha, \\quad w_{1}=\\alpha_{1}, \\quad w_{2}=\\alpha_{2}, \\\\\nw_{i+1}=w_{i}+\\frac{h}{12}\\left[23 f\\left(t_{i}, w_{i}\\right)-16 f\\left(t_{i-1}, w_{i-1}\\right)+5 f\\left(t_{i-2}, w_{i-2}\\right)\\right]\n\\end{gathered}\n\\]\n\nFour-step Adams-Bashforth\n\n\\[\n\\begin{gathered}\nw_{0}=\\alpha, \\quad w_{1}=\\alpha_{1}, \\quad w_{2}=\\alpha_{2}, \\quad w_{3}=\\alpha_{3} \\\\\nw_{i+1}=w_{i}+\\frac{h}{24}\\left[55 f\\left(t_{i}, w_{i}\\right)-59 f\\left(t_{i-1}, w_{i-1}\\right)+37 f\\left(t_{i-2}, w_{i-2}\\right)-9 f\\left(t_{i-3}, w_{i-3}\\right)\\right]\n\\end{gathered}\n\\]\n\nFive-step Adams-Bashforth\n\n\\[\n\\begin{gathered}\nw_{0}=\\alpha, \\quad w_{1}=\\alpha_{1}, \\quad w_{2}=\\alpha_{2}, \\quad w_{3}=\\alpha_{3}, \\quad w_{4}=\\alpha_{4}, \\\\\nw_{i+1}=w_{i}+\\frac{h}{720}\\left[1901 f\\left(t_{i}, w_{i}\\right)-2774 f\\left(t_{i-1}, w_{i-1}\\right)+2616 f\\left(t_{i-2}, w_{i-2}\\right)\\right. \\\\\n\\left.-1274 f\\left(t_{i-3}, w_{i-3}\\right)+251 f\\left(t_{i-4}, w_{i-4}\\right)\\right]\n\\end{gathered}\n\\]\nprogram untuk two-step Adams-Bashforth:\n\n%function_file\nfunction [t, w] = adams2(f, a, b, n, alpha)\n  % Inisiasi variabel awal\n  h = (b - a) / n;\n  t = zeros(n + 1, 1);\n  w = zeros(n + 1, 1);\n  t(1) = a;\n  w(1) = alpha;\n  \n  % Mencari t(2) dan w(2) menggunakan Runge-Kutta orde 4\n  i = 1;\n  t(i + 1) = t(i) + h;\n  m1 = h * f(t(i), w(i));\n  m2 = h * f(t(i) + (h/2), w(i) + (m1/2));\n  m3 = h * f(t(i) + (h/2), w(i) + (m2/2));\n  m4 = h * f(t(i + 1), w(i) + m3);\n  w(i+1) = w(i) + (m1 + 2*m2 + 2*m3 + m4) / 6;\n  \n  % Algoritma utama Adams-Bashforth\n  for i = 2:n\n    t(i + 1) = t(i) + h;\n    k1 = f(t(i), w(i));\n    k2 = f(t(i-1), w(i-1));\n    w(i+1) = w(i) + (h/2) * (3*k1 - k2);\n  endfor\nendfunction\n\nBerikut ini adalah contoh pengerjaaannya dengan menggunakan metode two-step Adams-Bashforth.\n\n%script file\nf = @(t, y) (y - t ^ 2 + 1);\na = 0;\nb = 2;\nalpha = 0.5;\nn=20\n[t1, w1] = adams2(f,a,b,n,alpha)\n\n[t1,w1]\n\nsln = @(t) (t + 1) ^ 2 - 0.5 * exp(t);\n\nfplot(sln, [0, 2], 'k');\nhold on;\nscatter(t1, w1, 'r');\n\n\n\n\nSerupa dengan metode adams-bashforth, bedanya persamaan iteratif \\(w_{i+1}\\) belum dalam bentuk yang dapat dihitung langsung (melainkan bentuknya implisit). Berikut ini adalah list persamaan iteratifnya (diambil dari buku burden).\n\nAdams-Moulton Two-Step Implicit Method \\[\n\\begin{aligned}\nw_0 & =\\alpha, \\quad w_1=\\alpha_1, \\\\\nw_{i+1} & =w_i+\\frac{h}{12}\\left[5 f\\left(t_{i+1}, w_{i+1}\\right)+8 f\\left(t_i, w_i\\right)-f\\left(t_{i-1}, w_{i-1}\\right)\\right],\n\\end{aligned}\n\\]\nAdams-Moulton Three-Step Implicit Method\n\n\\[\n\\begin{aligned}\nw_0 & =\\alpha, \\quad w_1=\\alpha_1, \\quad w_2=\\alpha_2, \\\\\nw_{i+1} & =w_i+\\frac{h}{24}\\left[9 f\\left(t_{i+1}, w_{i+1}\\right)+19 f\\left(t_i, w_i\\right)-5 f\\left(t_{i-1}, w_{i-1}\\right)+f\\left(t_{i-2}, w_{i-2}\\right)\\right],\n\\end{aligned}\n\\]\n\nAdams-Moulton Four-Step Implicit Method\n\n\\[\n\\begin{aligned}\nw_0= & \\alpha, \\quad w_1=\\alpha_1, \\quad w_2=\\alpha_2, \\quad w_3=\\alpha_3, \\\\\nw_{i+1}= & w_i+\\frac{h}{720}\\left[251 f\\left(t_{i+1}, w_{i+1}\\right)+646 f\\left(t_i, w_i\\right)\\right. \\\\\n& \\left.-264 f\\left(t_{i-1}, w_{i-1}\\right)+106 f\\left(t_{i-2}, w_{i-2}\\right)-19 f\\left(t_{i-3}, w_{i-3}\\right)\\right],\n\\end{aligned}\n\\]\nBentuk umum program yang akan dihasilkan\n\n%function_file\nfunction [t, w] = adam-moulton-general(f, a, b, n, alpha)\n  [\n    Inisialisai awal ...\n  ]\n  \n  [\n\n    Mencari nilai w_i lainnya yang dibutuhkan dengan rungge kutta jika \n    nilai awal tersebut tidak diberikan dengan runge-kutta\n  ]\n  \n  % Algoritma utama Adams-Bashforth\n\n\n  [\n    Iteratif algoritma adams-moulton\n\n    pada saat mencari $w_{i+1}$ gunakan metode numerik favorit anda.\n  ]\n\nendfunction\n\nTinjau bahwa, jika \\(f\\) linear, kita bisa mencarinya nilai bentuk explisit \\(W_{i+1}\\) dengan mudah. Dengan demikian, kita bisa mengganti metode numerik yang digunakan untuk mencari \\(w_{i+1}\\) dengan metode analitik.\n\n\n\nMenggunakan nilai \\(w_{i+1}\\) yang didapat secara implisit dari metode adams-moulton, kita masukkan ke dalam metode adams-bashforth untuk mengupdate nilai nilai \\(w_{i+1}\\) kembali.\nLihat contoh pada pada sub-chapter berikutnya.\n\n\n\n\n\n\n\n%function_file\nfunction [t,w] = rk4_sys(f, a, b, n, y0)\n  %f :differential equation y_p = f(t,y)\n  %a :initial time\n  %b :final time\n  %n :number of steps\n  %y0 :initial value\n\n  h=(b-a)/n;\n  t=[a:h:b];\n  s= length(y0);\n  w=zeros(s,n+1);\n  w(:,1)=y0;\n\n  for i=1:n\n    k1=f(t(i),w(:,i));\n    k2=f(t(i)+h/2,w(:,i)+h*k1/2);\n    k3=f(t(i)+h/2,w(:,i)+h*k2/2);\n    k4=f(t(i)+h,w(:,i)+h*k3);\n    w(:,i+1)=w(:,i)+h*(k1+2*k2+2*k3+k4)/6;\n\nyang perlu dicatat disini fungsi f merupakan fungsi anonimus yang mengeluarkan vektor hasil evaluasinya.\nberikut ini adalah contoh penggunaan fungsi rk4_sys untuk sistem persamaan differential.\n\\[\n\\begin{aligned}\n& I_1^{\\prime}=f_1\\left(t, I_1, I_2\\right)=-4 I_1+3 I_2+6, \\quad I_1(0)=0 \\\\\n& I_2^{\\prime}=f_2\\left(t, I_1, I_2\\right)=0.6 I_1^{\\prime}-0.2 I_2=-2.4 I_1+1.6 I_2+3.6, \\quad I_2(0)=0 .\n\\end{aligned}\n\\] Persamasalahan berikut akan dikerjakan dengan rk4_sys dengan mengunakan titik awal \\(t_0=0\\) dan \\(t_{n+1}=1\\) dengan \\(n=10\\) partisi.\n\n%script file\nf=@(t, I) [-4 * I(1)+ 3 * I(2)+6 ; -2.4*I(1) + 1.6 * I(2)+3.6] % fungsi\n% perhatikan bahwa  I addalah vektor (hence ada I(1) dan I(2))\ny0=[0;0] % nilai awal\na=0 % titik awal\nb=1 % titik akhir\nn=10 % banyaknya partisi.\n\n[t_sys, w_sys] = rk4_sys(f,a,b,n,y0)\n\ntranspose([t_sys ; w_sys]) %rapikan format\n\nCobalah jalankan kode di atas dan lihat hasilnya. selanjutnya bandingkan hasil dengan jawaban pada buku.\n\n\n\n\n\n% the multi-step second order method Adams-Bashforth-Moulton \n\n%function_file\nfunction [t,w] = abm2_sys(f,a,b,n,y0)\n  h=(b-a)/n;\n  t=[a:h:b];\n  s= length(y0);\n  w=zeros(s,n+1);\n  w(:,1)=y0;\n\n  w_serch= rk4_sys(f,a,b,n,y0);\n\n  w(:,2)= w_serch(:,2);\n\n  wnm1 = f(t(1),y0);\n  wn= f(t(2),y1);\n\n  for i=2:n\n    ws=w(:,i)+h/2*(3*wn-wnm1); % predictor\n    wnp1= f(t(i+1),ws); % predictor\n\n    w(:,i+1)=w(:,i)+h/2*(wn+wnp1); % corrector\n    wnm1=wn;\n    wn=f(t(i),w(:,i)); %corector"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/pdnum/module/week-01.html",
    "href": "semuahalaman/modulprak/2023/genap/pdnum/module/week-01.html",
    "title": "Lab Praktikum Departemen Matematika FMIPA UI",
    "section": "",
    "text": "Week-01\nKembali ke Persamaan Diferensial Numerik\nFile modul week 1-3:\nModul Praktikum PD Numerik.pdf"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/genap/pdnum/pdnum2023.html",
    "href": "semuahalaman/modulprak/2023/genap/pdnum/pdnum2023.html",
    "title": "Praktikum Persamaan Diferensial Numerik 2023 Genap",
    "section": "",
    "text": "Kembali ke Praktikum\nModul ini adalah salinan dari: https://github.com/carlesoctav/pdnum-2023\n\nTimeline\n\npraktikum-1: 1 Maret 2023, presensi [TODO: link]\npraktikum-2, praktikum-2.2: 8 Maret 2023, presensi [TODO: link]\npraktikum-3: 15 Maret 2023, presensi[TODO: link]\nTugas-1 (PDNUM): 22 Maret 2023, tempat pengumpulan: https://bit.ly/Tugas1PrakPDNum\nTugas-2 (PDNUM): 16 April 2023, tempat pengumpulan: https://bit.ly/Tugas2PrakPDNum\nTugas-3 (PDNUM): 16 April 2023, tempat pengumpulan: https://ristek.link/Tugas3PrakPDNum\npraktikum-5 : 3 Mei 2023, presensi bit.ly/PresensiPrak5PDNum\npraktikum-6\ntugas-akhir"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/strukdat2023.html",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/strukdat2023.html",
    "title": "Praktikum Struktur Data 2023 Ganjil dengan C",
    "section": "",
    "text": "Kembali ke Praktikum"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/strukdat2023.html#part-1-sebelum-uts",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/strukdat2023.html#part-1-sebelum-uts",
    "title": "Praktikum Struktur Data 2023 Ganjil dengan C",
    "section": "Part 1: Sebelum UTS",
    "text": "Part 1: Sebelum UTS\nPsst… UTS Struktur Data itu “jenis” soalnya sama seperti ujian Alprog: ada beberapa soal pilihan ganda serta satu/dua soal esai berupa menulis pseudocode. Kalau kalian lancar di praktikum, mungkin UTS kalian akan lancar jaya~ aamiin.\n\nModul 0: Instalasi dan konfigurasi software\nModul 1: Pengenalan bahasa C: data, ekspresi, pernyataan, dan alur logika\nModul 2: Array, fungsi, struct, dan proses kompilasi\nModul 3: Operasi array, algoritma searching dan sorting\nModul 4: Pointer, memori, CodeChef, input dan manipulasi string\n\nModul 4a (opsional): ASCII, Unicode, inttypes.h, dan manipulasi text file\nModul 4b (opsional): membuat command-line interface (CLI) dengan argv\n\nModul 5: Linked-list dengan struct dan pointer\n\nModul 5a (opsional): Pengenalan graphviz dan visualisasi berbagai jenis linked-list"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/strukdat2023.html#part-2-setelah-uts",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/strukdat2023.html#part-2-setelah-uts",
    "title": "Praktikum Struktur Data 2023 Ganjil dengan C",
    "section": "Part 2: Setelah UTS",
    "text": "Part 2: Setelah UTS\nSemangat terus ya! Setelah mempelajari dasar-dasar bahasa pemrograman C, hingga array dan linked list, kalian akan mempelajari struktur data yang lebih kompleks, yang sebenarnya memanfaatkan konsep array maupun linked list.\n\nModul 6: Stack (tumpukan)\n\nModul 6a (opsional): notasi prefix, infix, dan postfix\n\nModul 7: Queue (antrian)\nModul 8: Binary Tree, Binary Search Tree (BST), dan N-ary Tree\n\nModul 8a (opsional): DFS (depth-first search) dan BFS (breadth-first search) untuk tree\nModul 8b (opsional): Visualisasi sembarang binary tree dengan graphviz\nModul 8c (opsional): Visualisasi sembarang N-ary tree dengan graphviz\n\nModul 9: “Balance Tree” (AVL), Max Heap, Min Heap, dan B-Tree\n\nModul 9a (opsional): Konversi antara bentuk array (BFS) dan bentuk pointer untuk sembarang binary tree, termasuk heap\nModul 9b (opsional): Visualisasi B-Tree dengan graphviz\n\nModul 10: Pengantar database (basis data) dengan SQLite"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/strukdat2023.html#part-3-pengayaan-python",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/strukdat2023.html#part-3-pengayaan-python",
    "title": "Praktikum Struktur Data 2023 Ganjil dengan C",
    "section": "Part 3 (pengayaan): Python",
    "text": "Part 3 (pengayaan): Python\nMeskipun semua materi pada bagian ini bersifat pengayaan dan tidak akan dibahas di sesi praktikum, ada baiknya tetap dibaca untuk sekadar menambah wawasan. (Apabila Anda nekat berniat menggunakan bahasa pemrograman Python untuk proyek akhir Struktur Data, semoga materi pengayaan ini membantu.)\n\nModul 11: Struktur data yang khas Python\nModul 12: Pengantar OOP dengan class di Python, pengganti struct di C\nModul 13: I/O dan text file di Python\nModul 14: Visualisasi tree (pohon) dengan graphviz di Python"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html",
    "title": "Modul 4: Pointer, memori, CodeChef, input dan manipulasi string",
    "section": "",
    "text": "Kembali ke Struktur Data"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#pass-by-value-vs.-pass-by-reference",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#pass-by-value-vs.-pass-by-reference",
    "title": "Modul 4: Pointer, memori, CodeChef, input dan manipulasi string",
    "section": "Pass by value vs. pass by reference",
    "text": "Pass by value vs. pass by reference\nDengan adanya pointer, bahkan kita bisa memasukkan alamat ke dalam fungsi, sehingga fungsi tersebut akan memanipulasi data yang ada pada alamat tersebut. Contohnya, perhatikan kedua fungsi “addfive” berikut yang menambahkan lima ke sembarangan bilangan bulat.\nint addfive_notinplace(int number) {\n    int result = number + 5;\n    return result;\n}\n\nvoid addfive_inplace(int * numberptr) {\n    int result = *numberptr + 5;\n    *numberptr = result;\n}\nPerhatikan bahwa ada dua variasi, yaitu “in-place” dan “not-in-place” (juga disebut out-of-place). Berikut beberapa perbedaannya:\n\nInput yang diterima oleh versi “not-in-place” akan berupa nilai bilangan bulat seperti biasanya, tetapi input yang diterima oleh versi “in-place” akan berupa alamat (jangan lupa, pointer menyimpan alamat).\nVersi “in-place” memanfaatkan pointer sehingga bisa langsung mengakses data yang sesungguhnya, sedangkan versi “not-in-place” tidak memanfaatkan pointer sama sekali.\nVersi “in-place” langsung memanipulasi (mengubah) data yang ada pada alamat di pointer yang diberikan. Sedangkan, versi “not-in-place” mengembalikan hasil perhitungan, tanpa memodifikasi data aslinya.\nVersi “not-in-place” mengembalikan hasil berupa int. Sedangkan, versi “in-place” tidak mengembalikan apa-apa, sehingga ditulis return type berupa void (ketiadaan, tidak ada tipe datanya, karena memang tidak ada data yang dikembalikan).\n\nKedua fungsi tersebut bisa digunakan seperti pada kode berikut.\n\n\naddfive.c\n\n#include <stdio.h>\n\nint addfive_notinplace(int number) {\n    int result = number + 5;\n    return result;\n}\n\nvoid addfive_inplace(int * numberptr) {\n    int result = *numberptr + 5;\n    *numberptr = result;\n}\n\nint main () {\n    int a = 27;\n    int b = 27;\n\n    // Perhatikan perbedaan penggunaannya:\n\n    a = addfive_notinplace(a);\n    // - nilainya langsung dimasukkan ke dalam fungsi\n    // - fungsinya mengembalikan hasil untuk memperbarui nilai a\n\n    addfive_inplace(&b);\n    // - yang diberikan adalah alamatnya, sehingga digunakan tanda &\n    // - nilai b akan langsung diubah di tempat, tanpa mengembalikan nilai\n\n    // Hasil berikut ini pasti akan sama\n    printf(\"Hasil a adalah: %d\\n\", a);\n    printf(\"Hasil b adalah: %d\\n\", b);\n\n    return 0;\n}\n\nKetika kita memberikan alamat ke dalam fungsi, istilahnya adalah pass by reference, yaitu memasukkan variabel melalui reference atau alamatnya. Sedangkan, ketika kita langsung memasukkan nilai ke dalam fungsi (seperti yang sudah kita kenal sebelumnya), istilahnya adalah pass by value.\nSeandainya kita mencoba membuat versi “in-place” tanpa memanfaatkan pointer (sehingga tidak menggunakan alamat), pasti akan gagal. Perhatikan kode berikut.\n\n\naddfivefail.c\n\n#include <stdio.h>\n\nvoid addfive_fail(int number) {\n    int result = number + 5;\n    number = result;\n}\n\nint main() {\n    int c = 27;\n\n    // Coba aja...\n    addfive_fail(c);\n\n    printf(\"Hasil c adalah: %d\\n\", c);\n    // Ternyata tidak berubah\n\n    return 0;\n}"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#fungsi-swap_int-untuk-menukar-dua-integer",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#fungsi-swap_int-untuk-menukar-dua-integer",
    "title": "Modul 4: Pointer, memori, CodeChef, input dan manipulasi string",
    "section": "Fungsi swap_int untuk menukar dua integer",
    "text": "Fungsi swap_int untuk menukar dua integer\nSeperti pada contoh di atas, salah satu keunggulan pointer adalah bisa memberi akses langsung ke data aslinya dari dalam fungsi. Tentu saja, suatu fungsi bisa menerima input berupa lebih dari satu pointer (lebih tepatnya, lebih dari satu alamat). Bahkan, kita bisa membuat fungsi swap_int yang menerima dua alamat dari dua variabel yang sama-sama berupa int, lalu menukar nilai aslinya dari dalam fungsi. Dengan demikian, daripada harus seringkali manual membuat variabel temp untuk menukar dua nilai, kita bisa membuat kodenya sekali saja di dalam fungsi swap_int, sehingga untuk ke depannya tinggal menggunakan fungsi swap_int.\nvoid swap_int(int * ptr1, int * ptr2) {\n    int temp = *ptr1;\n    *ptr1 = *ptr2;\n    *ptr2 = temp;\n}\nFungsi swap_int demikian menjadi suatu fungsi in-place. Berikut contoh penggunaannya:\n\n\nswapint.c\n\n#include <stdio.h>\n\nvoid swap_int(int * ptr1, int * ptr2) {\n    int temp = *ptr1;\n    *ptr1 = *ptr2;\n    *ptr2 = temp;\n}\n\nint main() {\n    int x = 15;\n    int y = 9;\n\n    swap_int(&x, &y);\n    // Fungsi yang bersifat in-place memang umumnya digunakan seperti itu\n\n    printf(\"Nilai x baru: %d\\n\", x);\n    printf(\"Nilai y baru: %d\\n\", y);\n\n    return 0;\n}"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#array-adalah-pointer-ke-elemen-pertama",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#array-adalah-pointer-ke-elemen-pertama",
    "title": "Modul 4: Pointer, memori, CodeChef, input dan manipulasi string",
    "section": "Array adalah pointer ke elemen pertama",
    "text": "Array adalah pointer ke elemen pertama\n(write some code to assign an array to another array apparently, even though then you are actually assigning a pointer to another pointer. For example assign a string to another string, or to a char pointer. Then try to access from the second pointer, and even modify from the second pointer, then check the new value from the first pointer)"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#pointer-arithmetic-penjumlahanpengurangan-pointer",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#pointer-arithmetic-penjumlahanpengurangan-pointer",
    "title": "Modul 4: Pointer, memori, CodeChef, input dan manipulasi string",
    "section": "Pointer arithmetic: penjumlahan/pengurangan pointer",
    "text": "Pointer arithmetic: penjumlahan/pengurangan pointer\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#typecasting-untuk-pointer-mengubah-tipe-data-yang-ditunjuk",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#typecasting-untuk-pointer-mengubah-tipe-data-yang-ditunjuk",
    "title": "Modul 4: Pointer, memori, CodeChef, input dan manipulasi string",
    "section": "Typecasting untuk pointer: mengubah tipe data yang ditunjuk",
    "text": "Typecasting untuk pointer: mengubah tipe data yang ditunjuk\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#char-pointer-sebagai-pointer-satuan-satu-byte",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#char-pointer-sebagai-pointer-satuan-satu-byte",
    "title": "Modul 4: Pointer, memori, CodeChef, input dan manipulasi string",
    "section": "char pointer sebagai “pointer satuan” (satu byte)",
    "text": "char pointer sebagai “pointer satuan” (satu byte)\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#penggunaan-memori-sementara-malloc-dan-free",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#penggunaan-memori-sementara-malloc-dan-free",
    "title": "Modul 4: Pointer, memori, CodeChef, input dan manipulasi string",
    "section": "Penggunaan memori sementara: malloc dan free",
    "text": "Penggunaan memori sementara: malloc dan free\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#variasi-malloc-calloc-realloc",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#variasi-malloc-calloc-realloc",
    "title": "Modul 4: Pointer, memori, CodeChef, input dan manipulasi string",
    "section": "Variasi malloc: calloc, realloc",
    "text": "Variasi malloc: calloc, realloc\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#pengenalan-segmentation-fault",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#pengenalan-segmentation-fault",
    "title": "Modul 4: Pointer, memori, CodeChef, input dan manipulasi string",
    "section": "Pengenalan segmentation fault",
    "text": "Pengenalan segmentation fault\nSegmentation fault (sering juga disebut segfault atau SIGSEGV) adalah error yang menandakan adanya masalah pada alokasi memori dinamis, seperti:\n\nmalloc?\nfreeing the nonexistent or the already freed\n\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#memset-untuk-menyeragamkan-sejumlah-byte",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#memset-untuk-menyeragamkan-sejumlah-byte",
    "title": "Modul 4: Pointer, memori, CodeChef, input dan manipulasi string",
    "section": "memset untuk “menyeragamkan” sejumlah byte",
    "text": "memset untuk “menyeragamkan” sejumlah byte\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#memcpy-untuk-menduplikasi",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#memcpy-untuk-menduplikasi",
    "title": "Modul 4: Pointer, memori, CodeChef, input dan manipulasi string",
    "section": "memcpy untuk menduplikasi",
    "text": "memcpy untuk menduplikasi\n(termasuk duplikasi struct! :D)"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#pointer-ke-struct",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#pointer-ke-struct",
    "title": "Modul 4: Pointer, memori, CodeChef, input dan manipulasi string",
    "section": "Pointer ke struct",
    "text": "Pointer ke struct\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#notasi--",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#notasi--",
    "title": "Modul 4: Pointer, memori, CodeChef, input dan manipulasi string",
    "section": "Notasi ->",
    "text": "Notasi ->\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#pointer-di-dalam-struct",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#pointer-di-dalam-struct",
    "title": "Modul 4: Pointer, memori, CodeChef, input dan manipulasi string",
    "section": "Pointer di dalam struct",
    "text": "Pointer di dalam struct\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#automatic-memory-allocation-vs.-dynamic-memory-allocation",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#automatic-memory-allocation-vs.-dynamic-memory-allocation",
    "title": "Modul 4: Pointer, memori, CodeChef, input dan manipulasi string",
    "section": "Automatic memory allocation vs. dynamic memory allocation",
    "text": "Automatic memory allocation vs. dynamic memory allocation\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#function-yang-mengembalikan-pointer",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#function-yang-mengembalikan-pointer",
    "title": "Modul 4: Pointer, memori, CodeChef, input dan manipulasi string",
    "section": "Function yang mengembalikan pointer",
    "text": "Function yang mengembalikan pointer\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#function-pointer-pointer-ke-fungsi",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#function-pointer-pointer-ke-fungsi",
    "title": "Modul 4: Pointer, memori, CodeChef, input dan manipulasi string",
    "section": "Function pointer: pointer ke fungsi",
    "text": "Function pointer: pointer ke fungsi\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#menerima-input-buffer-fgets-dan-sscanf",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#menerima-input-buffer-fgets-dan-sscanf",
    "title": "Modul 4: Pointer, memori, CodeChef, input dan manipulasi string",
    "section": "Menerima input: buffer, fgets, dan sscanf",
    "text": "Menerima input: buffer, fgets, dan sscanf\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#menyimpan-formatted-string-snprintf",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#menyimpan-formatted-string-snprintf",
    "title": "Modul 4: Pointer, memori, CodeChef, input dan manipulasi string",
    "section": "Menyimpan formatted string: snprintf",
    "text": "Menyimpan formatted string: snprintf\nblabla (the main use of snprintf is indeed to store a formatted string instead of printing it with printf, so it’s like printf but to a string instead of to the console/stdin)"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#snprintf-untuk-copy-dan-penggabungan-string",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#snprintf-untuk-copy-dan-penggabungan-string",
    "title": "Modul 4: Pointer, memori, CodeChef, input dan manipulasi string",
    "section": "snprintf untuk copy dan penggabungan string",
    "text": "snprintf untuk copy dan penggabungan string\nSelain untuk menyimpan formatted string, snprintf ternyata juga bisa digunakan untuk meng-copy sebuah string maupun menggabungkan dua string.\n(blablabla, sebenarnya juga bisa dilakukan dengan memcpy? iya kah? blablabla)"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#pengenalan-codechef",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#pengenalan-codechef",
    "title": "Modul 4: Pointer, memori, CodeChef, input dan manipulasi string",
    "section": "Pengenalan CodeChef",
    "text": "Pengenalan CodeChef\nCodeChef adalah blablabla\nNanti kalian akan menggunakan CodeChef untuk proyek, mencari soal, blablabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#problem-1-number-mirror-start01",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#problem-1-number-mirror-start01",
    "title": "Modul 4: Pointer, memori, CodeChef, input dan manipulasi string",
    "section": "Problem 1: “Number Mirror” (START01)",
    "text": "Problem 1: “Number Mirror” (START01)\nlink soal: https://www.codechef.com/problems/START01\nContoh penyelesaian:\n\n\nstart01.c\n\n#include <stdio.h>\n\nint main() {\n    const size_t BUFFER_SIZE = 1000;\n    char buffer[BUFFER_SIZE];\n    \n    int number;\n    \n    fgets(buffer, BUFFER_SIZE, stdin);\n    sscanf(buffer, \"%d\", &number);\n    \n    printf(\"%d\", number);\n    \n    return 0;\n}"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#problem-2-add-two-numbers-flow001",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04.html#problem-2-add-two-numbers-flow001",
    "title": "Modul 4: Pointer, memori, CodeChef, input dan manipulasi string",
    "section": "Problem 2: “Add Two Numbers” (FLOW001)",
    "text": "Problem 2: “Add Two Numbers” (FLOW001)\nlink: https://www.codechef.com/problems/FLOW001\nContoh penyelesaian:\n\n\nflow001.c\n\n#include <stdio.h>\n\nint main() {\n    const size_t BUFFER_SIZE = 1000;\n    char buffer[BUFFER_SIZE];\n    \n    int T;\n    fgets(buffer, BUFFER_SIZE, stdin);\n    sscanf(buffer, \"%d\", &T);\n    \n    int a, b, result;\n    for (int i = 0; i < T; i++) {\n        fgets(buffer, BUFFER_SIZE, stdin);\n        sscanf(buffer, \"%d %d\", &a, &b);\n        result = a + b;\n        printf(\"%d\\n\", result);\n    }\n    \n    return 0;\n}"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul02.html",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul02.html",
    "title": "Modul 2 Struktur Data: Array, fungsi, struct, dan proses kompilasi",
    "section": "",
    "text": "Kembali ke Struktur Data"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul02.html#array",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul02.html#array",
    "title": "Modul 2 Struktur Data: Array, fungsi, struct, dan proses kompilasi",
    "section": "Array",
    "text": "Array\nblabla\n(jangan lupa ukuran array dengan sizeof)"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul02.html#char-huruf-putchar-dan-getchar",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul02.html#char-huruf-putchar-dan-getchar",
    "title": "Modul 2 Struktur Data: Array, fungsi, struct, dan proses kompilasi",
    "section": "char (huruf), putchar, dan getchar",
    "text": "char (huruf), putchar, dan getchar\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul02.html#string-puts-fgets-strlen-dan-strcmpstrncmp",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul02.html#string-puts-fgets-strlen-dan-strcmpstrncmp",
    "title": "Modul 2 Struktur Data: Array, fungsi, struct, dan proses kompilasi",
    "section": "string, puts, fgets, strlen, dan strcmp/strncmp",
    "text": "string, puts, fgets, strlen, dan strcmp/strncmp\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul02.html#menampilkan-semua-elemen-pada-array",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul02.html#menampilkan-semua-elemen-pada-array",
    "title": "Modul 2 Struktur Data: Array, fungsi, struct, dan proses kompilasi",
    "section": "Menampilkan semua elemen pada array",
    "text": "Menampilkan semua elemen pada array\nUntuk menampilkan semua elemen yang ada di dalam suatu array, kita perlu melakukan iterasi pada tiap elemen di array, lalu menggunakan printf pada tiap iterasi. Agar mengetahui batasan for loop, kita perlu mengetahui panjang array. Kita bisa membuat fungsi yang mem-print satu per satu elemen suatu array sampai panjang array tersebut.\nvoid array_int_print(int arr[], int arr_length) {\n    for (int i = 0; i < arr_length; i++) {\n        printf(\"%d \", arr[i]);\n    }\n}"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul02.html#mendalami-proses-kompilasi-program",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul02.html#mendalami-proses-kompilasi-program",
    "title": "Modul 2 Struktur Data: Array, fungsi, struct, dan proses kompilasi",
    "section": "Mendalami proses kompilasi program",
    "text": "Mendalami proses kompilasi program\n(diagram, empat langkah, caranya satu-satu di gcc)\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul02.html#preprocessor-directive-dan-header-file-.h",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul02.html#preprocessor-directive-dan-header-file-.h",
    "title": "Modul 2 Struktur Data: Array, fungsi, struct, dan proses kompilasi",
    "section": "Preprocessor directive dan header file (.h)",
    "text": "Preprocessor directive dan header file (.h)\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul02.html#build-system-make-kompilasi-otomatis-dengan-makefile",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul02.html#build-system-make-kompilasi-otomatis-dengan-makefile",
    "title": "Modul 2 Struktur Data: Array, fungsi, struct, dan proses kompilasi",
    "section": "Build system make: kompilasi otomatis dengan Makefile",
    "text": "Build system make: kompilasi otomatis dengan Makefile\nSumber referensi yang digunakan untuk materi pada bagian ini:\n\nHow to Create a Simple Makefile - Introduction to Makefiles\nhttps://www.youtube.com/watch?v=_r7i5X0rXJk\nMakefiles: 95% of what you need to know\nhttps://www.youtube.com/watch?v=DtGrdB8wQ_8\nhttps://github.com/gwu-cs-os/evening_os_hour/tree/master/f19/10.2-makefiles\n\nContoh Makefile 1 (tanpa variabel):\n# this is a comment\n\n## general format:\n\n# target: its dependencies\n#   command to build target from its dependencies\n\n## ^ tab character\n\n# if you only type \"make\",\n# it's going to execute the top most command,\n# which, in here, happens to be \"all\"\nall: helloworld\n\nhelloworld: helloworld.o dothing.o\n    gcc helloworld.o dothing.o -o helloworld\n\nhelloworld.o: helloworld.c\n    gcc -c helloworld.c\n\ndothing.o: dothing.c\n    gcc -c dothing.c\n\nclean:\n    rm helloworld *.o\n\ncleano:\n    rm *.o\nContoh Makefile 2 (dengan variabel):\n# this is a comment\n\n# === VARIABLES ===\n\n## general format:\n\n# VARNAME=word1 word2 word3\n# no space before NOR after the equal sign!\n# make sure NOT A SINGLE LINE ends with a trailing space!!\n# the variables will later be accessed with $(VARNAME)\n\n##\n\nCOMPILER=gcc\n\nCFILES=helloworld.c dothing.c\nOBJFILES=helloworld.o dothing.o\nBINARYNAME=helloworld\n\n# === COMMANDS ===\n\n## general format:\n\n# target: dependency\n#   command\n\n## ^ tab character\n\n# $@ refers to the target\n# $^ refers to the dependency\n\n# if you only type \"make\",\n# it's going to execute the top most command,\n# which, in here, happens to be \"all\"\nall: $(BINARYNAME)\n\n$(BINARYNAME): $(OBJFILES)\n    $(COMPILER) $(OBJFILES) -o $(BINARYNAME)\n\n%.o: %.c\n    $(COMPILER) -c $^ -o $@\n\nclean:\n    rm $(BINARYNAME) $(OBJFILES)\n\ncleano:\n    rm $(OBJFILES)\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul02.html#referensi-tambahan-cmake",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul02.html#referensi-tambahan-cmake",
    "title": "Modul 2 Struktur Data: Array, fungsi, struct, dan proses kompilasi",
    "section": "Referensi tambahan: CMake",
    "text": "Referensi tambahan: CMake\nKita telah belajar cara membuat Makefile secara manual dan menggunakannya. Sejauh ini, Makefile yang kita buat melibatkan beberapa variabel yang perlu kita setting secara manual. Untuk program dan proyek skala kecil seperti di mata kuliah Struktur Data, itu tidak masalah.\nSebenarnya, sudah ada software untuk membuat Makefile secara otomatis, yaitu CMake. Bahkan, CMake bisa menghasilkan Makefile untuk berbagai sistem operasi yang memiliki berbagai macam ketergantungan yang berbeda-beda. Namun, cara penggunaannya bisa agak sulit, sehingga tidak kami ajarkan di praktikum untuk menghemat waktu. Anda bisa membaca lebih lanjut tentang CMake di internet, seperti di link berikut:\nhttps://earthly.dev/blog/cmake-vs-make-diff/"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul02.html#faq-seputar-pembuatan-aplikasi-cli-gui-installer",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul02.html#faq-seputar-pembuatan-aplikasi-cli-gui-installer",
    "title": "Modul 2 Struktur Data: Array, fungsi, struct, dan proses kompilasi",
    "section": "FAQ seputar pembuatan aplikasi: CLI, GUI, installer",
    "text": "FAQ seputar pembuatan aplikasi: CLI, GUI, installer\nSampai sini, kita sudah bisa mengkompilasi program C ke dalam bentuk executable, hingga menggabungkan beberapa file yang berbeda dengan bantuan header file. Bahkan, kita sudah mempelajari penggunaan build system seperti make agar proses kompilasi bisa dilakukan secara otomatis.\nSejauh ini, semua program yang kita buat melibatkan command line (juga disebut command prompt atau terminal), karena perlu menampilkan output dan menerima input. Bisa dikatakan, tampilan seperti itu adalah semacam “perantara”, atau istilahnya “antarmuka” (interface), agar kita bisa “berkomunikasi” dengan program atau aplikasi tersebut. Antarmuka seperti itu disebut command-line interface (CLI).\n(Sebenarnya, istilah “command-line interface” umumnya digunakan untuk program yang sudah dirancang agar bisa merespon dengan baik terhadap berbagai macam input. Bahkan, daripada hanya mengetik ./namaprogram, kita bisa langsung memberi input di sebelah nama programnya, misalnya ./namaprogram input1 input2. Cara membuat fitur seperti ini di bahasa pemrograman C dibahas di Modul opsional 4b.)\n\n\n\n\n\n\nApakah ada program tanpa antarmuka?\n\n\n\nIya, ada, tidak mustahil. Mungkin terdengar aneh, program yang tidak memberikan output di command line maupun menerima input, dan terdengar tidak berguna. Biasanya, program seperti itu melakukan beberapa hal (seperti urusan membuat, mengubah, maupun menghapus file, yang dibahas di Modul opsional 4a) yang sudah ditentukan dan sudah dibuat kodenya sehingga tidak perlu menerima informasi tambahan apapun (sehingga tidak memerlukan input), dan tidak perlu memberikan informasi apapun (sehingga tidak memberikan output).\nNamun, program seperti itu jarang ada, dan biasanya dibuat untuk kepentingan pribadi saja.\n\n\nMungkin dalam kehidupan sehari-hari, kalian lebih terbiasa dengan aplikasi yang memiliki semacam tampilan dengan tombol-tombol yang bisa ditekan dan sebagainya. Tampilan atau antarmuka seperti itu disebut graphical user interface (GUI).\nBeberapa aplikasi memiliki CLI, seperti aplikasi atau program yang kita buat selama praktikum. Beberapa aplikasi memiliki GUI, seperti aplikasi yang biasa kalian gunakan di kehidupan sehari-hari. Beberapa aplikasi memiliki CLI dan GUI (biasanya kita bisa memilih di antara keduanya), dan ada juga aplikasi yang tidak memiliki keduanya (sudah dibahas di atas).\nBerikut adalah beberapa pertanyaan umum seputar pembuatan aplikasi serta jawabannya.\n\nSaya ingin program saya memiliki GUI, bagaimana caranya?\n\nUntuk itu, Anda perlu menginstal “library” (kumpulan kode yang dibuat oleh orang lain) yang diperuntukkan untuk membuat GUI, contohnya GTK. Pada umumnya, library memiliki “dokumentasi” (penjelasan tentang cara penggunaannya), sehingga Anda bisa mempelajari cara menggunakan library tersebut untuk membuat GUI. Tiap library menyediakan fungsi-fungsi yang bisa digunakan, yang bisa “diaktifkan” menggunakan #include, sebagaimana kita mengaktifkan fitur printf dengan #include <stdio.h>.\nLibrary untuk GUI, seperti GTK, memiliki fungsi-fungsi tersendiri untuk merancang GUI. Bahkan, dua library dengan kegunaan yang sama (misalnya sama-sama untuk membuat GUI) bisa memiliki fungsi-fungsi yang berbeda, hinggga cara penggunaan yang jauh berbeda, dan masing-masing memiliki kelebihan dan kekurangan tersendiri.\nSelama praktikum Struktur Data, tidak ada pembahasan tentang cara membuat GUI. Namun, kita akan menggunakan library seperti SQLite untuk kegunaan lainnya (cara menginstal ada di Modul 0).\n\nDi macOS, setelah kompilasi, hasilnya adalah suatu executable atau program yang bisa dijalankan, tetapi tampaknya tidak seperti aplikasi yang biasa saya gunakan. (Sedangkan, di Windows, hasil kompilasi sudah berupa file .exe seperti aplikasi yang biasa digunakan.) Mengapa demikian?\n\nYup betul, memang ada sedikit perbedaan antara Windows dan macOS dalam hal ini. Aplikasi yang biasa digunakan di macOS (dan bisa diinstal dari App Store) berupa file .app (juga disebut app bundle), sedangkan hasil kompilasi gcc berupa executable file yang… tidak memiliki akhiran/extension. Namun, app bundle bisa dibuat secara manual, karena sebenarnya app bundle adalah semacam file .zip yang isinya terdiri dari beberapa folder, dan di dalamnya terdiri dari executable juga.\nBerikut video yang membahas cara membuat app bundle secara manual.\n“How to create an app bundle with dynamically linked libraries on macOS”\nhttps://www.youtube.com/watch?v=ny1Na1oOsb8\n\nBagaimana cara membuat installer?\n\n\n\n\n\n\n\nTL;DR / ringkasan\n\n\n\n\n\nPelajari dulu cara menggunakan CMake, lalu ikuti petunjuk di link berikut:\nhttps://cmake.org/cmake/help/book/mastering-cmake/chapter/Packaging%20With%20CPack.html\n\n\n\nBisa dikatakan, sebenarnya Makefile sudah termasuk semacam installer. Bahkan, beberapa program di macOS (dan Linux) lazim diinstal menggunakan command ./configure lalu make lalu make install, yang memanfaatkan Makefile. Ini sering ditemukan di proyek open source yang ada di GitHub misalnya.\nNamun, installer yang sering dijumpai bisa berupa\n\n.exe atau .msi di Windows\n.pkg di macOS\n\n(File .dmg atau DMG lebih sering ditemukan di macOS daripada .pkg, tetapi DMG sebenarnya hanyalah sejenis .zip yang dikhususkan untuk penyimpanan aplikasi. Meskipun demikian, isi suatu DMG bisa berupa .app maupun .pkg, sehingga DMG juga terkadang disebut installer.)\nSeperti pembuatan GUI, pembuatan installer sudah di luar cakupan praktikum Struktur Data. Salah satu cara membuat installer adalah melalui CMake, dengan salah satu fiturnya yang bernama CPack, yang bisa membuat berbagai jenis installer seperti .exe, .pkg, dan .dmg. Anda bisa mempelajarinya lebih lanjut di link berikut:\nhttps://cmake.org/cmake/help/book/mastering-cmake/chapter/Packaging%20With%20CPack.html"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul03.html",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul03.html",
    "title": "Modul 3 Struktur Data: Operasi array, algoritma searching dan sorting",
    "section": "",
    "text": "Kembali ke Struktur Data"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul03.html#linear-search",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul03.html#linear-search",
    "title": "Modul 3 Struktur Data: Operasi array, algoritma searching dan sorting",
    "section": "Linear search",
    "text": "Linear search\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul03.html#binary-search",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul03.html#binary-search",
    "title": "Modul 3 Struktur Data: Operasi array, algoritma searching dan sorting",
    "section": "Binary search",
    "text": "Binary search\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul03.html#bubble-sort",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul03.html#bubble-sort",
    "title": "Modul 3 Struktur Data: Operasi array, algoritma searching dan sorting",
    "section": "Bubble sort",
    "text": "Bubble sort\nBubble sort adalah suatu algoritma sorting yang dilakukan berkali-kali sampai array sudah terurut dengan benar, di mana tiap elemen diperiksa dengan sebelahnya, kemudian ditukar apabila urutan di antara keduanya belum benar. Ketika melakukan bubble sort, kita bisa yakin bahwa array sudah terurut apabila sudah tidak terjadi pertukaran sama sekali ketika memeriksa kembali semua elemen array dari awal sampai akhir.\nDengan konsep di atas, kita bisa membuat fungsi bubble sort seperti berikut.\nvoid array_int_bubblesort1_asc(int arr[], size_t arr_length) {\n    bool terjadi_pertukaran = true; // asumsi array belum terurut\n\n    // ulangi selama masih terjadi pertukaran\n    while (terjadi_pertukaran) {\n        terjadi_pertukaran = false;\n        // asumsi tidak akan terjadi pertukaran,\n        // akan diubah menjadi true ketika terjadi pertukaran\n\n        // for loop untuk melihat tiap elemen dari awal sampai akhir\n        for (int i = 0; i < (int)arr_length-1; i++) {\n            if (arr[i] > arr[i+1]) { // apabila ada yang harus ditukar\n                // maka tukarlah\n                int temp = arr[i];\n                arr[i] = arr[i+1];\n                arr[i+1] = temp;\n\n                // terjadi pertukaran\n                terjadi_pertukaran = true;\n            }\n        }\n    }\n}\nPerhatikan bahwa fungsi di atas memiliki return type berupa void, yang artinya tidak ada yang di-return. Bahkan, elemen array langsung ditukar menggunakan array yang dimasukkan ke dalam fungsi. Di bahasa pemrograman C, ada sesuatu yang spesial tentang array sehingga array bisa langsung dimanipulasi dari dalam fungsi. Hal ini akan dibahas di pertemuan selanjutnya bersama pointer.\nIntinya, terima saja dulu, bahwa ketika array masuk sebagai input fungsi, maka apapun yang dilakukan pada array tersebut di dalam fungsinya akan benar-benar mengubah array yang sesungguhnya.\nDengan demikian, penggunaan fungsi di atas bisa seperti berikut:\n\n\nbubblesort1.c\n\n#include <stdio.h>\n#include \"prakmodul2.h\"\n\n// deklarasi fungsi\nvoid array_int_bubblesort1_asc(int arr[], size_t arr_length);\n// fungsi ini akan didefinisikan setelah definisi fungsi main\n\nint main () {\n    int array1[] = {10, 3, 8, 4, 5, 7, 9, 6};\n    size_t panjang1 = sizeof(array1)/sizeof(array1[0]);\n\n    printf(\"Sebelum bubble sort: \");\n    array_int_print(array1, panjang1);\n    printf(\"\\n\");\n\n    printf(\"Setelah bubble sort: \");\n    array_int_bubblesort1_asc(array1, panjang1);\n    array_int_print(array1, panjang1);\n\n    return 0;\n}\n\n// definisi fungsi\nvoid array_int_bubblesort1_asc(int arr[], size_t arr_length) {\n    bool terjadi_pertukaran = true; // asumsi array belum terurut\n\n    // ulangi selama masih terjadi pertukaran\n    while (terjadi_pertukaran) {\n        terjadi_pertukaran = false;\n        // asumsi tidak akan terjadi pertukaran,\n        // akan diubah menjadi true ketika terjadi pertukaran\n\n        // for loop untuk melihat tiap elemen dari awal sampai akhir\n        for (int i = 0; i < (int)arr_length-1; i++) {\n            if (arr[i] > arr[i+1]) { // apabila ada yang harus ditukar\n                // maka tukarlah\n                int temp = arr[i];\n                arr[i] = arr[i+1];\n                arr[i+1] = temp;\n\n                // terjadi pertukaran\n                terjadi_pertukaran = true;\n            }\n        }\n    }\n}\n\nPerhatikan bahwa… (basically lead to optimizing bubble sort, provide two other variations as per the wikipedia page)"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul03.html#selection-sort",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul03.html#selection-sort",
    "title": "Modul 3 Struktur Data: Operasi array, algoritma searching dan sorting",
    "section": "Selection sort",
    "text": "Selection sort\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul03.html#insertion-sort",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul03.html#insertion-sort",
    "title": "Modul 3 Struktur Data: Operasi array, algoritma searching dan sorting",
    "section": "Insertion sort",
    "text": "Insertion sort\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul03.html#merge-sort",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul03.html#merge-sort",
    "title": "Modul 3 Struktur Data: Operasi array, algoritma searching dan sorting",
    "section": "Merge sort",
    "text": "Merge sort\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul03.html#quicksort-versi-hoare",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul03.html#quicksort-versi-hoare",
    "title": "Modul 3 Struktur Data: Operasi array, algoritma searching dan sorting",
    "section": "Quicksort versi Hoare",
    "text": "Quicksort versi Hoare\nTony Hoare menerbitkan paper tentang quicksort, yaitu algoritma sorting yang ia buat, pada tahun 1961, yang bisa dilihat di tautan (link) berikut.\n\nhttps://www.cs.ox.ac.uk/files/6226/H2006%20-%20Historic%20Quicksort.pdf\n(link alternatif) http://rabbit.eng.miami.edu/class/een511/quicksort.pdf\n\nSejak itu, sudah ada beberapa variasi quicksort, seperti versi Lomuto. Namun, inti sari dari algoritma quicksort secara umum adalah sebagai berikut:\n\nApabila array ternyata kosong atau hanya terdiri dari satu elemen, diamkan saja, tidak ada yang perlu disortir. Apabila terdiri dari 2+ elemen, lanjut ke langkah selanjutnya.\nPilih salah satu elemen pada array (boleh yang mana saja) sebagai elemen “pivot”. Jangan sampai lupa, baik nilainya maupun indeksnya/letaknya.\nLakukan “partisi”, yaitu pertukaran elemen seperlunya (bahkan elemen pivot boleh ikut ditukar dan dipindahkan) sedemikian sehingga, pada akhirnya,\n\nsemua elemen di sebelah kiri pivot pasti lebih kecil (atau sama dengan) pivot; dan\nsemua elemen di sebelah kanan pivot pasti lebih besar (atau sama dengan) pivot.\n\n“Partisi” yang dimaksud adalah bahwa, setelah proses partisi selesai, array seakan-akan telah terbagi (terpartisi) menjadi tiga bagian, yaitu (dari kiri ke kanan):\n\n“partisi kiri/bawah”, yaitu bagian di sebelah kiri pivot, terdiri dari semua elemen yang lebih kecil (atau sama dengan) pivot;\npivot itu sendiri; dan\n“partisi kanan/atas”, yaitu bagian di sebelah kanan pivot, terdiri dari semua elemen yang lebih besar (atau sama dengan) pivot.\n\nKemudian, memperhatikan letak pivot, lakukan quicksort pada semua elemen di sebelah kiri pivot (yaitu pada partisi kiri), dan lakukan quicksort pada semua elemen di sebelah kanan pivot (yaitu pada partisi kanan).\n\n(Menariknya, Tony Hoare tidak menggunakan istilah “pivot”. Beliau menggunakan istilah “bound” untuk “nilai pivot”, dan menuliskan “the element from which the bound was chosen” ketika bermaksud mengatakan “elemen pivot”.)\nTerlihat dari langkah terakhir, algoritma quicksort bersifat rekursif. Bagian tersulit dari quicksort adalah pada tahapan partisi. Tahapan inilah yang cara melakukannya bisa bervariasi (tidak seperti algoritma sorting lainnya yang cenderung begitu-begitu saja). Tidak hanya itu, bahkan cara memilih pivot bisa saja dengan memilih elemen pertama, elemen tengah, elemen terakhir, atau median dari ketiganya (“median-of-three”), ataupun variasi lainnya.\nDari paper aslinya, penjelasan Tony Hoare tentang cara melakukan partisi (menurut beliau) bisa dirangkum sebagai berikut:\n\nBuat dua “panah”, yaitu “panah bawah” (i) dan “panah atas” (j), di mana panah bawah menunjuk pada elemen pertama dan panah atas menunjuk pada elemen terakhir. (Secara pemrograman, simpan indeksnya saja.) Bisa dibayangkan, ada asumsi array sudah dipartisi, di mana panah bawah akan memastikan partisi kiri sudah benar, dan panah atas akan memastikan partisi kanan sudah benar.\nwhile loop: selama elemen yang ditunjuk oleh panah bawah itu masih lebih kecil atau sama dengan nilai pivot, (dan selama panah bawah belum melewati panah atas,) geser panah bawah satu langkah ke kanan. (Artinya, selama partisi kiri sudah benar, lanjut memeriksa elemen berikutnya yaitu ke kanan. Berhenti ketika ada yang lebih besar dari pivot, sehingga harusnya ada di partisi kanan; menunggu ditukar.)\nwhile loop: selama elemen yang ditunjuk oleh panah atas itu masih lebih besar atau sama dengan nilai pivot, (dan selama panah bawah belum melewati panah atas,) geser panah atas satu langkah ke kiri. (Artinya, selama partisi kanan sudah benar, lanjut memeriksa elemen berikutnya yaitu ke kiri. Berhenti ketika ada yang lebih kecil dari pivot, sehingga harusnya ada di partisi kiri; menunggu ditukar.)\nSampai sini, apabila panah bawah masih belum melewati panah atas, maka ada dua elemen yang menunggu ditukar, yaitu yang ditunjuk oleh panah bawah dan yang ditunjuk oleh panah atas. Maka tukarlah, lalu kembali ke langkah kedua.\nSampai sini, sudah tidak lagi kembali ke langkah kedua, sehingga panah bawah sudah melewati panah atas; sekarang panah atas ada di sebelah kiri dari panah bawah. Bayangkan, di antara dua panah tersebut, ada semacam garis pembagi: dari elemen pertama sampai panah atas adalah “partisi kiri”, sedangkan dari panah bawah sampai elemen terakhir adalah “partisi kanan”.\n\nApabila pivot jatuh pada partisi kiri (indeks pivot <= panah atas), tukarkan elemen pada panah atas dengan elemen pivot. (Lalu, bayangkan bahwa partisi kiri sedikit diperkecil karena elemen pivot tidak boleh masuk ke kedua partisi.)\nSedangkan, apabila pivot berada pada partisi kanan (indeks pivot >= panah bawah), tukarkan elemen pada panah bawah dengan elemen pivot. (Lalu, bayangkan bahwa partisi kanan sedikit diperkecil karena elemen pivot tidak boleh masuk ke kedua partisi.)\n\n(Dengan demikian, letak pivot sekarang berada di perbatasan antara partisi kiri dan partisi kanan.)\nKembalikan indeks letak pivot.\n\nCatatan: apabila, pada langkah keempat, ternyata antara panah bawah maupun panah atas sedang menunjuk ke elemen pivot, maka elemen pivot terlibat dalam pertukaran; jangan lupa mengubah indeks pivot menjadi posisi barunya setelah ditukar.\n(Sebenarnya, Tony Hoare menggunakan istilah lower pointer dan upper pointer untuk kedua panah. Namun, konsep pointer sebenarnya tidak diperlukan sama sekali, dan konsep yang beliau maksud juga bisa digambarkan dengan panah, yang letaknya berupa indeks array.)\nSebelum membuat kode untuk algoritma quicksort versi Tony Hoare, kita perlu membuat fungsi yang akan menentukan elemen pivot berdasarkan array, misalnya memanfaatkan indeks pertama dan/atau indeks terakhir. (Fungsi ini akan bisa diubah-ubah apabila ingin bereksperimen dengan metode pemilihan pivot.)\nint ChoosePivot_idx(int arr[], int low, int high) {\n    int choice_idx = low; // pilih elemen pertama saja lah~\n    return choice_idx;\n}\nBerikut ini, kita akan mencoba menerapkan quicksort versi Tony Hoare, sebelum nantinya mencoba dengan algoritma partisi menurut Lomuto.\nvoid HoarePartition(int arr[], int low, int high) {\n    return;\n}"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul03.html#quicksort-versi-lomuto",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul03.html#quicksort-versi-lomuto",
    "title": "Modul 3 Struktur Data: Operasi array, algoritma searching dan sorting",
    "section": "Quicksort versi Lomuto",
    "text": "Quicksort versi Lomuto\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html",
    "title": "Modul 1 Struktur Data: Pengenalan bahasa C: data, ekspresi, pernyataan, dan alur logika",
    "section": "",
    "text": "Kembali ke Struktur Data\nSelamat datang di praktikum Struktur Data!"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html#hello-world---komponen-dasar-program-c",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html#hello-world---komponen-dasar-program-c",
    "title": "Modul 1 Struktur Data: Pengenalan bahasa C: data, ekspresi, pernyataan, dan alur logika",
    "section": "Hello world! - komponen dasar program C",
    "text": "Hello world! - komponen dasar program C\n\n\nhelloworld.c\n\n#include <stdio.h>\n\nint main() {\n    printf(\"Hello, world!\");\n    return 0;\n}\n\nProgram di atas melakukan… terdiri dari…\nCoba save di folder… kemudian pencet run (code runner)…\nBeberapa variasi…"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html#kompilasi-compilation-dan-eksekusi-execution-atau-running",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html#kompilasi-compilation-dan-eksekusi-execution-atau-running",
    "title": "Modul 1 Struktur Data: Pengenalan bahasa C: data, ekspresi, pernyataan, dan alur logika",
    "section": "Kompilasi (compilation) dan eksekusi (execution atau running)",
    "text": "Kompilasi (compilation) dan eksekusi (execution atau running)\nPerhatikan folder di mana kode Anda tersimpan. Apakah ada file baru dengan nama yang sama seperti nama program, tetapi dengan file extension (akhiran) yang berbeda? Sebenarnya, file itulah yang dibuka oleh komputer Anda.\nTidak seperti Python yang bersifat interpreted, bahasa pemrograman C adalah bahasa pemrograman yang bersifat compiled. Artinya, ketika ingin menguji coba program C yang telah kita buat, ada dua tahapan:\n\nKompilasi (compilation), yaitu mengkonversi program C menjadi bahasa mesin (machine language, bahasa yang langsung bisa dipahami oleh prosesor di komputer Anda, yaitu komponen yang gunanya adalah menjalankan program). Proses kompilasi ini menghasilkan file baru.\nEksekusi (execution atau running), yaitu komputer (lebih tepatnya prosesor) langsung menjalankan program yang telah dikompilasi ke dalam bahasa mesin (yaitu file baru tersebut).\n\nSedangkan, pada bahasa pemrograman yang interpreted, ketika komputer menjalankan program, komputer melakukannya per baris; artinya, untuk tiap baris, komputer perlu memahaminya terlebih dahulu, kemudian melakukan perintah pada baris tersebut. Bolak-balik antara memahami dan melakukan perintah itu dilakukan per baris, dan selalu dilakukan tiap kali program dijalankan. Oleh karena itu, program yang dibuat dengan bahasa pemrograman interpreted seperti Python cenderung lebih pelan daripada yang dibuat dengan bahasa pemrograman compiled seperti C.\nProses kompilasi dilakukan oleh compiler. Compiler untuk bahasa pemrograman C yang paling terkenal adalah gcc (GNU Compiler Collection), yang bisa tersambung langsung dengan Visual Studio Code melalui extension seperti “C/C++” dan “Code Runner”. Dengan extension Code Runner, Anda tinggal menekan tombol run (▶) di sekitar ujung kanan atas aplikasi, lalu gcc akan langsung mengkompilasi program Anda.\nProses kompilasi menghasilkan suatu file yang bisa langsung dijalankan oleh komputer Anda. Untuk model dan merek proseor yang berbeda, bisa jadi ada variasi dalam file hasil compile tersebut, tergantung bahasa mesin yang dipahami oleh prosesor. Untungnya, gcc juga bisa mengkompilasi program ke dalam file format seperti .exe (aplikasi Windows), sehingga hanya bergantung sistem operasi (operating system).\nTiap kali Anda ingin menjalankan suatu program C, proses kompilasi selalu harus dilakukan terlebih dahulu sebelum eksekusi, tidak seperti bahasa pemrograman yang interpreted.\nFun fact: biasanya compiler tidak sekedar mengkompilasi, tetapi juga mencoba melakukan optimisasi (optimization), yaitu mempersingkat dan menyederhanakan program, menghemat semua penggunaan memori dan sebagainya agar program menjadi lebih kecil dan lebih cepat dijalankan tetapi tetap melakukan hal yang sama persis."
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html#output-selain-string-format-specifier",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html#output-selain-string-format-specifier",
    "title": "Modul 1 Struktur Data: Pengenalan bahasa C: data, ekspresi, pernyataan, dan alur logika",
    "section": "Output selain string: format specifier",
    "text": "Output selain string: format specifier\nTentu saja, kemampuan C bukan sekedar mengeluarkan output berupa string. Program C juga bisa mengeluarkan output berupa integer (bilangan bulat), dengan syntax (sintaks; cara penulisan) seperti berikut:\n\n\nhelloint.c\n\n#include <stdio.h>\n\nint main() {\n    printf(\"%d\", 98);\n    return 0;\n}\n\nPada contoh program helloint.c di atas, output yang dikeluarkan adalah suatu bilangan bulat yaitu 98. Adanya tulisan \"%d\" adalah bentuk string formatting, di mana huruf “d” melambangkan tipe data bilangan bulat dalam bentuk desimal (base 10). Artinya, bilangan bulat di sampingnya itu disisipkan ke dalam string, sehingga kita bisa melihat output berupa bilangan bulat tersebut.\nLambang seperti %d disebut format specifier.\nFun fact: huruf “f” dalam istilah printf artinya “formatted”.\nTentu saja, kita dapat menuliskan apapun sebelum dan sesudah format specifier %d tersebut:\n\n\nhelloint2.c\n\n#include <stdio.h>\n\nint main() {\n    printf(\"Anda memasukkan %d yaitu bilangan bulat\", 98);\n    return 0;\n}\n\nBilangan bulat tersebut akan disisipkan di dalam string, sesuai dengan posisi %d.\nBilangan bulat juga bisa negatif:\n\n\nhelloint3.c\n\n#include <stdio.h>\n\nint main() {\n    printf(\"Anda memasukkan %d yaitu bilangan bulat\", -5);\n    return 0;\n}\n\nSelain “d” yang berarti bilangan bulat, huruf “f” artinya float, atau floating-point number. Singkat cerita, tipe data float adalah bilangan yang bisa berupa desimal, sehingga tidak terbatas bilangan bulat saja. (Kalau penasaran detilnya dan mengapa namanya demikian, kalian bisa review kembali materi pertemuan pertama kuliah Metode Numerik, tentang floating-point arithmetic.) Kita dapat membuat program seperti berikut:\n\n\nhellofloat.c\n\n#include <stdio.h>\n\nint main() {\n    printf(\"%f\", 3.14);\n    return 0;\n}\n\ndan kita akan menerima output berupa float yang kita tuliskan, yaitu 3.14. Tentu saja, tipe data float juga bisa negatif:\n\n\nhellofloat2.c\n\n#include <stdio.h>\n\nint main() {\n    printf(\"%f\", -0.618);\n    return 0;\n}\n\nKita bisa menyisipkan lebih dari satu bilangan:\n\n\nhellonum.c\n\n#include <stdio.h>\n\nint main() {\n    printf(\"%d %f %f\", 98, -0.618, 3.14);\n    return 0;\n}\n\nPerhatikan bahwa tiap bilangan di dalam string di atas dipisah dengan spasi. Sehingga, pada output, tiap bilangan akan dipisah dengan spasi.\nPerhatikan apa yang terjadi kalau kita memisahkan proses print menjadi satu bilangan saja per printf:\n\n\nhellonum2.c\n\n#include <stdio.h>\n\nint main() {\n    printf(\"%d\", 98);\n    printf(\"%f\", -0.618);\n    printf(\"%f\", 3.14);\n\n    return 0;\n}\n\n(Catatan: return 0; tidak harus selalu menempel dengan baris-baris sebelumnya. Bahkan, tidak ada baris yang harus saling menempel.)\nTernyata, semua output tetap di baris yang sama. Bahkan, tidak ada spasi yang memisahkan (karena tidak kita tulis). Ada kode khusus untuk membuat baris baru (new line), yaitu \\n. Perhatikan:\n\n\nhellonum3.c\n\n#include <stdio.h>\n\nint main() {\n    printf(\"%d\\n\", 98);\n    printf(\"%f\\n\", -0.618);\n    printf(\"%f\", 3.14);\n\n    return 0;\n}\n\nTiap kali ada \\n, dikeluarkan “output” berupa baris baru. Sehingga, output selanjutnya akan mulai dari baris baru tersebut. Kalau mau, kita bisa memisahkan pembuatan baris baru, seperti berikut:\n\n\nhellonum4.c\n\n#include <stdio.h>\n\nint main() {\n  printf(\"%d\", 98);\n  printf(\"\\n\");\n  printf(\"%f\", -0.618);\n  printf(\"\\n\");\n  printf(\"%f\", 3.14);\n\n  return 0;\n}"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html#escape-sequence-untuk-string",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html#escape-sequence-untuk-string",
    "title": "Modul 1 Struktur Data: Pengenalan bahasa C: data, ekspresi, pernyataan, dan alur logika",
    "section": "Escape sequence untuk string",
    "text": "Escape sequence untuk string\n\\n adalah contoh escape sequence, yaitu kode khusus untuk mem-print hal-hal yang tidak bisa kita ketik begitu saja. Contoh lain, bagaimana caranya kita mem-print output \"Hello world\" dengan tanda kutip? Masalahnya, tanda kutip sudah digunakan untuk menandakan awal dan akhir string, sehingga tidak bisa kita ketik begitu saja. Solusinya, kita gunakan escape sequence lain yaitu \\\" seperti berikut.\n\n\nescapequote.c\n\n#include <stdio.h>\n\nint main() {\n    printf(\"Kita coba print \\\"Hello world!\\\" apakah berhasil?\");\n    return 0;\n}\n\nPerhatikan kalimat berikut.\n\nSejauh ini, kita sudah mempelajari \\n dan \\” yaitu dua contoh escape sequence.\n\nBagaimana caranya kita mem-print keseluruhan kalimat tersebut di C, misalnya tanpa membuat baris baru? Masalanhya ada pada tanda backslash \\ yang memang sudah menjadi ciri khas untuk escape sequence. Kita ingin menampilkan escape sequence tersebut tanpa mengaktifkannya. Solusinya, bahkan tanda backslash itu sendiri bisa “dinonaktifkan” dengan menuliskan \\\\ seperti berikut:\n\n\nescapebackslash.c\n\n#include <stdio.h>\n\nint main() {\n    printf(\"Sejauh ini, kita sudah mempelajari \\\\n dan \\\\\\\" yaitu dua contoh escape sequence.\");\n    return 0;\n}\n\nPerhatikan bahwa, untuk \\n, hanya diperlukan satu backslash agar bisa ditampilkan. Sedangkan, diperlukan dua backslash untuk menampilkan \\\". Seandainya hanya digunakan satu backslash, yaitu mengetik \\\\\", maka output nya akan menjadi seperti berikut,\n\nSejauh ini, kita sudah mempelajari \\n dan \\\n\nkarena, melihat \\\\\", tanda kutip tersebut dianggap sebagai penutup string. Anggapan tersebut bisa kita nonaktifkan menggunakan backslash juga (yang ditambahkan tepat sebelum tanda kutip tersebut), sehingga kita ketik \\\\\\\".\nAda banyak escape sequence lainnya yang tidak dibahas di sini (bisa dicari di Google)."
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html#comment",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html#comment",
    "title": "Modul 1 Struktur Data: Pengenalan bahasa C: data, ekspresi, pernyataan, dan alur logika",
    "section": "Comment",
    "text": "Comment\nDalam pemrograman, comment adalah semacam catatan yang tidak diperhatikan oleh komputer sama sekali; gunanya hanya untuk memudahkan manusia memahami kode. Pada bahasa pemrograman C, ada dua jenis comment, yaitu:\n\nsingle-line (satu baris), yang diawali dengan // dan bisa dituliskan di mana saja. Penggunaan // pada C sama persis dengan penggunaan # pada Python.\nmulti-line (banyak baris), yang diawali dengan /* dan diakhiri dengan */, dan juga bisa ditempatkan di mana saja. Penggunaan ini bahkan lebih fleksibel daripada \"\"\" di Python.\n\nPerhatikan program berikut.\n\n\nhellocomment.c\n\n#include <stdio.h>\n\n// comment tidak harus di dalam main()\n\nint main() {\n    // ini comment\n    printf(\"Hello world!\\n\");\n    /* ini\n    juga\n    comment */\n\n    /*\n    bisa\n    seperti\n    ini\n    */\n\n    printf(\"%d adalah bilangan bulat.\\n\", 22);\n    printf(/* penyusup */ \"%f\\n\", /* tes */ -273.15);\n}\n\nSesuai kegunaannya, semua comment diabaikan oleh C; kode tetap diijalankan seolah-olah tidak ada comment sama sekali."
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html#variabel-dan-tipe-data-bilangan",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html#variabel-dan-tipe-data-bilangan",
    "title": "Modul 1 Struktur Data: Pengenalan bahasa C: data, ekspresi, pernyataan, dan alur logika",
    "section": "Variabel dan tipe data bilangan",
    "text": "Variabel dan tipe data bilangan\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html#operasi-dasar",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html#operasi-dasar",
    "title": "Modul 1 Struktur Data: Pengenalan bahasa C: data, ekspresi, pernyataan, dan alur logika",
    "section": "Operasi dasar",
    "text": "Operasi dasar\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html#konstanta",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html#konstanta",
    "title": "Modul 1 Struktur Data: Pengenalan bahasa C: data, ekspresi, pernyataan, dan alur logika",
    "section": "Konstanta",
    "text": "Konstanta\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html#ukuran-data-dengan-sizeof-dan-size_t",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html#ukuran-data-dengan-sizeof-dan-size_t",
    "title": "Modul 1 Struktur Data: Pengenalan bahasa C: data, ekspresi, pernyataan, dan alur logika",
    "section": "Ukuran data dengan sizeof dan size_t",
    "text": "Ukuran data dengan sizeof dan size_t\nnitip https://stackoverflow.com/questions/19732319/difference-between-size-t-and-unsigned-int\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html#format-specifier-lainnya",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html#format-specifier-lainnya",
    "title": "Modul 1 Struktur Data: Pengenalan bahasa C: data, ekspresi, pernyataan, dan alur logika",
    "section": "Format specifier lainnya",
    "text": "Format specifier lainnya\nSebelumnya, kita sudah menggunakan beberapa format specifier seperti %d, %f, dan %lf. Format specifier lainnya bisa dilihat di link berikut:\nhttps://www.tutorialspoint.com/format-specifiers-in-c"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html#if-else",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html#if-else",
    "title": "Modul 1 Struktur Data: Pengenalan bahasa C: data, ekspresi, pernyataan, dan alur logika",
    "section": "if, else",
    "text": "if, else\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html#tipe-data-boolean",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html#tipe-data-boolean",
    "title": "Modul 1 Struktur Data: Pengenalan bahasa C: data, ekspresi, pernyataan, dan alur logika",
    "section": "Tipe data boolean",
    "text": "Tipe data boolean\n\nPengartian data sebagai nilai kebenaran di bahasa pemrograman C\n\n\nData\nDiartikan sebagai\n\n\n\n\n0 (nol), NULL, \\0\nFalse (salah)\n\n\napapun data lainnya\nTrue (benar)\n\n\n\nAda juga istilah falsy value dan truthy value untuk mengkategorikan jenis data yang diartikan sebagai False dan yang diartikan sebagai True. Dalam hal ini, nol, NULL, dan \\0 adalah falsy values, dan semua data lainnya adalah truthy values.\n(Kita akan berjumpa dengan NULL dan \\0 di sesi praktikum yang akan datang.)\nPerlu diingat, klasifikasi antara data yang termasuk falsy values dan yang termasuk truthy values bisa berbeda-beda antara beberapa bahasa pemrograman. Oleh karena itu, ada semacam “standar” untuk data boolean di bahasa pemrgoraman C, di mana didefinisikan variabel false=0 dan true=1. Untuk menggunakan kedua variabel ini, kita perlu #include <stdbool.h>, yang juga akan memperkenalkan tipe data baru, yaitu bool, sebagai tipe data boolean. (Sudah menjadi standar untuk melakukan include tersebut daripada mendefinisikan kedua variabel secara manual.)\n(kode include stdbool)"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html#switch-case-dan-enum",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html#switch-case-dan-enum",
    "title": "Modul 1 Struktur Data: Pengenalan bahasa C: data, ekspresi, pernyataan, dan alur logika",
    "section": "switch case dan enum",
    "text": "switch case dan enum\nblabla\n(contoh switch case)\nSayangnya, bagian case hanya bisa menggunakan bilangan bulat dan huruf. Untungnya, bahasa pemrograman C memiliki fitur enum (dibaca “inam”) atau enumeration yang bisa digunakan untuk membuat tipe data baru yang sebenarnya merupakan bilangan bulat tetapi bisa dituliskan sebagai semacam variabel. Dengan demikian, kita seolah-olah bisa menggunakan switch case dengan variabel yang tidak terlihat seperti bilangan bulat, atau setidaknya kita bisa mendefinisikan beberapa bilangan bulat sekaligus yang merupakan bilangan bulat untuk digunakan dengan switch case.\nContohnya, kita bisa membuat enum untuk tipe data baru bernama “Hari” seperti berikut.\nenum Hari = {\n    Senin, Selasa, Rabu, Kamis, Jumat, Sabtu, Minggu\n}\nKemudian, enum bisa digunakan dengan switch case, karena Senin, Selasa, Rabu, Kamis, Jumat, Sabtu, dan Minggu sudah menjadi semacam variabel konstanta yang mengandung bilangan bulat yang berbeda-beda (dan berurut).\n\n\nenumhari.c\n\n#include <stdio.h>\n\nenum Hari = {\n    Senin, Selasa, Rabu, Kamis, Jumat, Sabtu, Minggu\n}\n\nint main() {\n    enum Hari sekarang = Rabu;\n\n    switch (sekarang) {\n        case Senin:\n        case Rabu:\n        case Kamis:\n            puts(\"Toko buka\");\n            printf(\"Urutan: %d\\n\", sekarang);\n            break;\n        case Selasa:\n        case Jumat:\n        case Sabtu:\n        case Minggu:\n            puts(\"Toko tutup\");\n            printf(\"Urutan: %d\\n\", sekarang);\n            break;\n        default:\n            puts(\"Hari tidak jelas\");\n            printf(\"Urutan: %d\\n\", sekarang);\n    }\n\n    return 0;\n}\n\nTentu saja, kegunaan enum tidak sebatas switch case. Meskipun cukup jarang dijumpai, enum bisa digunakan dalam kondisi apapun yang mengharuskan penggunaan bilangan bulat. Selain itu, dengan sifat enum yang selalu memasang nilai bilangan bulat secara terurut, enum bisa digunakan ketika ada variabel (atau ingin membuat tipe data baru) yang diharapkan hanya memiliki beberapa kemungkinan nilai (misalnya enum Hari di atas hanya memiliki 7 kemungkinan nilai), apalagi ketika urutan itu penting (walaupun tidak masalah juga menggunakan enum ketika urutan tidak penting).\nBahkan, kalau mau, kita bisa memasang nilai bilangan bulat tertentu untuk beberapa “konstanta” di dalam suatu enum, dan “konstanta” berikutnya akan selalu lebih besar daripada yang sebelumnya.\nenum KategoriUsia {\n    batita, balita=4, anak, remaja=13, dewasa=19, quarterlifecrisis, lansia=60\n};\nKita bisa melihat semua nilai yang dipasang:\n\n\nenumusia.c\n\n#include <stdio.h>\n\nenum KategoriUsia {\n    batita, balita=4, anak, remaja=13, dewasa=19, quarterlifecrisis, lansia=60\n};\n\nint main() {\n    printf(\n        \"%d %d %d %d %d %d %d\",\n        batita, balita, anak, remaja, dewasa, quarterlifecrisis, lansia\n    );\n    // output: 0 4 5 13 19 20 60\n\n    return 0;\n}\n\nKita juga bisa memaksakan agar beberapa “konstanta” memiliki nilai yang sama atau bahkan lebih rendah:\nenum Warna {\n    merah=100, putih=100, ungu=0, hijau, kuning, kelabu=1, biru\n};\nKarena enum merupakan bilangan bulat, kita bahkan bisa membandingkan apakah suatu bilangan bulat (ataupun suatu enum) itu sama dengan, lebih besar dari, atau lebih kecil dari suatu “konstanta” dalam enum.\n\n\nenumwarna.c\n\n#include <stdio.h>\n\nenum Warna {\n    merah=100, putih=100, ungu=0, hijau, kuning, kelabu=1, biru\n};\n\nint main() {\n    printf(\n        \"%d %d %d %d %d %d %d\",\n        merah, putih, ungu, hijau, kuning, kelabu, biru\n    );\n    // output: 100 100 0 1 2 1 \n    \n    if (merah==putih) {\n        puts(\"Merah dan putih setara\");\n    } else {\n        puts(\"Merah dan putih tidak setara\");\n    }\n\n    enum Warna warna_saya = biru;\n    if (warna_saya < hijau) {\n        puts(\"warna_saya < hijau\");\n    } else {\n        puts(\"warna_saya >= hijau\");\n    }\n\n    return 0;\n}"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html#while-loop",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html#while-loop",
    "title": "Modul 1 Struktur Data: Pengenalan bahasa C: data, ekspresi, pernyataan, dan alur logika",
    "section": "while loop",
    "text": "while loop\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html#for-loop",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html#for-loop",
    "title": "Modul 1 Struktur Data: Pengenalan bahasa C: data, ekspresi, pernyataan, dan alur logika",
    "section": "for loop",
    "text": "for loop\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html#do-while-loop",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul01.html#do-while-loop",
    "title": "Modul 1 Struktur Data: Pengenalan bahasa C: data, ekspresi, pernyataan, dan alur logika",
    "section": "do while loop",
    "text": "do while loop\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul00.html",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul00.html",
    "title": "Modul 0 Struktur Data: Instalasi dan konfigurasi software",
    "section": "",
    "text": "Kembali ke Struktur Data\nUntuk praktikum Struktur Data, kita akan menggunakan bahasa pemrograman C, sehingga perlu diinstal beberapa software, terutama gcc dan aplikasi Visual Studio Code. Apabila Anda tidak bersedia menginstal software tersebut di laptop, Anda tetap dapat menggunakan Sololearn Compiler Playground atau situs serupa. Kebetulan, aplikasi Sololearn juga tersedia untuk smartphone (Android, iOS).\nSelain itu, di praktikum terakhir, kita juga akan mulai membahas database dan SQL menggunakan SQLite, termasuk aplikasi DB Viewer (database viewer) untuk SQLite, sehingga keduanya perlu diinstal juga.\nAda juga graphviz (opsional) apabila Anda berniat ingin membuat visualisasi untuk berbagai struktur data, terutama berbagai jenis tree."
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul00.html#instalasi-gcc",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul00.html#instalasi-gcc",
    "title": "Modul 0 Struktur Data: Instalasi dan konfigurasi software",
    "section": "Instalasi gcc",
    "text": "Instalasi gcc\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul00.html#instalasi-dan-konfigurasi-visual-studio-code",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul00.html#instalasi-dan-konfigurasi-visual-studio-code",
    "title": "Modul 0 Struktur Data: Instalasi dan konfigurasi software",
    "section": "Instalasi dan konfigurasi Visual Studio Code",
    "text": "Instalasi dan konfigurasi Visual Studio Code\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul00.html#instalasi-sqlite",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul00.html#instalasi-sqlite",
    "title": "Modul 0 Struktur Data: Instalasi dan konfigurasi software",
    "section": "Instalasi SQLite",
    "text": "Instalasi SQLite\nhttps://www.sqlite.org/download.html\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul00.html#instalasi-db-browser-for-sqlite-db4s",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul00.html#instalasi-db-browser-for-sqlite-db4s",
    "title": "Modul 0 Struktur Data: Instalasi dan konfigurasi software",
    "section": "Instalasi DB Browser for SQLite (DB4S)",
    "text": "Instalasi DB Browser for SQLite (DB4S)\n\nWindows: dari installer\nStorage yang dibutuhkan: perkiraan 50-70 MB\n\nBuka situs https://sqlitebrowser.org/dl/, scroll ke bagian “Windows”, lalu pencet tulisan “DB Browser for SQLite - Standard installer for 64-bit Windows” untuk men-download/mengunduh installer untuk DB Browser for SQLite.\nSetelah proses download selesai, buka installer nya. Ikuti saja. Secara keseluruhan, Anda tinggal menekan Next berkali-kali sampai proses instalasi selesai. Apabila ada persetujuan seperti EULA (End-User License Agreement), setujui saja (centang). Namun, akan ada bagian Shortcuts, di mana Anda bisa mencentang semua pilihan untuk DB Browser (SQLite). Abaikan “SQLCipher” (tidak perlu dicentang).\nSetelah menekan Next beberapa kali, akan ada semacam proses loading, yang artinya proses instalasi sedang berjalan. Tunggu saja selama perkiraan 1 (satu) menit.\nNantinya, apabila proses instalasi sudah selesai, tombol Next akan berubah menjadi Finish, maka tekan Finish. Anda boleh menghapus installer nya.\n\n\n\nmacOS: dari file DMG\nStorage yang dibutuhkan: perkiraan 50-70 MB\n\nTentukan apakah laptop Anda memiliki prosesor Intel atau Apple Silicon. Di ujung kiri atas layar laptop Anda, tekan tombol Apple (), lalu “About This Mac”. Setelah itu, akan muncul beberapa informasi tentang MacBook Anda, termasuk keterangan prosesor atau chip, apakah Apple M1/M2 (Apple Silicon) atau Intel.\nBuka situs https://sqlitebrowser.org/dl/, scroll ke bagian “macOS”, lalu pencet tulisan “DB Browser for SQLite” yang sesuai dengan prosesor laptop Anda (antara Intel atau Apple Silicon) untuk men-download/mengunduh installer DB Browser for SQLite, yang berupa file DMG.\nSetelah proses download selesai, buka file DMG tersebut. Apabila muncul peringatan bahwa aplikasi tidak dikenal, tidak masalah, pencet Open saja.\nAkan muncul gambar/icon aplikasinya, dengan tulisan “DB Browser for SQLite”, serta folder Applications di sampingnya (dan ada panah di antaranya). Tarik gambar aplikasinya ke folder Applications tersebut, sesuai panah. Sebenarnya, ini adalah proses copy-paste agar aplikasinya menjadi tersedia di laptop Anda. Tunggu saja selama perkiraan 1 (satu) menit.\nProses instalasi sudah selesai dan aplikasi DB Browser untuk SQLite sudah bisa dibuka melalui folder Applications. Apabila, di Desktop, muncul semacam file Disk Image dengan tulisan DB Browser atau semacamnya, klik kanan lalu Eject saja. Anda boleh menghapus file DMG nya."
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul00.html#instalasi-graphviz",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul00.html#instalasi-graphviz",
    "title": "Modul 0 Struktur Data: Instalasi dan konfigurasi software",
    "section": "Instalasi graphviz",
    "text": "Instalasi graphviz\n\nWindows: dari installer\nhttps://graphviz.gitlab.io/download/\nblabla\n\n\nmacOS: dari source code\nStorage yang dibutuhkan: perkiraan 200-500 MB\n\nBuka situs https://graphviz.gitlab.io/download/source/, scroll ke bagian “Stable Releases”, lalu unduh/download versi yang terbaru (teratas), dengan menekan tulisan biru yang berakhiran “gz” (bukan yang sha256).\nSetelah proses download selesai, akan muncul file yang berakhiran .tar.gz. Itulah file yang telah diunduh. Klik file tersebut dua kali, seolah-olah ingin membuka suatu aplikasi. (Proses ini bernama extraction/unzipping. Daripada klik dua kali, Anda juga bisa klik kanan lalu “Extract”.) Kemudian, akan muncul folder baru dengan nama yang sama, tetapi tanpa akhiran .tar.gz, kira-kira bernama “graphviz-(versi)”, yang selanjutnya akan kita sebut “folder graphviz”.\nKlik kanan pada folder graphviz tersebut, lalu pencet “New Terminal at Folder”. Akan muncul Terimnal, yaitu semacam cmd atau command prompt untuk macOS.\nKetik ./configure, lalu tekan enter. Akan muncul banyak tulisan yang terus membanjiri Terminal. Tunggu saja selama perkiraan 3 (tiga) menit, sampai banjir berhenti. (Tentu saja, sambil menunggu, Anda boleh sambil melakukan hal lain, menggunakan aplikasi lain dan sebagainya, selama tidak menutup Terminal.)\nLalu, ketik make, tekan enter. Akan muncul banyak tulisan yang terus membanjiri Terminal lagi, tetapi kali ini lebih lama. Tunggu saja selama perkiraan 10 (sepuluh) menit, sampai banjir berhenti.\nTerakhir, ketik make install, dan tekan enter. Akan muncul banyak tulisan yang membanjiri Terminal lagi, tetapi tidak lama. Tunggu saja selama perkiraan 1 (satu) menit.\nSetelah banjir berhenti, proses instalasi sudah selesai dan Anda boleh menutup Terminal.\n\nSetelah instalasi selesai, Anda bisa membuka aplikasi Terminal (ada di folder Applications, lalu masuk folder Utilities) kapan saja, di mana saja, lalu menggunakan command dot untuk menggunakan graphviz. Contohnya, Anda bisa mengetik dot -V untuk memeriksa versi graphviz yang telah terinstal, atau mengetik dot -? untuk melihat daftar command yang ada."
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul00.html#konfigurasi-visual-studio-code-untuk-graphviz",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul00.html#konfigurasi-visual-studio-code-untuk-graphviz",
    "title": "Modul 0 Struktur Data: Instalasi dan konfigurasi software",
    "section": "Konfigurasi Visual Studio Code untuk graphviz",
    "text": "Konfigurasi Visual Studio Code untuk graphviz\nInstal extension berikut ini agar lebih mudah melihat gambar yang dihasilkan oleh bahasa Graphviz DOT:\nName: Graphviz Interactive Preview Id: tintinweb.graphviz-interactive-preview Description: Graphviz (dot) Interactive Preview Version: 0.3.5 Publisher: tintinweb VS Marketplace Link: https://marketplace.visualstudio.com/items?itemName=tintinweb.graphviz-interactive-preview\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul00.html#sololearn-compiler-playground",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul00.html#sololearn-compiler-playground",
    "title": "Modul 0 Struktur Data: Instalasi dan konfigurasi software",
    "section": "Sololearn Compiler Playground",
    "text": "Sololearn Compiler Playground\nhttps://www.sololearn.com/compiler-playground/"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul00.html#graphviz-online",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul00.html#graphviz-online",
    "title": "Modul 0 Struktur Data: Instalasi dan konfigurasi software",
    "section": "Graphviz Online",
    "text": "Graphviz Online\nhttps://dreampuf.github.io/GraphvizOnline/"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04b.html",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04b.html",
    "title": "Modul 4b (opsional): membuat command-line interface (CLI) dengan argv",
    "section": "",
    "text": "Kembali ke Struktur Data\n\nOutline\n\nPengenalan argc dan argv di fungsi main\nargv sebagai array of string\nContoh program echoall: menampilkan kembali tiap input\nContoh program sumall: menjumlahkan semua bilangan yang diberikan\nContoh program bacatxt: menampilkan isi suatu text file\n\n\n\nPengenalan argc dan argv di fungsi main\nblabla\n\n\nargv sebagai array of string\nblabla\n\n\nContoh program echoall: menampilkan kembali tiap input\nblabla\n\n\nContoh program sumall: menjumlahkan semua bilangan yang diberikan\nblabla\n\n\nContoh program bacatxt: menampilkan isi suatu text file\nblabla"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04a.html",
    "href": "semuahalaman/modulprak/2023/ganjil/arsip/strukdat_c_masih_rencana/Strukdat2023_Modul04a.html",
    "title": "Modul 4a (opsional): ASCII, Unicode, inttypes.h, dan manipulasi text file",
    "section": "",
    "text": "Kembali ke Struktur Data\n\nOutline\n\nTentang ASCII, char, dan int\nManipulasi text file berformat ASCII\nTentang stderr\ninttypes.h untuk tipe data bilangan bulat dengan berbagai ukuran\nTentang Unicode: UTF-32, UTF-8\nManipulasi text file berformat UTF-8\nHeader file untuk Modul 4a Praktikum: prakmodul4a.h dan prakmodul4a.c\n\n\n\nTentang ASCII, char, dan int\nblablabla chart table thingy\n\n\nManipulasi text file berformat ASCII\nhttps://stackoverflow.com/questions/4627330/difference-between-fprintf-printf-and-sprintf\nhttps://www.tutorialspoint.com/c_standard_library/c_function_fprintf.htm\nfopen, fprintf, fclose later fgets, sscanf\nhttps://www.guru99.com/c-file-input-output.html\nblabla\n\n\nTentang stderr\nhttps://stackoverflow.com/questions/12102332/when-should-i-use-perror-and-fprintfstderr\nblabla\n\n\ninttypes.h untuk tipe data bilangan bulat dengan berbagai ukuran\nblabla\n\n\nTentang Unicode: UTF-32, UTF-8\nblabla\n\n\nManipulasi text file berformat UTF-8\nhttps://stackoverflow.com/questions/21737906/how-to-read-write-utf8-text-files-in-c\nblabla\nhttps://www.youtube.com/watch?v=70b9ineDgLU\nhttps://gitlab.com/greggink/youtube_episode_understanding_text/-/blob/master/main.c\nblabla\n\n\nHeader file untuk Modul 4a Praktikum: prakmodul4a.h dan prakmodul4a.c\n\nprakmodul4a.hprakmodul4a.c\n\n\n// empty\n\n\n// empty"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/strukdat_py/strukdat2023.html",
    "href": "semuahalaman/modulprak/2023/ganjil/strukdat_py/strukdat2023.html",
    "title": "Praktikum Struktur Data 2023 Ganjil dengan Python",
    "section": "",
    "text": "Kembali ke Praktikum\n\nModul\nPraktikum Struktur Data tahun 2023 semester ganjil ini akan dilaksanakan menggunakan bahasa pemrograman Python.\n\nModul 1: Tipe Data di Python\nModul 2: Pengantar OOP (tunggu minggu depan aja :D)\n…"
  },
  {
    "objectID": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul01.html",
    "href": "semuahalaman/modulprak/2023/ganjil/strukdat_py/Strukdat2023_Modul01.html",
    "title": "Lab Praktikum Departemen Matematika FMIPA UI",
    "section": "",
    "text": "Kembali ke Struktur Data (dengan Python)\nSelamat datang di praktikum Struktur Data! Sesuai nama mata kuliahnya, kita akan mempelajari cara mengimplementasikan (membuat) berbagai jenis struktur data dengan bahasa pemrograman Python. Nantinya, berbagai struktur data akan dibentuk “di atas” struktur data array dan yang namanya linked list, tetapi yang lebih mendasar lagi daripada keduanya adalah tipe data.\nDi pertemuan pertama ini, kita akan membahas tentang berbagai tipe data yang ada di Python, baik yang sudah kita kenal di mata kuliah Algoritma dan Pemrograman (pasti tersedia di semua bahasa pemrograman) maupun beberapa tipe data khusus yang ada di Python tetapi belum tentu ada di bahasa pemrograman lain. Tujuannya agar kalian lebih mahir dan lebih mudah ketika menggunakan Python untuk menyelesaikan berbagai masalah dalam kehidupan sehari-hari :D\nKita juga akan membahas tentang array dari numpy di Python (bisa disebut static homogeneous array atau biasa disebut array saja), dan bedanya dengan list di Python (dynamic heterogeneous array).\n\n\nPada AlProg, ada beberapa jenis tipe data yang kalian pelajari, yaitu:\n\nNumerik: int, float\nTeks: string\nList\n\n\n\n\n# Tipe Data Integer\na1 = 5\na2 = -180\n\n# Melihat isinya\nprint(a1)\nprint(a2)\n\n5\n-180\n\n\n\n# Mengecek tipe data menggunakan syntax type\nprint(type(a1))\nprint(type(a2))\n\n<class 'int'>\n<class 'int'>\n\n\nMenurut output yang diperoleh, variabel a1 dan a2 saat ini berupa bilangan bulat atau integer. Python punya “kode” atau nama tersendiri untuk tiap tipe data. Untuk bilangan bulat, namanya adalah int. Nama ini sudah ketetapan dari sananya; kapanpun kita berurusan dengan bilangan bulat di Python, sebutannya selalu int.\nKebetulan, Python juga menyebut istilah class. Kita akan belajar lebih lanjut tentang class di pertemuan berikutnya. Untuk sekarang ini, terima saja dulu ya: kurang lebih, maksud dari istilah class adalah tipe data. Jadi intinya, Python memberi tahu bahwa tipe data nya adalah int.\nHasil jumlahan bilangan bulat pasti juga bilangan bulat.\n\na3 = a1 + a2\nprint(a3)\nprint(type(a3))\n\n-175\n<class 'int'>\n\n\nSelanjutnya, kita bahas tentang float atau floating-point number. Intinya ya koma-komaan atau bilangan rasional. Kenapa disebut “floating-point”, itu karena menurut komputer, titik nya itu bisa dengan mudah dipindah-pindah. Barangkali pernah dibahas dulu di awal kuliah Metode Numerik. Tapi detil itu tidak penting, intinya terima saja, namanya float\n\n# Tipe data float\nb1 = 2.54\nb2 = -3.141592\nb3 = float('inf') # memasukkan infinity sebagai float\n\n# Melihat isinya\nprint(b1)\nprint(b2)\nprint(b3)\n\n# Mengecek tipe data\nprint(type(b1))\nprint(type(b2))\nprint(type(b3))\n\n2.54\n-3.141592\ninf\n<class 'float'>\n<class 'float'>\n<class 'float'>\n\n\nfloat(\"inf\") atau float('inf') yang melambangkan tak hingga ini gunanya untuk perbandingan, barangkali sewaktu-waktu kalian membutuhkan suatu bilangan yang selalu lebih besar daripada semua bilangan lain.\n\n# apapun itu, pasti lebih kecil daripada b3 yaitu tak hingga\nif (b1 < b3):\n    print(\"lebih kecil\")\nelse:\n    print(\"lebih besar\")\n\nlebih kecil\n\n\nAda juga float(\"-inf\") atau float('-inf') yang melambangkan negatif tak hingga, yang selalu lebih kecil daripada semua bilangan lain.\n\nb4 = float(\"-inf\")\nif (-123456789 > b4):\n    print(\"masih lebih besar dari -inf\")\nelse:\n    print(\"lebih kecil dari -inf\")\n\nmasih lebih besar dari -inf\n\n\n\n# Operasi dengan int dan float\nprint(b1 * b2)\nprint(a1 ** b1)\nprint(abs(b2))\n\n-7.979643680000001\n59.618879710940476\n3.141592\n\n\n\n# Jika int bertemu float, maka tipe datanya akan menjadi float,\n# walaupun float nya sebenarnya bulat\nprint(type(a1 ** b1))\n\n<class 'float'>\n\n\n\nprint(10.0 / 2)\nprint(type(10.0 / 2))\n\n5.0\n<class 'float'>\n\n\n\n\n\nUntuk menyimpan teks atau “tulisan” di Python, kita gunakan tipe data string, yang menurut Python sebutannya str. Penulisannya bisa menggunakan tanda petik ' atau tanda kutip \" itu sama saja, sama-sama string, yang penting konsisten.\n\n# Tipe Data String\nc1 = \"string biasa\"\nc2 = 'string lagi'\n\n# Print isinya\nprint(c1)\nprint(c2)\n\nstring biasa\nstring lagi\n\n\n\n# Mengecek Tipe Data\nprint(type(c1))\nprint(type(c2))\n\n<class 'str'>\n<class 'str'>\n\n\nApabila tanda petik atau tanda kutip itu diketik tiga kali berturut-turut, string nya bisa berbaris-baris (disebut multiline string).\n\nc3 = '''string\nsampe\nbawah'''\n\nprint(c3)\nprint(type(c3))\n\nstring\nsampe\nbawah\n<class 'str'>\n\n\nSebenarnya, secara internal, baris baru atau newline itu berupa “huruf” atau karakter tersendiri. Ada cara penulisan khusus, yaitu \\n untuk newline character. Dengan demikian, kita bisa mengadakan baris baru tanpa menekan tombol Enter.\n\nc4 = \"Selamat\\nsore\\nsemuanya\"\nprint(c4)\nprint(type(c4))\n\nSelamat\nsore\nsemuanya\n<class 'str'>\n\n\nCara penulisan khusus seperti \\n itu disebut escape character. Maksudnya, yang tadinya berupa huruf “n” itu diawali garis miring \\ sehingga maknanya berubah.\nPada string dapat dilakukan penggabungan (s + s), penggandaan (s * n), slicing (s[a:b]), cari panjang (len), maksimum-minimum (max-min di sini diliat dari urutannya di ASCII), dll.\n\nprint('ayam' + 'geprek')\n\nayamgeprek\n\n\n\nprint('ayam' + ' ' + 'geprek')\n\nayam geprek\n\n\n\n# Penjumlahan berulang adalah perkalian :)\nprint('es jeruk' * 5)\n\nes jerukes jerukes jerukes jerukes jeruk\n\n\n\nprint('es jeruk, ' * 5)\n\nes jeruk, es jeruk, es jeruk, es jeruk, es jeruk, \n\n\n\n\n\n\nKetiganya dapat digunakan untuk menyimpan banyak item sekaligus.\n\n# Membuat list\nlist1 = [10, -1, 13.7]\nlist2 = [\"apel\", \"pisang\", \"mangga\"]\nlist3 = [-75, \"kartu\", True]\nlist4 = list(\"rumput\")\n\nprint(list1)\nprint(list2)\nprint(list3)\nprint(list4)\n\n[10, -1, 13.7]\n['apel', 'pisang', 'mangga']\n[-75, 'kartu', True]\n['r', 'u', 'm', 'p', 'u', 't']\n\n\nPerhatikan bahwa kita dapat menyimpan berbagai tipe data yang berbeda-beda di dalam list yang sama. Kita juga dapat memodifikasi list:\n\nnilai = [100, 75, 30, 60]\nnilai[2] = 55\n\nprint(nilai)\n\n[100, 75, 55, 60]\n\n\nBahkan, kita dapat dengan mudah menambahkan elemen di belakang list:\n\nwarna = [\"merah\", \"hijau\", \"biru\"]\nwarna.append(\"kuning\")\nwarna.append(\"putih\")\nwarna.append(\"hitam\")\n\nprint(warna)\n\n['merah', 'hijau', 'biru', 'kuning', 'putih', 'hitam']\n\n\nKita dapat memperoleh panjangnya (banyaknya elemen; isinya ada berapa) menggunakan len seperti berikut\n\nprint(len(warna))\n\n6\n\n\nSelanjutnya, mari kita coba membuat tuple.\n\n# Membuat tuple\nt1 = (2, 3)\nt2 = (4, 'abc')\nt3 = tuple('kacang')\n\nprint(t1)\nprint(t2)\nprint(t3)\n\n(2, 3)\n(4, 'abc')\n('k', 'a', 'c', 'a', 'n', 'g')\n\n\n\nprint(type(t1))\nprint(type(t2))\nprint(type(t3))\n\n<class 'tuple'>\n<class 'tuple'>\n<class 'tuple'>\n\n\nTuple dapat dianggap sebagai list yang isinya tidak bisa diganti, ditambah, ataupun dihapus. Namun masih berlaku operasi list yang tidak termasuk editing. Kelebihan tuple adalah bisa menjadi key untuk dict (akan dijelaskan kemudian)\n\n# Kalau mencoba edit tuple, pasti error\nt2[1] = 'xyz'\n\nTypeError: 'tuple' object does not support item assignment\n\n\nKata error nya sih, ga ada fitur assignment. Ini memang disengaja, tuple itu dimaksudkan sebagai list yang tidak bisa diubah.\nBarangkali sewaktu-waktu kalian perlu menyimpan data yang sudah pasti tidak berubah. Kalian bisa menggunakan tuple untuk berjaga-jaga, takutnya kalian ga sengaja mengubah datanya, nah itu akan error agar kalian ingat bahwa tidak bisa diubah.\nKemudian, mari kita mencoba membuat set atau himpunan. Penulisannya menggunakan kurung kurawal. Konsep set atau himpunan di Python ini diharapkan sama seperti himpunan yang kalian pelajari di mata kuliah Logika dan Himpunan (LDH).\n\n# Membuat set\ns1 = {'ayam', 'bebek', 'ayam', 'kuda'}\ns2 = set(list('kacang'))\n\nprint(s1)\nprint(s2)\n\n{'ayam', 'bebek', 'kuda'}\n{'a', 'g', 'k', 'n', 'c'}\n\n\nBisa jadi, hasil di atas itu agak berbeda dengan hasil kalian, karena memang agak random, urutan elemen di himpunan itu benar-benar tidak diperhatikan di Python.\nSet bisa dianggap sebagai list yang tidak mempunyai urutan, sehingga tidak ada indexing dan slicing. Kelebihan utamanya adalah set hanya bisa mempunyai elemen yang unik (tidak bisa ada elemen yang sama di set). Hal ini berguna jika kalian mempunyai list yang kalian ingin hilangkan dobel-dobelnya (efek sampingnya, indeksnya jadi hilang sehingga bisa saja isinya tak beraturan).\nAtau bisa jadi, mungkin kalian memang memerlukan konsep himpunan dari LDH itu di dalam Python, seperti memeriksa apakah suatu elemen ada atau tidak ada di himpunan.\n\nif ('ayam' in s1):\n    print(\"ada ayam\")\nelse:\n    print(\"ayam habis\")\n\nada ayam\n\n\nBeberapa operator himpunan matematika juga ada di set, seperti subset, superset, disjoint, union, intersection, dll.\n\ns3 = set('matematika')\ns4 = set('statistika')\ns5 = set('aktuaria')\n\nprint(s3)\nprint(s4)\nprint(s5)\n\n{'a', 'm', 'k', 't', 'e', 'i'}\n{'a', 's', 'k', 't', 'i'}\n{'a', 'k', 'u', 't', 'i', 'r'}\n\n\n\nprint(s3 & s4) # irisan/intersection\n\n{'a', 'i', 't', 'k'}\n\n\n\nprint(s3 | s4) # gabungan/union\n\n{'a', 'm', 's', 'k', 't', 'e', 'i'}\n\n\n\n# subset\nprint(s4 <= s5)\nprint( {3, 4} <= {1, 2, 3, 4, 5} )\n\nFalse\nTrue\n\n\n\n# superset\nprint(s4 >= s3)\nprint( {3, 4, 5, 6, 7, 8} >= {7, 4} )\n\nFalse\nTrue\n\n\n\n\n\nIstilah set/list/tuple comprehension itu konsepnya sama saja, mungkin kita bahas di set/himpunan dulu yaa.\nMisalnya kalian punya himpunan ini:\n\\(B = \\{ 1, 2, 3, 4, 5 \\}\\)\n\nB = {1, 2, 3, 4, 5}\nprint(B)\nprint(type(B))\n\n{1, 2, 3, 4, 5}\n<class 'set'>\n\n\nTerus misalnya kalian ingin membangun himpunan baru (seperti di LDH) seperti berikut:\n\\(C = \\{ 2x : x \\in B \\}\\)\nMenariknya, di Python, kalian tinggal mengetik seperti ini:\n\nC = {2*x for x in B}\nprint(C)\n\n{2, 4, 6, 8, 10}\n\n\nBahkan kita juga bisa menambahkan syarat tambahan, misalnya:\n\\(D = \\{ 2x : x \\in B, x < 3 \\}\\)\n\nD = {2*x for x in B if x < 3}\nprint(D)\n\n{2, 4}\n\n\nJangan lupa, himpunan itu tidak memperhatikan urutan (di sini kebetulan aja lagi berurut, tumben). Untungnya, penulisan set comprehension ini juga berlaku sama persis di list maupun tuple, sehingga ada istilah list comprehension dan tuple comprehension kalau dilakukan di list maupun tuple.\nWalaupun fitur ini mungkin hanya ada di Python, set/list/tuple comprehension ini bisa sangat mempersingkat kode kita. Terkadang kita membangun list menggunakan for loop, dan for loop tersebut bisa saja memakan beberapa line. Dengan list comprehension, kita dapat membangun list tersebut hanya menggunakan 1 line dan kode kita menjadi lebih enak untuk dibaca.\nSebagai contoh, misal kita ingin membuat list yang berisi nilai dari \\(2^x\\):\n\nexpo = []\nfor i in range(6):\n    expo.append(2**i)\n\nprint(expo)\n\n[1, 2, 4, 8, 16, 32]\n\n\nJika menggunakan list comprehension, akan menjadi seperti ini:\n\nexpo = [2 ** i for i in range(6)]\n\nprint(expo)\n\n[1, 2, 4, 8, 16, 32]\n\n\nList comprehension dibuat dengan membuat list yang berisi suatu ekspresi lalu diikuti dengan for, dan jika diinginkan, bisa ditambah lagi for atau if. Hasilnya seolah-olah kita menjalankan for loop untuk membuat list tersebut, namun hanya menggunakan satu baris kode.\nList comprehension dapat menggunakan lebih dari satu variabel pada ekspresinya. Hal ini ekivalen dengan menggunakan nested for loop untuk membuat list tersebut.\nContohnya, ada konsep cartesian product dari dua himpunan, yaitu memasangkan tiap elemen pertama dengan tiap elemen kedua, seperti berikut:\n\\(\\{ 1, 2 \\} \\times \\{ a, b, c \\} = \\{ (1, a), (1, b), (1, c), (2, a), (2, b), (2, c) \\}\\)\nDi Python, kita bisa menggunakan list comprehension untuk membuat list hasil cartesian product dengan mudah, yaitu dengan dua for:\n\ncartesian_prod = [(x, y) for x in [1, 2] for y in ['a', 'b', 'c']]\nprint(cartesian_prod)\n\n[(1, 'a'), (1, 'b'), (1, 'c'), (2, 'a'), (2, 'b'), (2, 'c')]\n\n\n(Tentu saja, daripada menggunakan list, kita bisa menggunakan set atau bahkan tuple.)\nPotongan kode di atas ekivalen dengan:\n\ncartesian_prod = []\nfor x in [1, 2]:\n    for y in ['a', 'b', 'c']:\n        cartesian_prod.append((x, y))\n\nprint(cartesian_prod)\n\n[(1, 'a'), (1, 'b'), (1, 'c'), (2, 'a'), (2, 'b'), (2, 'c')]\n\n\nIngat bahwa urutan pembacaan setiap ekspresi for dan if pada list comprehension adalah dari kiri ke kanan.\nList comprehension pun juga bisa di-nesting.\n\nmat = [[1, 2, 3],\n       [4, 5, 6],\n       [7, 8, 9]]\n\nmat_transpos = [[baris[j] for baris in mat] for j in range(len(mat))]\nprint(mat_transpos)\n\n[[1, 4, 7], [2, 5, 8], [3, 6, 9]]\n\n\n\n\n\nDictionary ini secara harfiah memang artinya “kamus” ya. Di dalam kamus, ada kata dan ada definisi, sebagai pasangan, di mana kita memiliki kata dan kita mencari definisi.\nDi Python, dictionary seperti semacam “perumuman” dari konsep pasangan kata-definisi untuk kamus, di mana “kata” disebut “key” atau kunci dan “definisi” menjadi “value” atau nilai atau data yang sedang dicari berdasarkan key nya.\nKita juga bisa memandang dictionary sebagai list yang indeksnya tidak harus berupa bilangan bulat (tetapi, seperti set, tidak ada urutan).\nStrukturnya adalah {key1:value1, key2:value2, ....}.\nDictionary dalam hal ini juga terkadang disebut associative array.\n\n# Membuat dictionary\nd1 = {'a': 1, 'b': 2, 'c': 3}\nd2 = {'kopi': 6000, 'teh': 5000, 'susu': 7000}\n\nprint(d1)\nprint(d2)\nprint(type(d1))\nprint(type(d2))\n\n{'a': 1, 'b': 2, 'c': 3}\n{'kopi': 6000, 'teh': 5000, 'susu': 7000}\n<class 'dict'>\n<class 'dict'>\n\n\nTidak seperti list yang diindeks menggunakan suatu range bilangan, dictionary diindeks menggunakan key. Jadi, untuk memanggil suatu value, panggil layaknya list, namun indeksnya menggunakan key\n\nprint(d2['kopi'])\n\n6000\n\n\nTipe data dari value boleh bebas, namun untuk key itu harus yang immutable (kurang lebih artinya tidak bisa diubah). Seandainya kita coba membuat dictionary dengan key berupa tipe data yang mutable (bisa diubah) seperti list, akan error:\n\nd3 = { [2, 3]: 6, [3, 4]: 12 }\nprint(d3)\n\nTypeError: unhashable type: 'list'\n\n\nSehingga, kita harus menggunakan tuple:\n\nd3 = {(2, 3): 6, (3, 4): 12}\nprint(d3)\n\n{(2, 3): 6, (3, 4): 12}\n\n\n\nprint(d3[(3, 4)])\n\n12\n\n\nUntuk menambah suatu pasangan key:value baru, cukup menggunakan d[key] = value, dan akan masuk ke dict tersebut.\n\nd3[(3, 5)] = 15\nprint(d3)\n\n{(2, 3): 6, (3, 4): 12, (3, 5): 15}\n\n\nJika ingin menghapus elemen pada dict, dapat menggunakan del\n\ndel d3[(2, 3)]\nprint(d3)\n\n{(3, 4): 12, (3, 5): 15}\n\n\n\n\n\nSebenarnya, list yang ada di Python itu sedikit berbeda dengan array (larik) yang biasa dibahas di Alprog. Suatu array:\n\nharus statis, yaitu ukurannya tidak dapat berubah;\nharus homogen, yaitu tipe datanya harus sama semua.\n\nDi Python, kita bisa menggunakan array melalui numpy. Mari kita coba, import numpy dulu:\n\nimport numpy as np\n\nAda “cara cepat” untuk membuat array yang berisi nol semua atau berisi satu semua, yaitu dengan numpy.zeros dan numpy.ones:\n\narray1 = np.zeros(5)\narray2 = np.ones(3)\n\nprint(array1)\nprint(array2)\nprint(type(array1))\nprint(type(array2))\n\n[0. 0. 0. 0. 0.]\n[1. 1. 1.]\n<class 'numpy.ndarray'>\n<class 'numpy.ndarray'>\n\n\nMaksud dari istilah ndarray adalah n-dimensional array atau array yang dimensinya bisa berupa bilangan asli apapun.\nApabila kita memasukkan tuple, kita bisa membuat array dengan dimensi yang lebih tinggi.\n\n# Memasukkan tuple (3, 2) untuk ukuran 3 x 2\narray3 = np.ones((3, 2))\nprint(array3)\n\n[[1. 1.]\n [1. 1.]\n [1. 1.]]\n\n\n\narray1[3] = -15\nprint(array1)\n\n[  0.   0.   0. -15.   0.]\n\n\n\narray1.append(7)\n\nAttributeError: 'numpy.ndarray' object has no attribute 'append'\n\n\nMungkin di beberapa referensi pemrograman yang membahas array, ada istilah deklarasi dan inisialisasi. Deklarasi itu sekedar menyatakan bahwa array akan memiliki ukuran sekian, sedangkan inisialisasi adalah memasang nilai awal.\nDengan numpy, kita bisa menggunakan numpy.empty(ukuran) untuk deklarasi saja, atau numpy.array(list_isinya) untuk sekaligus memasang nilai awal.\nMisalnya, kita coba deklarasi + inisialisasi sekaligus:\n\narray4 = np.array([10, -5, 2, 17])\nprint(array4)\n\n[10 -5  2 17]\n\n\nPerhatikan bahwa array4 yang sudah kita buat ini berisi bilangan bulat semua. Setelah membuat array tersebut, ukurannya sudah tetap dan tipe datanya juga sudah tetap (dan harus seragam).\nSeandainya kita mencoba memasang float ke array bilangan bulat, akan dipaksakan menjadi bilangan bulat:\n\narray4[3] = 3.14\nprint(array4)\n\n[10 -5  2  3]\n\n\nSeandainya mencoba memasang str ke array bilangan bulat, Python menyerah dan menjadi error:\n\narray4[3] = \"string\"\nprint(array4)\n\nValueError: invalid literal for int() with base 10: 'string'\n\n\nBagaimana kalau kita ingin membuat array float meskipun data kita kebetulan bilangan bulat semua? Salah satu caranya adalah menambahkan .0 ke salah satu elemennya:\n\narray5 = np.array([10.0, -5, 2, 17])\nprint(array5)\n\n[10. -5.  2. 17.]\n\n\nDengan demikian, kita bisa memasang float:\n\narray5[3] = 3.14\nprint(array5)\n\n[10.   -5.    2.    3.14]\n\n\nCara lain adalah dengan memberitahu numpy, melalui dtype yaitu tipe data yang kita tentukan. Perhatikan, untuk dtype, di sini kita menggunakan nama yang dikenal oleh Python. Misalnya, float untuk koma-komaan dan int untuk bilangan bulat.\n\narray6 = np.array([10, -5, 2, 17], dtype=float)\nprint(array6)\n\n[10. -5.  2. 17.]\n\n\nKita bahkan bisa membuat array berisi string yaitu str\n\narray7 = np.array(['p', 'r', 'a', 'k'], dtype=str)\nprint(array7)\n\n['p' 'r' 'a' 'k']\n\n\nNamun, ingat bahwa array bersifat fixed size. Bahkan, di sini kita sudah terlanjur membuat array berisi 4 string dan masing-masing satu huruf. Maka, array ini sudah terlanjur hanya bisa menampung 4 string dengan masing-masing string hanya sebesar satu karakter.\n\narray7[3] = \"praktikum\"\nprint(array7)\n\n['p' 'r' 'a' 'p']\n\n\nTerakhir, tentang deklarasi menggunakan numpy.empty. Kalau kita hanya melakukan deklarasi, kita hanya menyatakan ukurannya, tanpa memberitahu isinya apa. Dengan demikian, komputer kita akan mencari memori yang sedang tidak digunakan, lalu langsung menggunakannya untuk array baru kita. Kemungkinan besar, memori yang sudah ditemukan itu tadinya bekas data lain yang sudah terhapus.\nCara menggunakan numpy.empty serupa dengan numpy.ones atau numpy.zeros:\n\narray8 = np.empty(8)\nprint(array8)\n\n[3.10503618e+231 1.49457044e-154 3.95252517e-323 0.00000000e+000\n 0.00000000e+000 0.00000000e+000 3.10503618e+231 3.10503618e+231]\n\n\nLho, muncul angka-angka ga jelas. Mungkin di kalian akan berbeda. Inilah bekas dari data yang sudah terhapus.\nTahukah kalian, ketika kalian menghapus file, sebenarnya data itu belum tentu benar-benar terhapus? Datanya hanya diberi tanda “terhapus”, bukan benar-benar dihilangkan. Data bekas seperti itu disebut garbage value.\nBiasanya, ketika kita membuat file baru, barulah komputer mencari memori yang “kosong”, yaitu berisi garbage value, kemudian komputer menimpa data yang baru di atas data yang lama (garbage value) tersebut.\nTentu saja, array hasil deklarasi ini kemudian bisa dipasang nilainya satu-per-satu (assignment):\n\n# bisa manual tiap indeks\narray8[0] = -17.6\narray8[1] = 24.3\n\n# bisa juga dengan for loop\nfor i in range(2, len(array8)): # dari i=2 sampai i=7\n    array8[i] = 5*i/4\n\nprint(array8)\n\n[-17.6   24.3    2.5    3.75   5.     6.25   7.5    8.75]\n\n\nKebetulan, hasil numpy.empty berisi float, sehingga tipe data array nya otomatis menjadi float. Namun, tentu saja, kita bisa menentukan dtype yang kita inginkan (begitu juga untuk numpy.ones dan numpy.zeros, sama seperti numpy.array).\nContohnya, dengan dtype=str kita mendapatkan array yang tiap elemennya berupa string yang hanya bisa menampung satu karakter (secara teori juga disebut tipe data karakter atau char):\n\narray9 = np.empty(4, dtype=str)\nprint(array9)\n\narray9[2] = \"coba\"\nprint(array9)\n\n['' '' '' '']\n['' '' 'c' '']\n\n\nUntuk string dengan panjang maksimum \\(n\\) karakter, gunakan dtype='<Un' atau dtype=\"<Un\". Misalnya, dtype='<U3' atau dtype=\"<U3\" untuk tiga karakter:\n\narray10 = np.empty(5, dtype=\"<U3\")\nprint(array10)\n\narray10[2] = \"percobaan\"\nprint(array10)\n\n['' '' '' '' '']\n['' '' 'per' '' '']\n\n\nUntuk bilangan bulat, seperti biasa, gunakan dtype=int\n\narray11 = np.empty(11, dtype=int)\nprint(array11)\n\n[8070450532247928832 1152930267120700532                   6\n                   0                   0 3832119515839358315\n 3271410370466756915 3762814858193679157 4120005537702227256\n 3977580307635332705 8386112019188900194]\n\n\nSangat random ya! Lagi-lagi, isi dari hasil numpy.empty sangat mungkin berbeda-beda untuk tiap komputer dan di tiap saat. Intinya, kita hanya meminta array dengan ukuran tertentu, tanpa menentukan isinya (tidak seperti numpy.ones dan numpy.zeros yang isinya sudah pasti, atau numpy.array di mana kita manual menentukan isinya), sehingga isinya bisa berupa apa saja. Begitulah jadinya, jika array hanya dideklarasi tanpa ditentukan isinya.\nPada prakteknya, deklarasi array selalu diikuti dengan menentukan isinya, seperti dengan assignment atau contoh for loop di atas (atau kalau mau, kita bisa saja menggunakan numpy.ones, numpy.zeros, atau bahkan numpy.array agar tidak pusing).\n\n\n\nSekian praktikum Struktur Data minggu ini. Di pertemuan selanjutnya, kita akan belajar tentang class, di mana kita seolah-olah bisa membuat tipe data sendiri lho! Selain itu, fitur class ini akan sering kita gunakan untuk membuat berbagai struktur data ke depannya. Sekalian, kita akan membahas juga tentang object-oriented programming atau biasa disingkat OOP (atau dalam bahasa Indonesia: pemrograman berorientasi objek, biasa disingkat PBO), yaitu semacam “paradigma pemrograman” atau “gaya pemrograman” di mana kita sering berurusan dengan class. Sampai jumpa!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Lab Praktikum Departemen Matematika FMIPA UI",
    "section": "",
    "text": "Langsung pencet Praktikum aja yaa!\nThis is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "semuahalaman/modulprak/2022/ganjil/strukdat/strukdat2022.html",
    "href": "semuahalaman/modulprak/2022/ganjil/strukdat/strukdat2022.html",
    "title": "Praktikum Struktur Data 2022 Ganjil",
    "section": "",
    "text": "Kembali ke Praktikum\n\nModul\n\nModul 1 | Tipe Data di Python\nModul 2 | Searching dan Sorting\nModul 3 | Pengenalan class\nModul 4 | Linked List, Stack, dan Queue\nModul 5 | Tree (1)\nModul 6 | Tree (2)"
  },
  {
    "objectID": "semuahalaman/modulprak/2022/ganjil/strukdat/Strukdat2022_Modul01.html",
    "href": "semuahalaman/modulprak/2022/ganjil/strukdat/Strukdat2022_Modul01.html",
    "title": "Lab Praktikum Departemen Matematika FMIPA UI",
    "section": "",
    "text": "Kembali ke Struktur Data\nSelamat dataing di praktikum pertama StrukDat. Pada pertemuan pertama akan di-review lagi beberapa materi AlProg dengan beberapa tambahan. Kita juga akan memperkenalkan kelas objek baru, yaitu dict.\n\n\nPada AlProg, ada beberapa jenis tipe data yang kalian pelajari, yaitu:\n\nNumerik: int, float, complex\nTeks: string\nList, Tuple\n\n\n\n\n\n# Tipe Data Integer\na1 = 5\na2 = -180\n\n# Mengecek tipe data menggunakan syntax type\nprint(type(a1))\nprint(type(a2))\n\n<class 'int'>\n<class 'int'>\n\n\n\n# Tipe data float\nb1 = 2.54\nb2 = -3.141592\nb3 = float('inf') # memasukkan infinity sebagai float\n\n# Mengecek tipe data\nprint(type(b1))\nprint(type(b2))\nprint(type(b3))\n\n<class 'float'>\n<class 'float'>\n<class 'float'>\n\n\n\n# Operasi pada numerik\nprint(a1 + a2)\nprint(b1 * b2)\nprint(a1 ** b1)\nprint(abs(b2))\n\n# Jika int bertemu float, maka tipe datanya akan menjadi float,\n# walaupun float nya sebenarnya bulat\nprint(type(a1 ** b1))\n\n-175\n-7.979643680000001\n59.618879710940476\n3.141592\n<class 'float'>\n\n\n\n\n\n\n# Tipe Data String\nc1 = 'string biasa'\nc2 = '''string\nsampe\nbawah'''\n\n# Mengecek Tipe Data\nprint(type(c1))\nprint(type(c2))\n\n<class 'str'>\n<class 'str'>\n\n\nPada string dapat dilakukan penggabungan (s + s), penggandaan (s * n), slicing (s[a:b]), cari panjang (len), maksimum-minimum (max-min di sini diliat dari urutannya di ASCII), dll. Method bisa lebih banyak lagi\n\nprint('ayam' + 'geprek')\nprint(5 * 'es jeruk') # dia ga nambahin whitespace yaa\n\nayamgeprek\nes jerukes jerukes jerukes jerukes jeruk\n\n\n\n\n\nKetiganya dapat digunakan untuk menyimpan banyak item sekaligus. Karena list sudah dijelaskan, akan dijelaskan mengenai tuple dan set\n\n# Membuat tuple\nt1 = (2, 3)\nt2 = (4, 'abc')\nt3 = tuple('kacang')\n\nprint(t3)\n\n('k', 'a', 'c', 'a', 'n', 'g')\n\n\nTuple dapat dianggap sebagai list yang isinya tidak bisa diganti, ditambah, ataupun dihapus. Namun masih berlaku operasi list yang tidak termasuk editing. Kelebihan tuple adalah bisa menjadi key untuk dict (akan dijelaskan kemudian)\n\n# Membuat set\ns1 = {'ayam', 'bebek', 'ayam', 'kuda'}\ns2 = set(list('kacang'))\n\nprint(s1)\nprint(s2)\n\n{'bebek', 'kuda', 'ayam'}\n{'k', 'g', 'c', 'a', 'n'}\n\n\nSet dianggap sebagai list yang tidak mempunyai urutan, sehingga tidak ada indexing dan slicing. Kelebihan utamanya adalah set hanya bisa mempunyai elemen yang unik (tidak bisa ada elemen yang sama di set). Hal ini berguna jika kalian mempunyai list yang kalian ingin hilangkan dobel-dobelnya (efek sampingnya, indeksnya jadi hilang sehingga bisa saja isinya tak beraturan).\nBeberapa operator himpunan matematika juga ada di set, seperti subset, superset, disjoint, union, intersection, dll.\n\ns3 = set('matematika')\ns4 = set('statistika')\ns5 = set('aktuaria')\n\nprint(s3)\nprint(s4)\nprint(s5)\n\n{'t', 'm', 'e', 'i', 'k', 'a'}\n{'t', 'i', 'k', 'a', 's'}\n{'t', 'k', 'r', 'i', 'a', 'u'}\n\n\n\nprint(s3 & s4) # Irisan\nprint(s3 | s4) # Gabungan\n\n{'t', 'a', 'i', 'k'}\n{'t', 'm', 'e', 'k', 'i', 'a', 's'}\n\n\n\n\n\nTerkadang kita membangun list menggunakan for loop, dan for loop tersebut bisa saja memakan beberapa line dari kode kalian. Dengan list comprehension, kita dapat membangun list tersebut hanya menggunakan 1 line dan bisa saja kode kita menjadi lebih enak untuk dibaca.\nSebagai contoh, kita ingin membuat list yang berisi nilai dari \\(2^x\\):\n\nexpo = []\nfor i in range(6):\n    expo.append(2**i)\n\nprint(expo)\n\n[1, 2, 4, 8, 16, 32]\n\n\nJika menggunakan list comprehension, akan menjadi seperti ini:\n\nexpo = [2 ** i for i in range(6)]\n\nprint(expo)\n\n[1, 2, 4, 8, 16, 32]\n\n\nList comprehension dibuat dengan membuat list yang berisi suatu ekspresi lalu diikuti dengan for, dan jika diinginkan, bisa ditambah lagi for atau if. Hasilnya akan membuat seolah kita menjalankan for loop untuk membuat list tersebut, namun hanya menggunakan satu line.\nSeperti disinggung sebelumnya, list comprehension dapat menggunakan lebih dari satu variabel pada ekspresinya. Hal ini ekivalen dengan jika kita menggunakan nested for loop untuk membuat list tersebut.\nSebagai contoh:\n\ncrossprod = [(x, y) for x in [1, 3, 5] for y in [2, 4, 6]]\nprint(crossprod)\n\n[(1, 2), (1, 4), (1, 6), (3, 2), (3, 4), (3, 6), (5, 2), (5, 4), (5, 6)]\n\n\nPotongan kode di atas ekivalen dengan:\n\ncrossprod = []\nfor x in [1, 3, 5]:\n    for y in [2, 4, 6]:\n        crossprod.append((x, y))\n\nprint(crossprod)\n\n[(1, 2), (1, 4), (1, 6), (3, 2), (3, 4), (3, 6), (5, 2), (5, 4), (5, 6)]\n\n\nIngat bahwa urutan pembacaan setiap ekspresi for dan if pada list comprehension adalah dari kiri ke kanan.\nList comprehension pun juga bisa di-nesting.\n\nmat = [[1, 2, 3],\n       [4, 5, 6],\n       [7, 8, 9]]\n\nmattr = [[ro[i] for ro in mat] for i in range(len(mat))]\nprint(mattr)\n\n[[1, 4, 7], [2, 5, 8], [3, 6, 9]]\n\n\n\n\n\nDictionary dapat dianggap sebagai set yang tiap elemennya memiliki 2 jenis nilai, yaitu key dan value. Strukturnya adalah {key1:value1, key2:value2, ....}.\n\n# Membuat dictionary\nd1 = {'a': 1, 'b': 2, 'c': 3}\nd2 = {'kopi': 6000, 'teh': 5000, 'susu': 7000}\n\nTidak seperti list yang diindeks menggunakan suatu range bilangan, dictionary diindeks meenggunakan key. Tipe data dari value boleh bebas, namun untuk key harus yang immutable (agak oversimplification tapi artinya tidak bisa diubah), sehingga tuple juga berguna untuk menjadi key dari dictionary\n\nd3 = {(2, 3): 6, (3, 4): 12}\nprint(d3)\n\n{(2, 3): 6, (3, 4): 12}\n\n\nUntuk memanggil suatu value, panggil layaknya list, namun indeksnya menggunakan key\n\nprint(d3[(3, 4)])\n\n12\n\n\nUntuk meneambah suatu pasangan key:value baru, cukup menggunakan d[key] = value, dan akan masuk ke dict tersebut.\n\nd3[(3, 5)] = 15\nprint(d3)\n\n{(2, 3): 6, (3, 4): 12, (3, 5): 15}\n\n\nJika ingin menghapus elemen pada dict, dapat menggunakan del\n\ndel d3[(2, 3)]\nprint(d3)\n\n{(3, 4): 12, (3, 5): 15}"
  }
]