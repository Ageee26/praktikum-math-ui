[
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul4.html",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul4.html",
    "title": "Modul 4 Sains Data",
    "section": "",
    "text": "Kembali ke Sains Data\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nPada pertemuan kali ini, kita akan membahas tentang salah satu metode machine learning, yaitu regresi.\nMetode regresi yang paling sering digunakan adalah regresi linier (linear regression).\nInti sari dari regresi linier adalah, diberikan sekumpulan data (meliputi satu fitur target yang ingin diprediksi, biasa disebut \\(y\\), serta minimal satu variabel bebas), ingin ditemukan garis yang paling mendekati semua titik.\n“Paling mendekati” bisa diukur dengan menjumlahkan (kuadrat dari) semua selisih antara nilai \\(y\\) pada tiap titik dengan nilai \\(y\\) pada garis. (Misalkan fungsi garis ditulis \\(y = P\\left(x\\right)\\). Maka, nilai \\(y\\) pada garis ditulis \\(P\\left(x_i\\right)\\) untuk titik ke-\\(i\\).)\nJika hasil jumlah ini makin kecil, maka garis makin mendekati titik-titiknya. Hasil jumlah ini disebut error, atau di sini lebih tepatnya SSE (sum of squared errors):\n\\[\\text{SSE = } \\sum_{i=1}^{n} \\left( y_i - P\\left(x_i\\right) \\right)^2\\]\nMaka, tujuan dari regresi linier adalah menemukan garis yang meminimalkan error, yaitu meminimalkan SSE. Fungsi yang ingin diminimalkan (di sini SSE) biasa disebut fungsi objektif (objective function), terutama di dunia optimasi.\nRegresi linier umumnya terbagi lagi menjadi dua jenis, yaitu\nBanyak metode regresi lainnya yang sebenarnya dibangun di atas regresi linier, contohnya regresi polinomial (polynomial regression). Intinya sama: mencoba mencari bentuk fungsi tertentu yang paling cocok dengan sekumpulan data yang diberikan, baik untuk urusan deskripsi maupun prediksi."
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul4.html#import-dataset",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul4.html#import-dataset",
    "title": "Modul 4 Sains Data",
    "section": "Import Dataset",
    "text": "Import Dataset\nSebelum mulai, seperti biasa, kita perlu meng-import dataset terlebih dahulu.\nUntuk praktikum kali ini, kita akan melanjutkan dataset minggu lalu, California Housing Prices, yang sudah kita imputasi. Apabila kalian tidak sempat menyimpan dataset hasil imputasi tersebut sebagai file CSV, silakan download housing_modified.csv berikut:\n\nDirect link: housing_modified.csv\n\nKemudian read dengan pandas seperti biasa:\n\ndf = pd.read_csv(\"./housing_modified.csv\")\n\n\ndf\n\n\n\n\n\n\n\n\n\nUnnamed: 0\nlongitude\nlatitude\nhousing_median_age\ntotal_rooms\ntotal_bedrooms\npopulation\nhouseholds\nmedian_income\nmedian_house_value\n&lt;1H OCEAN\nINLAND\nISLAND\nNEAR BAY\nNEAR OCEAN\n\n\n\n\n0\n0\n-122.23\n37.88\n41.0\n880.0\n129.0\n322.0\n126.0\n8.3252\n452600.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n1\n1\n-122.22\n37.86\n21.0\n7099.0\n1106.0\n2401.0\n1138.0\n8.3014\n358500.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n2\n2\n-122.24\n37.85\n52.0\n1467.0\n190.0\n496.0\n177.0\n7.2574\n352100.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n3\n3\n-122.25\n37.85\n52.0\n1274.0\n235.0\n558.0\n219.0\n5.6431\n341300.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n4\n4\n-122.25\n37.85\n52.0\n1627.0\n280.0\n565.0\n259.0\n3.8462\n342200.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n20635\n20635\n-121.09\n39.48\n25.0\n1665.0\n374.0\n845.0\n330.0\n1.5603\n78100.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20636\n20636\n-121.21\n39.49\n18.0\n697.0\n150.0\n356.0\n114.0\n2.5568\n77100.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20637\n20637\n-121.22\n39.43\n17.0\n2254.0\n485.0\n1007.0\n433.0\n1.7000\n92300.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20638\n20638\n-121.32\n39.43\n18.0\n1860.0\n409.0\n741.0\n349.0\n1.8672\n84700.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20639\n20639\n-121.24\n39.37\n16.0\n2785.0\n616.0\n1387.0\n530.0\n2.3886\n89400.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n\n\n20640 rows × 15 columns\n\n\n\n\n\ndf = df.drop(df.columns[0], axis=1)\n\n\ndf\n\n\n\n\n\n\n\n\n\nlongitude\nlatitude\nhousing_median_age\ntotal_rooms\ntotal_bedrooms\npopulation\nhouseholds\nmedian_income\nmedian_house_value\n&lt;1H OCEAN\nINLAND\nISLAND\nNEAR BAY\nNEAR OCEAN\n\n\n\n\n0\n-122.23\n37.88\n41.0\n880.0\n129.0\n322.0\n126.0\n8.3252\n452600.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n1\n-122.22\n37.86\n21.0\n7099.0\n1106.0\n2401.0\n1138.0\n8.3014\n358500.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n2\n-122.24\n37.85\n52.0\n1467.0\n190.0\n496.0\n177.0\n7.2574\n352100.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n3\n-122.25\n37.85\n52.0\n1274.0\n235.0\n558.0\n219.0\n5.6431\n341300.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n4\n-122.25\n37.85\n52.0\n1627.0\n280.0\n565.0\n259.0\n3.8462\n342200.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n20635\n-121.09\n39.48\n25.0\n1665.0\n374.0\n845.0\n330.0\n1.5603\n78100.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20636\n-121.21\n39.49\n18.0\n697.0\n150.0\n356.0\n114.0\n2.5568\n77100.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20637\n-121.22\n39.43\n17.0\n2254.0\n485.0\n1007.0\n433.0\n1.7000\n92300.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20638\n-121.32\n39.43\n18.0\n1860.0\n409.0\n741.0\n349.0\n1.8672\n84700.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20639\n-121.24\n39.37\n16.0\n2785.0\n616.0\n1387.0\n530.0\n2.3886\n89400.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n\n\n20640 rows × 14 columns\n\n\n\n\nPastikan sudah tidak ada missing value:\n\ndf.isna().sum()\n\nlongitude             0\nlatitude              0\nhousing_median_age    0\ntotal_rooms           0\ntotal_bedrooms        0\npopulation            0\nhouseholds            0\nmedian_income         0\nmedian_house_value    0\n&lt;1H OCEAN             0\nINLAND                0\nISLAND                0\nNEAR BAY              0\nNEAR OCEAN            0\ndtype: int64\n\n\nUntuk dataset ini, fitur target utama yang ingin diprediksi adalah harga rumah, yaitu median_house_value. Kita bisa memisahkan antara fitur target tersebut, misal \\(y\\), dengan fitur-fitur lainnya, misal \\(X\\) besar.\n\nX = df.drop(columns=[\"median_house_value\"])\ny = df[[\"median_house_value\"]]\n\n\nX\n\n\n\n\n\n\n\n\n\nlongitude\nlatitude\nhousing_median_age\ntotal_rooms\ntotal_bedrooms\npopulation\nhouseholds\nmedian_income\n&lt;1H OCEAN\nINLAND\nISLAND\nNEAR BAY\nNEAR OCEAN\n\n\n\n\n0\n-122.23\n37.88\n41.0\n880.0\n129.0\n322.0\n126.0\n8.3252\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n1\n-122.22\n37.86\n21.0\n7099.0\n1106.0\n2401.0\n1138.0\n8.3014\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n2\n-122.24\n37.85\n52.0\n1467.0\n190.0\n496.0\n177.0\n7.2574\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n3\n-122.25\n37.85\n52.0\n1274.0\n235.0\n558.0\n219.0\n5.6431\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n4\n-122.25\n37.85\n52.0\n1627.0\n280.0\n565.0\n259.0\n3.8462\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n20635\n-121.09\n39.48\n25.0\n1665.0\n374.0\n845.0\n330.0\n1.5603\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20636\n-121.21\n39.49\n18.0\n697.0\n150.0\n356.0\n114.0\n2.5568\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20637\n-121.22\n39.43\n17.0\n2254.0\n485.0\n1007.0\n433.0\n1.7000\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20638\n-121.32\n39.43\n18.0\n1860.0\n409.0\n741.0\n349.0\n1.8672\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20639\n-121.24\n39.37\n16.0\n2785.0\n616.0\n1387.0\n530.0\n2.3886\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n\n\n20640 rows × 13 columns\n\n\n\n\n\ny\n\n\n\n\n\n\n\n\n\nmedian_house_value\n\n\n\n\n0\n452600.0\n\n\n1\n358500.0\n\n\n2\n352100.0\n\n\n3\n341300.0\n\n\n4\n342200.0\n\n\n...\n...\n\n\n20635\n78100.0\n\n\n20636\n77100.0\n\n\n20637\n92300.0\n\n\n20638\n84700.0\n\n\n20639\n89400.0\n\n\n\n\n20640 rows × 1 columns"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul4.html#train-test-split",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul4.html#train-test-split",
    "title": "Modul 4 Sains Data",
    "section": "Train-Test Split",
    "text": "Train-Test Split\nInti sari dari machine learning adalah membuat “model” yang bisa belajar dari pola, dan kemudian bisa menghasilkan prediksi yang akurat berdasarkan pola tersebut.\nSehingga, untuk menguji apakah model kita sudah bagus, fokus kita adalah menguji seberapa baik model bisa memprediksi.\n\nDi satu sisi, model machine learning memerlukan data, yang dengan data tersebut, model akan terbentuk dengan “latihan”, mencoba memahami pola yang ada di data tersebut.\nDi sisi lain, untuk menguji kemampuan model memprediksi, perlu ada juga data acuan sehingga hasil prediksi model bisa dibandingkan dengan data aslinya (yaitu data acuan tersebut).\n\nData untuk “latihan” disebut data training (training data), dan data acuan untuk menguji kemampuan prediksi disebut data testing (test data).\nTentunya, kedua data ini harus saling lepas (tidak memiliki irisan), agar tidak terjadi yang namanya data leakage. Semisal ada data training yang sama persis muncul di data testing, kan prediksinya jadi hafalan doang, kegampangan :D\nSebenarnya, regresi tidak terbatas machine learning. Kebetulan, regresi juga menjadi pembahasan yang mendalam di kalangan statistika, hingga ada mata kuliah tersendiri yang membahas regresi (Model Linier / Model Linear).\nDalam konteks machine learning, regresi linier (sebagai model) mencoba mencari garis yang meminimalkan SSE menggunakan data training saja, yaitu data yang dimaksudkan untuk membentuk model. Kemudian, garis yang ditemukan (model yang terbentuk) akan diuji kemampuan prediksinya menggunakan data testing.\nDi dunia nyata, data yang kita peroleh biasanya utuh, satu kesatuan. Padahal, untuk menggunakan machine learning, kita memerlukan data training dan data testing.\nSehingga, dataset yang utuh tersebut bisa kita pecah sendiri menjadi data training dan data testing, namanya train-test split.\nKebetulan, scikit-learn menyediakan fungsi untuk melakukan train-test split. Mari kita coba. Import dulu:\n\nfrom sklearn.model_selection import train_test_split\n\nBiasanya, dataset dipisah menjadi data training sebanyak 80% dan data testing sebanyak 20%. Dalam penggunaan fungsi train_test_split, ditulis test_size=0.2.\nRasio 80-20 ini sebenarnya hanya kebiasaan saja; paling sering begitu, tapi boleh saja misalnya 70-30 atau bahkan 90-10.\nMengapa jauh lebih banyak data training? Tujuannya agar model bisa memahami pola pada data dengan lebih mendalam. Namun, perlu hati-hati juga: kalau data testing terlalu sedikit, kita kurang bisa menguji kemampuan prediksi model.\nKalau ragu, langsung gunakan saja rasio 80-20. Sepertinya memang sudah standar, digunakan di mana-mana.\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nApa itu random state?\nTentunya, kita berharap bahwa train-test split dilakukan secara random atau sembarang, yaitu tidak berdasarkan pola tertentu, agar apapun pola yang terkandung dalam data training itu kurang lebih juga terkandung dalam data testing.\nDi sisi lain, apabila orang lain ingin mencoba model yang kita buat, tentunya kita juga berharap bahwa dia mendapatkan hasil yang sama.\nApabila train-test split benar-benar selalu random tiap kali dijalankan, kemungkinan hasil yang diperoleh orang lain akan cukup berbeda dengan hasil yang kita peroleh, padahal modelnya sama.\nOleh karena itu, meskipun kita menginginkan train-test split dilakukan secara random, kita juga menginginkan cara random tersebut adalah selalu cara yang sama. Hal ini bisa kita atur dengan memasang nilai random_state yang selalu sama.\nBiasanya, random_state dipasang nilai 42. Namun, itu hanya kebiasaan saja. Apapun boleh, asalkan konsisten.\nMari kita lihat hasilnya:\n\nX_train\n\n\n\n\n\n\n\n\n\nlongitude\nlatitude\nhousing_median_age\ntotal_rooms\ntotal_bedrooms\npopulation\nhouseholds\nmedian_income\n&lt;1H OCEAN\nINLAND\nISLAND\nNEAR BAY\nNEAR OCEAN\n\n\n\n\n14196\n-117.03\n32.71\n33.0\n3126.0\n627.0\n2300.0\n623.0\n3.2596\n0.0\n0.0\n0.0\n0.0\n1.0\n\n\n8267\n-118.16\n33.77\n49.0\n3382.0\n787.0\n1314.0\n756.0\n3.8125\n0.0\n0.0\n0.0\n0.0\n1.0\n\n\n17445\n-120.48\n34.66\n4.0\n1897.0\n331.0\n915.0\n336.0\n4.1563\n0.0\n0.0\n0.0\n0.0\n1.0\n\n\n14265\n-117.11\n32.69\n36.0\n1421.0\n367.0\n1418.0\n355.0\n1.9425\n0.0\n0.0\n0.0\n0.0\n1.0\n\n\n2271\n-119.80\n36.78\n43.0\n2382.0\n431.0\n874.0\n380.0\n3.5542\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n11284\n-117.96\n33.78\n35.0\n1330.0\n201.0\n658.0\n217.0\n6.3700\n1.0\n0.0\n0.0\n0.0\n0.0\n\n\n11964\n-117.43\n34.02\n33.0\n3084.0\n570.0\n1753.0\n449.0\n3.0500\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n5390\n-118.38\n34.03\n36.0\n2101.0\n569.0\n1756.0\n527.0\n2.9344\n1.0\n0.0\n0.0\n0.0\n0.0\n\n\n860\n-121.96\n37.58\n15.0\n3575.0\n597.0\n1777.0\n559.0\n5.7192\n1.0\n0.0\n0.0\n0.0\n0.0\n\n\n15795\n-122.42\n37.77\n52.0\n4226.0\n1315.0\n2619.0\n1242.0\n2.5755\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n\n\n16512 rows × 13 columns\n\n\n\n\n\nX_test\n\n\n\n\n\n\n\n\n\nlongitude\nlatitude\nhousing_median_age\ntotal_rooms\ntotal_bedrooms\npopulation\nhouseholds\nmedian_income\n&lt;1H OCEAN\nINLAND\nISLAND\nNEAR BAY\nNEAR OCEAN\n\n\n\n\n20046\n-119.01\n36.06\n25.0\n1505.0\n537.870553\n1392.0\n359.0\n1.6812\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n3024\n-119.46\n35.14\n30.0\n2943.0\n537.870553\n1565.0\n584.0\n2.5313\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n15663\n-122.44\n37.80\n52.0\n3830.0\n537.870553\n1310.0\n963.0\n3.4801\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n20484\n-118.72\n34.28\n17.0\n3051.0\n537.870553\n1705.0\n495.0\n5.7376\n1.0\n0.0\n0.0\n0.0\n0.0\n\n\n9814\n-121.93\n36.62\n34.0\n2351.0\n537.870553\n1063.0\n428.0\n3.7250\n0.0\n0.0\n0.0\n0.0\n1.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n15362\n-117.22\n33.36\n16.0\n3165.0\n482.000000\n1351.0\n452.0\n4.6050\n1.0\n0.0\n0.0\n0.0\n0.0\n\n\n16623\n-120.83\n35.36\n28.0\n4323.0\n886.000000\n1650.0\n705.0\n2.7266\n0.0\n0.0\n0.0\n0.0\n1.0\n\n\n18086\n-122.05\n37.31\n25.0\n4111.0\n538.000000\n1585.0\n568.0\n9.2298\n1.0\n0.0\n0.0\n0.0\n0.0\n\n\n2144\n-119.76\n36.77\n36.0\n2507.0\n466.000000\n1227.0\n474.0\n2.7850\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n3665\n-118.37\n34.22\n17.0\n1787.0\n463.000000\n1671.0\n448.0\n3.5521\n1.0\n0.0\n0.0\n0.0\n0.0\n\n\n\n\n4128 rows × 13 columns\n\n\n\n\n\ny_train\n\n\n\n\n\n\n\n\n\nmedian_house_value\n\n\n\n\n14196\n103000.0\n\n\n8267\n382100.0\n\n\n17445\n172600.0\n\n\n14265\n93400.0\n\n\n2271\n96500.0\n\n\n...\n...\n\n\n11284\n229200.0\n\n\n11964\n97800.0\n\n\n5390\n222100.0\n\n\n860\n283500.0\n\n\n15795\n325000.0\n\n\n\n\n16512 rows × 1 columns\n\n\n\n\n\ny_test\n\n\n\n\n\n\n\n\n\nmedian_house_value\n\n\n\n\n20046\n47700.0\n\n\n3024\n45800.0\n\n\n15663\n500001.0\n\n\n20484\n218600.0\n\n\n9814\n278000.0\n\n\n...\n...\n\n\n15362\n263300.0\n\n\n16623\n266800.0\n\n\n18086\n500001.0\n\n\n2144\n72300.0\n\n\n3665\n151500.0\n\n\n\n\n4128 rows × 1 columns"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul4.html#regresi-linier-sederhana",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul4.html#regresi-linier-sederhana",
    "title": "Modul 4 Sains Data",
    "section": "Regresi Linier Sederhana",
    "text": "Regresi Linier Sederhana\nUntuk satu variabel bebas \\(x\\), rumus garis untuk regresi linier sederhana adalah sebagai berikut:\n\\[y = \\beta_0 + \\beta_1 x\\]\nIngin ditemukan nilai \\(\\beta_0\\) dan \\(\\beta_1\\) yang meminimalkan SSE.\n(Ada juga yang menulis \\(y = \\theta_0 + \\theta_1 x\\), sama saja)\nMari kita pilih terlebih dahulu, variabel bebas apa yang ingin kita gunakan.\n\ndf\n\n\n\n\n\n\n\n\n\nlongitude\nlatitude\nhousing_median_age\ntotal_rooms\ntotal_bedrooms\npopulation\nhouseholds\nmedian_income\nmedian_house_value\n&lt;1H OCEAN\nINLAND\nISLAND\nNEAR BAY\nNEAR OCEAN\n\n\n\n\n0\n-122.23\n37.88\n41.0\n880.0\n129.0\n322.0\n126.0\n8.3252\n452600.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n1\n-122.22\n37.86\n21.0\n7099.0\n1106.0\n2401.0\n1138.0\n8.3014\n358500.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n2\n-122.24\n37.85\n52.0\n1467.0\n190.0\n496.0\n177.0\n7.2574\n352100.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n3\n-122.25\n37.85\n52.0\n1274.0\n235.0\n558.0\n219.0\n5.6431\n341300.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n4\n-122.25\n37.85\n52.0\n1627.0\n280.0\n565.0\n259.0\n3.8462\n342200.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n20635\n-121.09\n39.48\n25.0\n1665.0\n374.0\n845.0\n330.0\n1.5603\n78100.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20636\n-121.21\n39.49\n18.0\n697.0\n150.0\n356.0\n114.0\n2.5568\n77100.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20637\n-121.22\n39.43\n17.0\n2254.0\n485.0\n1007.0\n433.0\n1.7000\n92300.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20638\n-121.32\n39.43\n18.0\n1860.0\n409.0\n741.0\n349.0\n1.8672\n84700.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20639\n-121.24\n39.37\n16.0\n2785.0\n616.0\n1387.0\n530.0\n2.3886\n89400.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n\n\n20640 rows × 14 columns\n\n\n\n\nMisalkan kita ingin menggunakan fitur median_income sebagai prediktor untuk mencoba memprediksi variabel target median_house_value. (Asumsinya, mungkin harga rumah kurang lebih berbanding lurus dengan penghasilan.)\n\nx1_train = X_train[[\"median_income\"]]\nx1_test = X_test[[\"median_income\"]]\n\n\nx1_train\n\n\n\n\n\n\n\n\n\nmedian_income\n\n\n\n\n14196\n3.2596\n\n\n8267\n3.8125\n\n\n17445\n4.1563\n\n\n14265\n1.9425\n\n\n2271\n3.5542\n\n\n...\n...\n\n\n11284\n6.3700\n\n\n11964\n3.0500\n\n\n5390\n2.9344\n\n\n860\n5.7192\n\n\n15795\n2.5755\n\n\n\n\n16512 rows × 1 columns\n\n\n\n\n\nx1_test\n\n\n\n\n\n\n\n\n\nmedian_income\n\n\n\n\n20046\n1.6812\n\n\n3024\n2.5313\n\n\n15663\n3.4801\n\n\n20484\n5.7376\n\n\n9814\n3.7250\n\n\n...\n...\n\n\n15362\n4.6050\n\n\n16623\n2.7266\n\n\n18086\n9.2298\n\n\n2144\n2.7850\n\n\n3665\n3.5521\n\n\n\n\n4128 rows × 1 columns\n\n\n\n\nAda beberapa cara untuk melakukan regresi linier sederhana di Python.\n\nscikit-learn\n\nfrom sklearn.linear_model import LinearRegression\n\nLinearRegression adalah class yang dapat menghasilkan objek (inget-inget lagi materi OOP di praktikum Struktur Data :D), dengan tiap objek itu adalah model regresi linier tersendiri.\nSehingga, untuk membuat model regresi linier, kita buat objeknya terlebih dahulu:\n\nlinreg1 = LinearRegression()\n\nTraining dilakukan dengan method .fit()\n\nlinreg1.fit(x1_train, y_train)\n\nLinearRegression()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LinearRegressionLinearRegression()\n\n\nSetelah dilakukan .fit(), model linreg1 sudah selesai training.\nKita bisa memperoleh nilai parameter \\(\\beta_0\\) dan \\(\\beta_1\\) melalui atribut .intercept_ dan .coef_\n\nlinreg1.intercept_\n\narray([44459.72916908])\n\n\n\nlinreg1.coef_\n\narray([[41933.84939381]])\n\n\n\nlinreg1_b0 = linreg1.intercept_[0]\nlinreg1_b1 = linreg1.coef_[0][0]\n\n\nprint(\"y =\", linreg1_b0, \"+\", linreg1_b1, \"x\")\n\ny = 44459.72916907875 + 41933.84939381272 x\n\n\nPrediksi dilakukan dengan method .predict()\n\ny_pred1 = linreg1.predict(x1_test)\n\n\ny_pred1\n\narray([[114958.91676996],\n       [150606.88213964],\n       [190393.71844449],\n       ...,\n       [431500.77230409],\n       [161245.49973085],\n       [193412.95560084]])\n\n\n\n\nSolusi eksak: metode least squares\nMetode least squares menyediakan “solusi eksak” (dijamin meminimalkan fungsi objektif) untuk regresi linier sederhana, sebagai berikut:\n\\[\\beta_1 = \\frac{n \\left( \\sum_{i=1}^{n} x_i y_i \\right) - \\left( \\sum_{i=1}^{n} x_i \\right) \\left( \\sum_{i=1}^{n} y_i \\right)}{n \\left( \\sum_{i=1}^{n} \\left(x_i\\right)^2 \\right) - \\left( \\sum_{i=1}^{n} x_i \\right)^2}\\]\n\\[\\beta_0 = \\bar{y} - \\beta_1 \\bar{x}\\]\ndengan\n\\[\\bar{x} = \\frac{1}{n} \\sum_{i=1}^{n} x_i\\]\n\\[\\bar{y} = \\frac{1}{n} \\sum_{i=1}^{n} y_i\\]\n\ndef least_squares_sederhana(x, y):\n    n = len(y)\n    x = np.array(x)\n    y = np.array(y)\n    \n    sum_x = sum(x)\n    sum_y = sum(y)\n    sum_x2 = sum(x**2)\n    sum_xy = sum(x*y)\n    \n    atas = n*(sum_xy) - (sum_x)*(sum_y)\n    bawah = n * sum_x2 - (sum_x)**2\n    beta1 = atas/bawah\n\n    mean_x = sum_x / n\n    mean_y = sum_y / n\n\n    beta0 = mean_y - beta1 * mean_x\n\n    return (beta0[0], beta1[0])\n\n\nlinreg2_betas = least_squares_sederhana(x1_train, y_train)\n\n\nlinreg2_betas\n\n(44459.72916908396, 41933.849393811244)\n\n\n\nlinreg2_beta0, linreg2_beta1 = linreg2_betas\n\nUntuk melakukan prediksi, ikuti rumus model (bentuk umum) \\(y = \\beta_0 + \\beta_1 x\\):\n\ny_pred2 = np.array(linreg2_beta0 + linreg2_beta1 * x1_test)\n\n\ny_pred2\n\narray([[114958.91676996],\n       [150606.88213964],\n       [190393.71844449],\n       ...,\n       [431500.77230408],\n       [161245.49973085],\n       [193412.95560084]])\n\n\n\n\nTambahan: statsmodels\nscikit-learn adalah package di Python untuk kebutuhan sains data dan/atau machine learning dasar.\nKarena regresi linier juga dibahas di dunia statistika, ada package statistika bernama “statsmodels” yang juga menyediakan model regresi linier, yang disebut OLS (ordinary least squares). Bedanya, model regresi linier dari statsmodels menyediakan lebih banyak statistik seputar model. Mari kita coba.\nKalau belum punya, install terlebih dahulu:\n\n!pip install statsmodels\n\nCollecting statsmodels\n  Downloading statsmodels-0.14.1-cp310-cp310-macosx_10_9_x86_64.whl.metadata (9.5 kB)\nRequirement already satisfied: numpy&lt;2,&gt;=1.18 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from statsmodels) (1.23.5)\nRequirement already satisfied: scipy!=1.9.2,&gt;=1.4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from statsmodels) (1.10.1)\nRequirement already satisfied: pandas!=2.1.0,&gt;=1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from statsmodels) (2.0.3)\nCollecting patsy&gt;=0.5.4 (from statsmodels)\n  Downloading patsy-0.5.6-py2.py3-none-any.whl.metadata (3.5 kB)\nRequirement already satisfied: packaging&gt;=21.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from statsmodels) (23.1)\nRequirement already satisfied: python-dateutil&gt;=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas!=2.1.0,&gt;=1.0-&gt;statsmodels) (2.8.2)\nRequirement already satisfied: pytz&gt;=2020.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas!=2.1.0,&gt;=1.0-&gt;statsmodels) (2023.3)\nRequirement already satisfied: tzdata&gt;=2022.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas!=2.1.0,&gt;=1.0-&gt;statsmodels) (2023.3)\nRequirement already satisfied: six in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from patsy&gt;=0.5.4-&gt;statsmodels) (1.16.0)\nDownloading statsmodels-0.14.1-cp310-cp310-macosx_10_9_x86_64.whl (10.5 MB)\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.5/10.5 MB 2.6 MB/s eta 0:00:0000:0100:01\nDownloading patsy-0.5.6-py2.py3-none-any.whl (233 kB)\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 233.9/233.9 kB 597.1 kB/s eta 0:00:00 0:00:01\nInstalling collected packages: patsy, statsmodels\nSuccessfully installed patsy-0.5.6 statsmodels-0.14.1\nNote: you may need to restart the kernel to use updated packages.\n\n\nKemudian import:\n\nimport statsmodels.api as sm\n\nSebelum membuat model, statsmodels memerlukan adanya kolom intercept di variabel prediktor, yaitu kolom yang berisi konstanta yaitu 1 semua.\n\nx1_train_sm = sm.add_constant(x1_train)\n\nModel OLS bisa diakses melalui sm.OLS, yang lagi-lagi merupakan class\n\nlinreg3_OLS = sm.OLS(y_train, x1_train_sm)\n\nAgak berbeda dengan scikit-learn, statsmodels menghasilkan objek baru lagi (yang menyimpan hasilnya) ketika dilakukan training dengan .fit()\n\nlinreg3 = linreg3_OLS.fit()\n\nKita bisa lihat hasilnya:\n\nprint(linreg3.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:     median_house_value   R-squared:                       0.477\nModel:                            OLS   Adj. R-squared:                  0.477\nMethod:                 Least Squares   F-statistic:                 1.506e+04\nDate:                Wed, 13 Mar 2024   Prob (F-statistic):               0.00\nTime:                        07:17:26   Log-Likelihood:            -2.1058e+05\nNo. Observations:               16512   AIC:                         4.212e+05\nDf Residuals:                   16510   BIC:                         4.212e+05\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n=================================================================================\n                    coef    std err          t      P&gt;|t|      [0.025      0.975]\n---------------------------------------------------------------------------------\nconst          4.446e+04   1477.242     30.096      0.000    4.16e+04    4.74e+04\nmedian_income  4.193e+04    341.735    122.709      0.000    4.13e+04    4.26e+04\n==============================================================================\nOmnibus:                     3353.131   Durbin-Watson:                   1.982\nProb(Omnibus):                  0.000   Jarque-Bera (JB):             7339.541\nSkew:                           1.175   Prob(JB):                         0.00\nKurtosis:                       5.268   Cond. No.                         10.2\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\nParameter \\(\\beta_0\\) dan \\(\\beta_1\\) bisa diperoleh melalui atribut .params\n\nlinreg3_betas = linreg3.params\n\n\nlinreg3_betas\n\nconst            44459.729169\nmedian_income    41933.849394\ndtype: float64\n\n\n\nlinreg3_beta0 = linreg3_betas[\"const\"]\nlinreg3_beta1 = linreg3_betas[\"median_income\"]\n\n\nprint(\"y =\", linreg3_beta0, \"+\", linreg3_beta1, \"x\")\n\ny = 44459.729169078724 + 41933.8493938127 x\n\n\nPrediksi dengan .predict()\n\nx1_test_sm = sm.add_constant(x1_test)\n\n\ny_pred3 = linreg3.predict(x1_test_sm)\n\n\ny_pred3\n\n20046    114958.916770\n3024     150606.882140\n15663    190393.718444\n20484    285059.383451\n9814     200663.318161\n             ...      \n15362    237565.105628\n16623    158796.562926\n18086    431500.772304\n2144     161245.499731\n3665     193412.955601\nLength: 4128, dtype: float64"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul4.html#metrik-evaluasi-untuk-regresi",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul4.html#metrik-evaluasi-untuk-regresi",
    "title": "Modul 4 Sains Data",
    "section": "Metrik Evaluasi untuk Regresi",
    "text": "Metrik Evaluasi untuk Regresi\n\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul4.html#regresi-linier-berganda",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul4.html#regresi-linier-berganda",
    "title": "Modul 4 Sains Data",
    "section": "Regresi Linier Berganda",
    "text": "Regresi Linier Berganda"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul4.html#regresi-logistik",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul4.html#regresi-logistik",
    "title": "Modul 4 Sains Data",
    "section": "Regresi Logistik",
    "text": "Regresi Logistik"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/saindat2024genap.html",
    "href": "semuahalaman/modulprak/2024/genap/saindat/saindat2024genap.html",
    "title": "Praktikum Saindat (Sains Data) 2024 Genap (Kurikulum 2020)",
    "section": "",
    "text": "Kembali ke Praktikum\n\nTimeline\n\nModul 1: Pengenalan Pandas, Transformasi Data, 19-20 Februari 2024 (offline di Lab Komputer D.311)\nModul 2: Pengenalan Seaborn, Visualisasi Data, 26-27 Februari 2024 (offline di Lab Komputer D.311)\nModul 3: Encoding Data Kategorik dan Imputasi Data, 4-5 Maret 2024 (offline di Lab Komputer D.311)\nModul 4"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul1.html",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul1.html",
    "title": "Modul 1 Sains Data: Pengenalan Pandas, Transformasi Data",
    "section": "",
    "text": "Kembali ke Sains Data"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul1.html#prerequisites",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul1.html#prerequisites",
    "title": "Modul 1 Sains Data: Pengenalan Pandas, Transformasi Data",
    "section": "Prerequisites",
    "text": "Prerequisites\nPada module ini kita akan coba mememahami package pandas, yang merupakan package inti dalam sains-data. kita akan coba melakukan beberapa transformasi data menggunakan pandas.\nsebelum itu, python module di bawah ini yang akan digunakan selama praktikum.\n\nimport numpy as np\nimport pandas as pd\n\nApabila ada yang belum terinstal, silakan instal terlebih dahulu menggunakan pip:\n!pip install numpy\n!pip install pandas\natau conda jika sedang menggunakan Anaconda:\nconda install numpy\nconda install pandas"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul1.html#series",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul1.html#series",
    "title": "Modul 1 Sains Data: Pengenalan Pandas, Transformasi Data",
    "section": "Series",
    "text": "Series\npandas.Series sangat mirip dengan array NumPy (bahkan dibangun di atas objek array NumPy). Yang membedakan array NumPy dari sebuah Series adalah bahwa sebuah Series dapat memiliki label index, yang berarti dapat diindeks dengan label, bukan hanya lokasi nomor saja. Selain itu, sebuah Series tidak perlu menyimpan data numerik, ia dapat menyimpan objek Python sembarang.\n\nMembuat pd.Series dengan list\nPaling mudah, ktia dapat membuat pd.Series dengan python list\n\nmy_index= ['a','b','c','d','e']\nmy_data= [1,2,3,4,5]\nmy_series= pd.Series(data=my_data, index=my_index)\n\n\nprint(my_series)\n\na    1\nb    2\nc    3\nd    4\ne    5\ndtype: int64\n\n\n\nprint(my_series.__class__)\n\n&lt;class 'pandas.core.series.Series'&gt;\n\n\n\n\nMembuat pd.Series dengan dictionary\nKita juga dapat membuat pd.Series dengan dictionary\n\n# creating a series from a dictionary\nmy_dict= {'a':1, 'b':2, 'c':3, 'd':4, 'e':5}\nmy_series_dict= pd.Series(my_dict)\n\n\nprint(my_series_dict)\n\na    1\nb    2\nc    3\nd    4\ne    5\ndtype: int64\n\n\n\nprint(my_series_dict.__class__)\n\n&lt;class 'pandas.core.series.Series'&gt;\n\n\n\n\nOperasi pada Series\n\n# Imaginary Sales Data for 1st and 2nd Quarters for Global Company\nq1 = {'Japan': 80, 'China': 450, 'India': 200, 'USA': 250}\nq2 = {'Brazil': 100,'China': 500, 'India': 210,'USA': 260}\n\n\n# Creating a Series from a Dictionary q1 and q2\nq1_series= pd.Series(q1)\nq2_series= pd.Series(q2)\n\n\nprint(q1_series)\n\nJapan     80\nChina    450\nIndia    200\nUSA      250\ndtype: int64\n\n\nKita dapat mengindeks dengan label\n\n# call values of q1_series based on named index\nprint(q1_series['Japan'])\nprint(q1_series['China'])\nprint(q1_series['India'])\n\n80\n450\n200\n\n\nkita dapat tetap dapat mengindeks dengan integer\n\n# u can also call values of q1_series based on positional index\nprint(q1_series[0])\nprint(q1_series[1])\nprint(q1_series[2])\n\n80\n450\n200\n\n\nhati-hati dalam melakukan indexing dengan label. bisa saja terjadi error jika label tidak ada di dalam pd.series\n\n# remember named index is case sensitive\ntry:\n    print(q1_series['japan'])\nexcept:\n    print('something went wrong')\n\nsomething went wrong\n\n\nOperasi aritmatik sederhana pada pd.Series bersifat broadcasting, yaitu diterapkan ke masing-masing elemen\n\n# operations with arithmetic on series are broadcasted to all values\nprint(q1_series*2)\n\nJapan    160\nChina    900\nIndia    400\nUSA      500\ndtype: int64\n\n\n\nprint(q1_series+1000)\n\nJapan    1080\nChina    1450\nIndia    1200\nUSA      1250\ndtype: int64\n\n\nUntuk penjumlahan antara dua pd.Series, apabila ada label yang hanya muncul di salah satu series, maka label tersebut akan muncul di hasil jumlah dengan data NaN (not a number, di sini artinya tidak ada data).\n(Kebetulan, keterangan NaN hanya bisa muncul untuk tipe data float atau koma-komaan, sehingga tipe data terpaksa diubah menjadi float.)\n\n# operation between series are also broadcasted\nprint(q1_series+q2_series)\n\nBrazil      NaN\nChina     950.0\nIndia     410.0\nJapan       NaN\nUSA       510.0\ndtype: float64\n\n\nMengapa tidak nol saja? Ketiadaan label pada salah satu series dianggap sebagai ketidaktahuan data untuk label tersebut, bukan dianggap nol.\nApabila diinginkan agar data yang tiada dianggap nol terlebih dahulu baru dijumlahkan, bisa seperti berikut:\n\nprint(q1_series.add(q2_series, fill_value=0))\n\nBrazil    100.0\nChina     950.0\nIndia     410.0\nJapan      80.0\nUSA       510.0\ndtype: float64"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul1.html#data-frame",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul1.html#data-frame",
    "title": "Modul 1 Sains Data: Pengenalan Pandas, Transformasi Data",
    "section": "data frame",
    "text": "data frame\nSebuah pd.DataFrame terdiri dari beberapa pd.Series yang berbagi nilai indeks.\nMisalkan kita punya data seperti berikut.\n\nmy_data = np.array([\n    [25, 59, 18],\n    [75, 54, 65],\n    [29, 21,  7],\n    [32, 68, 16]\n])\n\n\nmy_data\n\narray([[25, 59, 18],\n       [75, 54, 65],\n       [29, 21,  7],\n       [32, 68, 16]])\n\n\nKita akan membuat pd.Dataframe melalui python list. Perhatikan bahwa kita dapat memberikan nama pada kolom dan baris\n\nmy_index= [\"Toko A\", \"Toko B\", \"Toko C\", \"Toko D\"]\nmy_columns= [\"Apel\", \"Jeruk\", \"Pisang\"]\n\ndf= pd.DataFrame(data=my_data, index=my_index, columns=my_columns)\n\n\ndf\n\n\n\n\n\n\n\n\n\nApel\nJeruk\nPisang\n\n\n\n\nToko A\n25\n59\n18\n\n\nToko B\n75\n54\n65\n\n\nToko C\n29\n21\n7\n\n\nToko D\n32\n68\n16\n\n\n\n\n\n\n\n\n\ndf_2 = pd.DataFrame(data=my_data)\ndf_2\n\n\n\n\n\n\n\n\n\n0\n1\n2\n\n\n\n\n0\n25\n59\n18\n\n\n1\n75\n54\n65\n\n\n2\n29\n21\n7\n\n\n3\n32\n68\n16\n\n\n\n\n\n\n\n\n\ndf_3 = pd.DataFrame(data=my_data, columns=my_columns)\ndf_3\n\n\n\n\n\n\n\n\n\nApel\nJeruk\nPisang\n\n\n\n\n0\n25\n59\n18\n\n\n1\n75\n54\n65\n\n\n2\n29\n21\n7\n\n\n3\n32\n68\n16\n\n\n\n\n\n\n\n\n\nmembaca file csv sebagai pd.DataFrame\nJika berkas .py atau .ipynb Anda berada di lokasi folder yang sama persis dengan berkas .csv yang ingin Anda baca, cukup berikan nama berkas sebagai string, misalnya:\ndf = pd.read_csv('some_file.csv')\nBerikan s berkas jika Anda berada di direktori yang berbeda. Jalur berkas harus 100% benar agar ini berfungsi. Misalnya:\ndf = pd.read_csv(\"C:\\\\Users\\\\myself\\\\files\\\\some_file.csv\")\nsebelum itu, kalian dapat mendownload dataset “Waiter’s Tips Dataset” melalui salah satu link berikut:\n\nDirect link (langsung dari GitHub Pages ini)\nKaggle\nGoogle Drive\n\n\ndf_tips = pd.read_csv('./tips.csv')\n\n\ndf_tips\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nprice_per_person\nPayer Name\nCC Number\nPayment ID\n\n\n\n\n0\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n8.49\nChristy Cunningham\n3560325168603410\nSun2959\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n3.45\nDouglas Tucker\n4478071379779230\nSun4608\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n7.00\nTravis Walters\n6011812112971322\nSun4458\n\n\n3\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n11.84\nNathaniel Harris\n4676137647685994\nSun5260\n\n\n4\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4\n6.15\nTonya Carter\n4832732618637221\nSun2251\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n239\n29.03\n5.92\nMale\nNo\nSat\nDinner\n3\n9.68\nMichael Avila\n5296068606052842\nSat2657\n\n\n240\n27.18\n2.00\nFemale\nYes\nSat\nDinner\n2\n13.59\nMonica Sanders\n3506806155565404\nSat1766\n\n\n241\n22.67\n2.00\nMale\nYes\nSat\nDinner\n2\n11.34\nKeith Wong\n6011891618747196\nSat3880\n\n\n242\n17.82\n1.75\nMale\nNo\nSat\nDinner\n2\n8.91\nDennis Dixon\n4375220550950\nSat17\n\n\n243\n18.78\n3.00\nFemale\nNo\nThur\nDinner\n2\n9.39\nMichelle Hardin\n3511451626698139\nThur672\n\n\n\n\n244 rows × 11 columns\n\n\n\n\n\n\nOperasi sederhana pada DataFrame\n\n# mengecek nama kolom\ndf_tips.columns\n\nIndex(['total_bill', 'tip', 'sex', 'smoker', 'day', 'time', 'size',\n       'price_per_person', 'Payer Name', 'CC Number', 'Payment ID'],\n      dtype='object')\n\n\n\n# mengecek \ndf_tips.index\n\nRangeIndex(start=0, stop=244, step=1)\n\n\n\ndf_tips.head()\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nprice_per_person\nPayer Name\nCC Number\nPayment ID\n\n\n\n\n0\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n8.49\nChristy Cunningham\n3560325168603410\nSun2959\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n3.45\nDouglas Tucker\n4478071379779230\nSun4608\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n7.00\nTravis Walters\n6011812112971322\nSun4458\n\n\n3\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n11.84\nNathaniel Harris\n4676137647685994\nSun5260\n\n\n4\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4\n6.15\nTonya Carter\n4832732618637221\nSun2251\n\n\n\n\n\n\n\n\n\ndf_tips.head(10)\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nprice_per_person\nPayer Name\nCC Number\nPayment ID\n\n\n\n\n0\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n8.49\nChristy Cunningham\n3560325168603410\nSun2959\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n3.45\nDouglas Tucker\n4478071379779230\nSun4608\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n7.00\nTravis Walters\n6011812112971322\nSun4458\n\n\n3\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n11.84\nNathaniel Harris\n4676137647685994\nSun5260\n\n\n4\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4\n6.15\nTonya Carter\n4832732618637221\nSun2251\n\n\n5\n25.29\n4.71\nMale\nNo\nSun\nDinner\n4\n6.32\nErik Smith\n213140353657882\nSun9679\n\n\n6\n8.77\n2.00\nMale\nNo\nSun\nDinner\n2\n4.38\nKristopher Johnson\n2223727524230344\nSun5985\n\n\n7\n26.88\n3.12\nMale\nNo\nSun\nDinner\n4\n6.72\nRobert Buck\n3514785077705092\nSun8157\n\n\n8\n15.04\n1.96\nMale\nNo\nSun\nDinner\n2\n7.52\nJoseph Mcdonald\n3522866365840377\nSun6820\n\n\n9\n14.78\n3.23\nMale\nNo\nSun\nDinner\n2\n7.39\nJerome Abbott\n3532124519049786\nSun3775\n\n\n\n\n\n\n\n\n\ndf_tips.tail()\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nprice_per_person\nPayer Name\nCC Number\nPayment ID\n\n\n\n\n239\n29.03\n5.92\nMale\nNo\nSat\nDinner\n3\n9.68\nMichael Avila\n5296068606052842\nSat2657\n\n\n240\n27.18\n2.00\nFemale\nYes\nSat\nDinner\n2\n13.59\nMonica Sanders\n3506806155565404\nSat1766\n\n\n241\n22.67\n2.00\nMale\nYes\nSat\nDinner\n2\n11.34\nKeith Wong\n6011891618747196\nSat3880\n\n\n242\n17.82\n1.75\nMale\nNo\nSat\nDinner\n2\n8.91\nDennis Dixon\n4375220550950\nSat17\n\n\n243\n18.78\n3.00\nFemale\nNo\nThur\nDinner\n2\n9.39\nMichelle Hardin\n3511451626698139\nThur672\n\n\n\n\n\n\n\n\n\ndf_tips.tail(10)\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nprice_per_person\nPayer Name\nCC Number\nPayment ID\n\n\n\n\n234\n15.53\n3.00\nMale\nYes\nSat\nDinner\n2\n7.76\nTracy Douglas\n4097938155941930\nSat7220\n\n\n235\n10.07\n1.25\nMale\nNo\nSat\nDinner\n2\n5.04\nSean Gonzalez\n3534021246117605\nSat4615\n\n\n236\n12.60\n1.00\nMale\nYes\nSat\nDinner\n2\n6.30\nMatthew Myers\n3543676378973965\nSat5032\n\n\n237\n32.83\n1.17\nMale\nYes\nSat\nDinner\n2\n16.42\nThomas Brown\n4284722681265508\nSat2929\n\n\n238\n35.83\n4.67\nFemale\nNo\nSat\nDinner\n3\n11.94\nKimberly Crane\n676184013727\nSat9777\n\n\n239\n29.03\n5.92\nMale\nNo\nSat\nDinner\n3\n9.68\nMichael Avila\n5296068606052842\nSat2657\n\n\n240\n27.18\n2.00\nFemale\nYes\nSat\nDinner\n2\n13.59\nMonica Sanders\n3506806155565404\nSat1766\n\n\n241\n22.67\n2.00\nMale\nYes\nSat\nDinner\n2\n11.34\nKeith Wong\n6011891618747196\nSat3880\n\n\n242\n17.82\n1.75\nMale\nNo\nSat\nDinner\n2\n8.91\nDennis Dixon\n4375220550950\nSat17\n\n\n243\n18.78\n3.00\nFemale\nNo\nThur\nDinner\n2\n9.39\nMichelle Hardin\n3511451626698139\nThur672\n\n\n\n\n\n\n\n\n\ndf_tips.describe()\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsize\nprice_per_person\nCC Number\n\n\n\n\ncount\n244.000000\n244.000000\n244.000000\n244.000000\n2.440000e+02\n\n\nmean\n19.785943\n2.998279\n2.569672\n7.888197\n2.563496e+15\n\n\nstd\n8.902412\n1.383638\n0.951100\n2.914234\n2.369340e+15\n\n\nmin\n3.070000\n1.000000\n1.000000\n2.880000\n6.040679e+10\n\n\n25%\n13.347500\n2.000000\n2.000000\n5.800000\n3.040731e+13\n\n\n50%\n17.795000\n2.900000\n2.000000\n7.255000\n3.525318e+15\n\n\n75%\n24.127500\n3.562500\n3.000000\n9.390000\n4.553675e+15\n\n\nmax\n50.810000\n10.000000\n6.000000\n20.270000\n6.596454e+15\n\n\n\n\n\n\n\n\n\ndf_tips.describe().transpose()\n\n\n\n\n\n\n\n\n\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\n\n\ntotal_bill\n244.0\n1.978594e+01\n8.902412e+00\n3.070000e+00\n1.334750e+01\n1.779500e+01\n2.412750e+01\n5.081000e+01\n\n\ntip\n244.0\n2.998279e+00\n1.383638e+00\n1.000000e+00\n2.000000e+00\n2.900000e+00\n3.562500e+00\n1.000000e+01\n\n\nsize\n244.0\n2.569672e+00\n9.510998e-01\n1.000000e+00\n2.000000e+00\n2.000000e+00\n3.000000e+00\n6.000000e+00\n\n\nprice_per_person\n244.0\n7.888197e+00\n2.914234e+00\n2.880000e+00\n5.800000e+00\n7.255000e+00\n9.390000e+00\n2.027000e+01\n\n\nCC Number\n244.0\n2.563496e+15\n2.369340e+15\n6.040679e+10\n3.040731e+13\n3.525318e+15\n4.553675e+15\n6.596454e+15\n\n\n\n\n\n\n\n\n\n\nTransformasi data (row-wise)\n\nfiltering\n\ndf_tips.head()\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nprice_per_person\nPayer Name\nCC Number\nPayment ID\n\n\n\n\n0\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n8.49\nChristy Cunningham\n3560325168603410\nSun2959\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n3.45\nDouglas Tucker\n4478071379779230\nSun4608\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n7.00\nTravis Walters\n6011812112971322\nSun4458\n\n\n3\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n11.84\nNathaniel Harris\n4676137647685994\nSun5260\n\n\n4\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4\n6.15\nTonya Carter\n4832732618637221\nSun2251\n\n\n\n\n\n\n\n\n\nprint(df_tips[\"size\"] == 3)\n\n0      False\n1       True\n2       True\n3      False\n4      False\n       ...  \n239     True\n240    False\n241    False\n242    False\n243    False\nName: size, Length: 244, dtype: bool\n\n\n\nconditional_size = (df_tips[\"size\"] == 3)\ndf_tips[conditional_size]\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nprice_per_person\nPayer Name\nCC Number\nPayment ID\n\n\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n3.45\nDouglas Tucker\n4478071379779230\nSun4608\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n7.00\nTravis Walters\n6011812112971322\nSun4458\n\n\n16\n10.33\n1.67\nFemale\nNo\nSun\nDinner\n3\n3.44\nElizabeth Foster\n4240025044626033\nSun9715\n\n\n17\n16.29\n3.71\nMale\nNo\nSun\nDinner\n3\n5.43\nJohn Pittman\n6521340257218708\nSun2998\n\n\n18\n16.97\n3.50\nFemale\nNo\nSun\nDinner\n3\n5.66\nLaura Martinez\n30422275171379\nSun2789\n\n\n19\n20.65\n3.35\nMale\nNo\nSat\nDinner\n3\n6.88\nTimothy Oneal\n6568069240986485\nSat9213\n\n\n35\n24.06\n3.60\nMale\nNo\nSat\nDinner\n3\n8.02\nJoseph Mullins\n5519770449260299\nSat632\n\n\n36\n16.31\n2.00\nMale\nNo\nSat\nDinner\n3\n5.44\nWilliam Ford\n3527691170179398\nSat9139\n\n\n37\n16.93\n3.07\nFemale\nNo\nSat\nDinner\n3\n5.64\nErin Lewis\n5161695527390786\nSat6406\n\n\n38\n18.69\n2.31\nMale\nNo\nSat\nDinner\n3\n6.23\nBrandon Bradley\n4427601595688633\nSat4056\n\n\n39\n31.27\n5.00\nMale\nNo\nSat\nDinner\n3\n10.42\nMr. Brandon Berry\n6011525851069856\nSat6373\n\n\n40\n16.04\n2.24\nMale\nNo\nSat\nDinner\n3\n5.35\nAdam Edwards\n3544447755679420\nSat8549\n\n\n48\n28.55\n2.05\nMale\nNo\nSun\nDinner\n3\n9.52\nAustin Fisher\n6011481668986587\nSun4142\n\n\n64\n17.59\n2.64\nMale\nNo\nSat\nDinner\n3\n5.86\nMichael Johnson\n2222114458088108\nSat1667\n\n\n65\n20.08\n3.15\nMale\nNo\nSat\nDinner\n3\n6.69\nJustin Dixon\n180021262464926\nSat6840\n\n\n71\n17.07\n3.00\nFemale\nNo\nSat\nDinner\n3\n5.69\nTeresa Fisher\n5442222963796367\nSat3469\n\n\n102\n44.30\n2.50\nFemale\nYes\nSat\nDinner\n3\n14.77\nHeather Cohen\n379771118886604\nSat6240\n\n\n112\n38.07\n4.00\nMale\nNo\nSun\nDinner\n3\n12.69\nJeff Lopez\n3572865915176463\nSun591\n\n\n114\n25.71\n4.00\nFemale\nNo\nSun\nDinner\n3\n8.57\nKatie Smith\n5400160161311292\nSun6492\n\n\n129\n22.82\n2.18\nMale\nNo\nThur\nLunch\n3\n7.61\nRaymond Torres\n4855776744024\nThur9424\n\n\n146\n18.64\n1.36\nFemale\nNo\nThur\nLunch\n3\n6.21\nKelly Estrada\n60463302327\nThur3941\n\n\n152\n17.26\n2.74\nMale\nNo\nSun\nDinner\n3\n5.75\nGregory Smith\n4292362333741\nSun5205\n\n\n162\n16.21\n2.00\nFemale\nNo\nSun\nDinner\n3\n5.40\nJennifer Baird\n4227834176859693\nSun5521\n\n\n165\n24.52\n3.48\nMale\nNo\nSun\nDinner\n3\n8.17\nJacob Hansen\n4031116007387\nSun9043\n\n\n170\n50.81\n10.00\nMale\nYes\nSat\nDinner\n3\n16.94\nGregory Clark\n5473850968388236\nSat1954\n\n\n182\n45.35\n3.50\nMale\nYes\nSun\nDinner\n3\n15.12\nJose Parsons\n4112207559459910\nSun2337\n\n\n186\n20.90\n3.50\nFemale\nYes\nSun\nDinner\n3\n6.97\nHeidi Atkinson\n4422858423131187\nSun4254\n\n\n188\n18.15\n3.50\nFemale\nYes\nSun\nDinner\n3\n6.05\nGlenda Wiggins\n578329325307\nSun430\n\n\n189\n23.10\n4.00\nMale\nYes\nSun\nDinner\n3\n7.70\nRichard Stevens\n3560193117506187\nSun1821\n\n\n200\n18.71\n4.00\nMale\nYes\nThur\nLunch\n3\n6.24\nJason Conrad\n4581233003487\nThur6048\n\n\n205\n16.47\n3.23\nFemale\nYes\nThur\nLunch\n3\n5.49\nCarly Reyes\n4787787236486\nThur8084\n\n\n206\n26.59\n3.41\nMale\nYes\nSat\nDinner\n3\n8.86\nDaniel Owens\n38971087967574\nSat1\n\n\n210\n30.06\n2.00\nMale\nYes\nSat\nDinner\n3\n10.02\nShawn Mendoza\n30184049218122\nSat8361\n\n\n214\n28.17\n6.50\nFemale\nYes\nSat\nDinner\n3\n9.39\nMarissa Jackson\n4922302538691962\nSat3374\n\n\n223\n15.98\n3.00\nFemale\nNo\nFri\nLunch\n3\n5.33\nMary Rivera\n5343428579353069\nFri6014\n\n\n231\n15.69\n3.00\nMale\nYes\nSat\nDinner\n3\n5.23\nJason Parks\n4812333796161\nSat6334\n\n\n238\n35.83\n4.67\nFemale\nNo\nSat\nDinner\n3\n11.94\nKimberly Crane\n676184013727\nSat9777\n\n\n239\n29.03\n5.92\nMale\nNo\nSat\nDinner\n3\n9.68\nMichael Avila\n5296068606052842\nSat2657\n\n\n\n\n\n\n\n\n\nconditional = (df_tips[\"size\"] == 3) & (df_tips[\"total_bill\"] &gt; 20)\nprint(conditional)\n\n0      False\n1      False\n2       True\n3      False\n4      False\n       ...  \n239     True\n240    False\n241    False\n242    False\n243    False\nLength: 244, dtype: bool\n\n\n\ndf_tips[conditional]\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nprice_per_person\nPayer Name\nCC Number\nPayment ID\n\n\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n7.00\nTravis Walters\n6011812112971322\nSun4458\n\n\n19\n20.65\n3.35\nMale\nNo\nSat\nDinner\n3\n6.88\nTimothy Oneal\n6568069240986485\nSat9213\n\n\n35\n24.06\n3.60\nMale\nNo\nSat\nDinner\n3\n8.02\nJoseph Mullins\n5519770449260299\nSat632\n\n\n39\n31.27\n5.00\nMale\nNo\nSat\nDinner\n3\n10.42\nMr. Brandon Berry\n6011525851069856\nSat6373\n\n\n48\n28.55\n2.05\nMale\nNo\nSun\nDinner\n3\n9.52\nAustin Fisher\n6011481668986587\nSun4142\n\n\n65\n20.08\n3.15\nMale\nNo\nSat\nDinner\n3\n6.69\nJustin Dixon\n180021262464926\nSat6840\n\n\n102\n44.30\n2.50\nFemale\nYes\nSat\nDinner\n3\n14.77\nHeather Cohen\n379771118886604\nSat6240\n\n\n112\n38.07\n4.00\nMale\nNo\nSun\nDinner\n3\n12.69\nJeff Lopez\n3572865915176463\nSun591\n\n\n114\n25.71\n4.00\nFemale\nNo\nSun\nDinner\n3\n8.57\nKatie Smith\n5400160161311292\nSun6492\n\n\n129\n22.82\n2.18\nMale\nNo\nThur\nLunch\n3\n7.61\nRaymond Torres\n4855776744024\nThur9424\n\n\n165\n24.52\n3.48\nMale\nNo\nSun\nDinner\n3\n8.17\nJacob Hansen\n4031116007387\nSun9043\n\n\n170\n50.81\n10.00\nMale\nYes\nSat\nDinner\n3\n16.94\nGregory Clark\n5473850968388236\nSat1954\n\n\n182\n45.35\n3.50\nMale\nYes\nSun\nDinner\n3\n15.12\nJose Parsons\n4112207559459910\nSun2337\n\n\n186\n20.90\n3.50\nFemale\nYes\nSun\nDinner\n3\n6.97\nHeidi Atkinson\n4422858423131187\nSun4254\n\n\n189\n23.10\n4.00\nMale\nYes\nSun\nDinner\n3\n7.70\nRichard Stevens\n3560193117506187\nSun1821\n\n\n206\n26.59\n3.41\nMale\nYes\nSat\nDinner\n3\n8.86\nDaniel Owens\n38971087967574\nSat1\n\n\n210\n30.06\n2.00\nMale\nYes\nSat\nDinner\n3\n10.02\nShawn Mendoza\n30184049218122\nSat8361\n\n\n214\n28.17\n6.50\nFemale\nYes\nSat\nDinner\n3\n9.39\nMarissa Jackson\n4922302538691962\nSat3374\n\n\n238\n35.83\n4.67\nFemale\nNo\nSat\nDinner\n3\n11.94\nKimberly Crane\n676184013727\nSat9777\n\n\n239\n29.03\n5.92\nMale\nNo\nSat\nDinner\n3\n9.68\nMichael Avila\n5296068606052842\nSat2657\n\n\n\n\n\n\n\n\n\ndf_tips[(df_tips[\"size\"] == 3) & (df_tips[\"total_bill\"] &gt; 20)]\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nprice_per_person\nPayer Name\nCC Number\nPayment ID\n\n\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n7.00\nTravis Walters\n6011812112971322\nSun4458\n\n\n19\n20.65\n3.35\nMale\nNo\nSat\nDinner\n3\n6.88\nTimothy Oneal\n6568069240986485\nSat9213\n\n\n35\n24.06\n3.60\nMale\nNo\nSat\nDinner\n3\n8.02\nJoseph Mullins\n5519770449260299\nSat632\n\n\n39\n31.27\n5.00\nMale\nNo\nSat\nDinner\n3\n10.42\nMr. Brandon Berry\n6011525851069856\nSat6373\n\n\n48\n28.55\n2.05\nMale\nNo\nSun\nDinner\n3\n9.52\nAustin Fisher\n6011481668986587\nSun4142\n\n\n65\n20.08\n3.15\nMale\nNo\nSat\nDinner\n3\n6.69\nJustin Dixon\n180021262464926\nSat6840\n\n\n102\n44.30\n2.50\nFemale\nYes\nSat\nDinner\n3\n14.77\nHeather Cohen\n379771118886604\nSat6240\n\n\n112\n38.07\n4.00\nMale\nNo\nSun\nDinner\n3\n12.69\nJeff Lopez\n3572865915176463\nSun591\n\n\n114\n25.71\n4.00\nFemale\nNo\nSun\nDinner\n3\n8.57\nKatie Smith\n5400160161311292\nSun6492\n\n\n129\n22.82\n2.18\nMale\nNo\nThur\nLunch\n3\n7.61\nRaymond Torres\n4855776744024\nThur9424\n\n\n165\n24.52\n3.48\nMale\nNo\nSun\nDinner\n3\n8.17\nJacob Hansen\n4031116007387\nSun9043\n\n\n170\n50.81\n10.00\nMale\nYes\nSat\nDinner\n3\n16.94\nGregory Clark\n5473850968388236\nSat1954\n\n\n182\n45.35\n3.50\nMale\nYes\nSun\nDinner\n3\n15.12\nJose Parsons\n4112207559459910\nSun2337\n\n\n186\n20.90\n3.50\nFemale\nYes\nSun\nDinner\n3\n6.97\nHeidi Atkinson\n4422858423131187\nSun4254\n\n\n189\n23.10\n4.00\nMale\nYes\nSun\nDinner\n3\n7.70\nRichard Stevens\n3560193117506187\nSun1821\n\n\n206\n26.59\n3.41\nMale\nYes\nSat\nDinner\n3\n8.86\nDaniel Owens\n38971087967574\nSat1\n\n\n210\n30.06\n2.00\nMale\nYes\nSat\nDinner\n3\n10.02\nShawn Mendoza\n30184049218122\nSat8361\n\n\n214\n28.17\n6.50\nFemale\nYes\nSat\nDinner\n3\n9.39\nMarissa Jackson\n4922302538691962\nSat3374\n\n\n238\n35.83\n4.67\nFemale\nNo\nSat\nDinner\n3\n11.94\nKimberly Crane\n676184013727\nSat9777\n\n\n239\n29.03\n5.92\nMale\nNo\nSat\nDinner\n3\n9.68\nMichael Avila\n5296068606052842\nSat2657\n\n\n\n\n\n\n\n\n\nconditional_or = (df_tips[\"tip\"] &gt; 4) | (df_tips[\"total_bill\"] &gt; 20)\ndf_tips[conditional_or]\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nprice_per_person\nPayer Name\nCC Number\nPayment ID\n\n\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n7.00\nTravis Walters\n6011812112971322\nSun4458\n\n\n3\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n11.84\nNathaniel Harris\n4676137647685994\nSun5260\n\n\n4\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4\n6.15\nTonya Carter\n4832732618637221\nSun2251\n\n\n5\n25.29\n4.71\nMale\nNo\nSun\nDinner\n4\n6.32\nErik Smith\n213140353657882\nSun9679\n\n\n7\n26.88\n3.12\nMale\nNo\nSun\nDinner\n4\n6.72\nRobert Buck\n3514785077705092\nSun8157\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n237\n32.83\n1.17\nMale\nYes\nSat\nDinner\n2\n16.42\nThomas Brown\n4284722681265508\nSat2929\n\n\n238\n35.83\n4.67\nFemale\nNo\nSat\nDinner\n3\n11.94\nKimberly Crane\n676184013727\nSat9777\n\n\n239\n29.03\n5.92\nMale\nNo\nSat\nDinner\n3\n9.68\nMichael Avila\n5296068606052842\nSat2657\n\n\n240\n27.18\n2.00\nFemale\nYes\nSat\nDinner\n2\n13.59\nMonica Sanders\n3506806155565404\nSat1766\n\n\n241\n22.67\n2.00\nMale\nYes\nSat\nDinner\n2\n11.34\nKeith Wong\n6011891618747196\nSat3880\n\n\n\n\n101 rows × 11 columns\n\n\n\n\n\nweekend = [\"Sun\", \"Sat\"]\nconditional_in = df_tips[\"day\"].isin(weekend)\ndf_tips[conditional_in]\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nprice_per_person\nPayer Name\nCC Number\nPayment ID\n\n\n\n\n0\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n8.49\nChristy Cunningham\n3560325168603410\nSun2959\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n3.45\nDouglas Tucker\n4478071379779230\nSun4608\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n7.00\nTravis Walters\n6011812112971322\nSun4458\n\n\n3\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n11.84\nNathaniel Harris\n4676137647685994\nSun5260\n\n\n4\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4\n6.15\nTonya Carter\n4832732618637221\nSun2251\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n238\n35.83\n4.67\nFemale\nNo\nSat\nDinner\n3\n11.94\nKimberly Crane\n676184013727\nSat9777\n\n\n239\n29.03\n5.92\nMale\nNo\nSat\nDinner\n3\n9.68\nMichael Avila\n5296068606052842\nSat2657\n\n\n240\n27.18\n2.00\nFemale\nYes\nSat\nDinner\n2\n13.59\nMonica Sanders\n3506806155565404\nSat1766\n\n\n241\n22.67\n2.00\nMale\nYes\nSat\nDinner\n2\n11.34\nKeith Wong\n6011891618747196\nSat3880\n\n\n242\n17.82\n1.75\nMale\nNo\nSat\nDinner\n2\n8.91\nDennis Dixon\n4375220550950\nSat17\n\n\n\n\n163 rows × 11 columns\n\n\n\n\n\ndf_tips.head()\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nprice_per_person\nPayer Name\nCC Number\nPayment ID\n\n\n\n\n0\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n8.49\nChristy Cunningham\n3560325168603410\nSun2959\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n3.45\nDouglas Tucker\n4478071379779230\nSun4608\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n7.00\nTravis Walters\n6011812112971322\nSun4458\n\n\n3\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n11.84\nNathaniel Harris\n4676137647685994\nSun5260\n\n\n4\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4\n6.15\nTonya Carter\n4832732618637221\nSun2251\n\n\n\n\n\n\n\n\n\n\nmencari nilai unik\n\ndf_tips[\"day\"].unique()\n\narray(['Sun', 'Sat', 'Thur', 'Fri'], dtype=object)\n\n\n\ndf_tips[[\"day\",\"time\"]]\n\n\n\n\n\n\n\n\n\nday\ntime\n\n\n\n\n0\nSun\nDinner\n\n\n1\nSun\nDinner\n\n\n2\nSun\nDinner\n\n\n3\nSun\nDinner\n\n\n4\nSun\nDinner\n\n\n...\n...\n...\n\n\n239\nSat\nDinner\n\n\n240\nSat\nDinner\n\n\n241\nSat\nDinner\n\n\n242\nSat\nDinner\n\n\n243\nThur\nDinner\n\n\n\n\n244 rows × 2 columns\n\n\n\n\n\ndf_tips.drop_duplicates([\"day\",\"time\"])[[\"day\",\"time\"]]\n\n\n\n\n\n\n\n\n\nday\ntime\n\n\n\n\n0\nSun\nDinner\n\n\n19\nSat\nDinner\n\n\n77\nThur\nLunch\n\n\n90\nFri\nDinner\n\n\n220\nFri\nLunch\n\n\n243\nThur\nDinner\n\n\n\n\n\n\n\n\n\n\n\nTransforming Data (Column Wise)\n\nSelecting Columns\n\nprint(df_tips[\"day\"])\n\n0       Sun\n1       Sun\n2       Sun\n3       Sun\n4       Sun\n       ... \n239     Sat\n240     Sat\n241     Sat\n242     Sat\n243    Thur\nName: day, Length: 244, dtype: object\n\n\n\nprint(df_tips.day)\n\n0       Sun\n1       Sun\n2       Sun\n3       Sun\n4       Sun\n       ... \n239     Sat\n240     Sat\n241     Sat\n242     Sat\n243    Thur\nName: day, Length: 244, dtype: object\n\n\n\ndf_tips[[\"day\",\"time\"]]\n\n\n\n\n\n\n\n\n\nday\ntime\n\n\n\n\n0\nSun\nDinner\n\n\n1\nSun\nDinner\n\n\n2\nSun\nDinner\n\n\n3\nSun\nDinner\n\n\n4\nSun\nDinner\n\n\n...\n...\n...\n\n\n239\nSat\nDinner\n\n\n240\nSat\nDinner\n\n\n241\nSat\nDinner\n\n\n242\nSat\nDinner\n\n\n243\nThur\nDinner\n\n\n\n\n244 rows × 2 columns\n\n\n\n\n\n\nMutating (create new column)\n\ndf_tips[\"tips_percentage\"]= df_tips[\"tip\"]/df_tips[\"total_bill\"]*100\n\ndf_tips.head()\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nprice_per_person\nPayer Name\nCC Number\nPayment ID\ntips_percentage\n\n\n\n\n0\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n8.49\nChristy Cunningham\n3560325168603410\nSun2959\n5.944673\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n3.45\nDouglas Tucker\n4478071379779230\nSun4608\n16.054159\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n7.00\nTravis Walters\n6011812112971322\nSun4458\n16.658734\n\n\n3\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n11.84\nNathaniel Harris\n4676137647685994\nSun5260\n13.978041\n\n\n4\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4\n6.15\nTonya Carter\n4832732618637221\nSun2251\n14.680765\n\n\n\n\n\n\n\n\n\n\nrenaming column\n\ndf_tips.rename(columns={\"tips_percentage\": \"tips_%\"}, inplace=True)\ndf_tips.head()\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nprice_per_person\nPayer Name\nCC Number\nPayment ID\ntips_%\n\n\n\n\n0\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n8.49\nChristy Cunningham\n3560325168603410\nSun2959\n5.944673\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n3.45\nDouglas Tucker\n4478071379779230\nSun4608\n16.054159\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n7.00\nTravis Walters\n6011812112971322\nSun4458\n16.658734\n\n\n3\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n11.84\nNathaniel Harris\n4676137647685994\nSun5260\n13.978041\n\n\n4\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4\n6.15\nTonya Carter\n4832732618637221\nSun2251\n14.680765\n\n\n\n\n\n\n\n\n\n\nrelocate columns\n\n#relocate tips_percentage_% column to the rightmost\ncols = list(df_tips.columns)\ncols = [cols[-1]]+ cols[:-2]\n\ndf_tips = df_tips[cols]\n\n\ndf_tips\n\n\n\n\n\n\n\n\n\ntips_%\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nprice_per_person\nPayer Name\nCC Number\n\n\n\n\n0\n5.944673\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n8.49\nChristy Cunningham\n3560325168603410\n\n\n1\n16.054159\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n3.45\nDouglas Tucker\n4478071379779230\n\n\n2\n16.658734\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n7.00\nTravis Walters\n6011812112971322\n\n\n3\n13.978041\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n11.84\nNathaniel Harris\n4676137647685994\n\n\n4\n14.680765\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4\n6.15\nTonya Carter\n4832732618637221\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n239\n20.392697\n29.03\n5.92\nMale\nNo\nSat\nDinner\n3\n9.68\nMichael Avila\n5296068606052842\n\n\n240\n7.358352\n27.18\n2.00\nFemale\nYes\nSat\nDinner\n2\n13.59\nMonica Sanders\n3506806155565404\n\n\n241\n8.822232\n22.67\n2.00\nMale\nYes\nSat\nDinner\n2\n11.34\nKeith Wong\n6011891618747196\n\n\n242\n9.820426\n17.82\n1.75\nMale\nNo\nSat\nDinner\n2\n8.91\nDennis Dixon\n4375220550950\n\n\n243\n15.974441\n18.78\n3.00\nFemale\nNo\nThur\nDinner\n2\n9.39\nMichelle Hardin\n3511451626698139\n\n\n\n\n244 rows × 11 columns"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul1.html#export-dataframe-ke-csv",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul1.html#export-dataframe-ke-csv",
    "title": "Modul 1 Sains Data: Pengenalan Pandas, Transformasi Data",
    "section": "Export DataFrame ke CSV",
    "text": "Export DataFrame ke CSV\n\ndf_tips.to_csv(\"tips_modified.csv\")"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul3.html",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul3.html",
    "title": "Modul 3 Sains Data",
    "section": "",
    "text": "Kembali ke Sains Data\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nInstall scikit-learn dengan:\n!pip install scikit-learn\nLalu import sklearn:\nimport sklearn"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul3.html#import-dataset",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul3.html#import-dataset",
    "title": "Modul 3 Sains Data",
    "section": "Import Dataset",
    "text": "Import Dataset\nUntuk praktikum kali ini, kita akan menggunakan dataset “California Housing Prices” (housing.csv) yang bisa didownload dari salah satu sumber berikut:\n\nDirect link (langsung dari GitHub Pages ini)\nKaggle: https://www.kaggle.com/datasets/camnugent/california-housing-prices\n\nKemudian, baca sebagai dataframe:\n\ndf = pd.read_csv(\"./housing.csv\")\n\nMari kita lihat isinya:\n\ndf\n\n\n\n\n\n\n\n\n\nlongitude\nlatitude\nhousing_median_age\ntotal_rooms\ntotal_bedrooms\npopulation\nhouseholds\nmedian_income\nmedian_house_value\nocean_proximity\n\n\n\n\n0\n-122.23\n37.88\n41.0\n880.0\n129.0\n322.0\n126.0\n8.3252\n452600.0\nNEAR BAY\n\n\n1\n-122.22\n37.86\n21.0\n7099.0\n1106.0\n2401.0\n1138.0\n8.3014\n358500.0\nNEAR BAY\n\n\n2\n-122.24\n37.85\n52.0\n1467.0\n190.0\n496.0\n177.0\n7.2574\n352100.0\nNEAR BAY\n\n\n3\n-122.25\n37.85\n52.0\n1274.0\n235.0\n558.0\n219.0\n5.6431\n341300.0\nNEAR BAY\n\n\n4\n-122.25\n37.85\n52.0\n1627.0\n280.0\n565.0\n259.0\n3.8462\n342200.0\nNEAR BAY\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n20635\n-121.09\n39.48\n25.0\n1665.0\n374.0\n845.0\n330.0\n1.5603\n78100.0\nINLAND\n\n\n20636\n-121.21\n39.49\n18.0\n697.0\n150.0\n356.0\n114.0\n2.5568\n77100.0\nINLAND\n\n\n20637\n-121.22\n39.43\n17.0\n2254.0\n485.0\n1007.0\n433.0\n1.7000\n92300.0\nINLAND\n\n\n20638\n-121.32\n39.43\n18.0\n1860.0\n409.0\n741.0\n349.0\n1.8672\n84700.0\nINLAND\n\n\n20639\n-121.24\n39.37\n16.0\n2785.0\n616.0\n1387.0\n530.0\n2.3886\n89400.0\nINLAND\n\n\n\n\n20640 rows × 10 columns\n\n\n\n\nAda satu data kategorik, yaitu ocean_proximity. Mari kita liat jenis-jenisnya (kategorinya):\n\ndf[\"ocean_proximity\"].value_counts()\n\nocean_proximity\n&lt;1H OCEAN     9136\nINLAND        6551\nNEAR OCEAN    2658\nNEAR BAY      2290\nISLAND           5\nName: count, dtype: int64\n\n\nApakah ada missing value?\n\ndf.isna().sum()\n\nlongitude               0\nlatitude                0\nhousing_median_age      0\ntotal_rooms             0\ntotal_bedrooms        207\npopulation              0\nhouseholds              0\nmedian_income           0\nmedian_house_value      0\nocean_proximity         0\ndtype: int64\n\n\n\ndf[df[\"total_bedrooms\"].isna()]\n\n\n\n\n\n\n\n\n\nlongitude\nlatitude\nhousing_median_age\ntotal_rooms\ntotal_bedrooms\npopulation\nhouseholds\nmedian_income\nmedian_house_value\nocean_proximity\n\n\n\n\n290\n-122.16\n37.77\n47.0\n1256.0\nNaN\n570.0\n218.0\n4.3750\n161900.0\nNEAR BAY\n\n\n341\n-122.17\n37.75\n38.0\n992.0\nNaN\n732.0\n259.0\n1.6196\n85100.0\nNEAR BAY\n\n\n538\n-122.28\n37.78\n29.0\n5154.0\nNaN\n3741.0\n1273.0\n2.5762\n173400.0\nNEAR BAY\n\n\n563\n-122.24\n37.75\n45.0\n891.0\nNaN\n384.0\n146.0\n4.9489\n247100.0\nNEAR BAY\n\n\n696\n-122.10\n37.69\n41.0\n746.0\nNaN\n387.0\n161.0\n3.9063\n178400.0\nNEAR BAY\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n20267\n-119.19\n34.20\n18.0\n3620.0\nNaN\n3171.0\n779.0\n3.3409\n220500.0\nNEAR OCEAN\n\n\n20268\n-119.18\n34.19\n19.0\n2393.0\nNaN\n1938.0\n762.0\n1.6953\n167400.0\nNEAR OCEAN\n\n\n20372\n-118.88\n34.17\n15.0\n4260.0\nNaN\n1701.0\n669.0\n5.1033\n410700.0\n&lt;1H OCEAN\n\n\n20460\n-118.75\n34.29\n17.0\n5512.0\nNaN\n2734.0\n814.0\n6.6073\n258100.0\n&lt;1H OCEAN\n\n\n20484\n-118.72\n34.28\n17.0\n3051.0\nNaN\n1705.0\n495.0\n5.7376\n218600.0\n&lt;1H OCEAN\n\n\n\n\n207 rows × 10 columns\n\n\n\n\nPerhatikan bahwa tipe datanya adalah int64 atau bilangan bulat.\nDari 20640 baris, ada satu kolom/fitur (total_bedrooms) dengan 207 missing value.\nSecara umum, ada dua cara untuk menangani missing value:\n\nMenghapus baris-baris yang memiliki missing value, dengan df.dropna()\nMelakukan metode imputasi\n\nKarena banyaknya missing value relatif sedikit, sebenarnya tidak masalah apabila baris-baris tersebut cukup dihapus saja. Namun, kita akan mempelajari metode imputasi."
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul3.html#encoding-data-kategorik",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul3.html#encoding-data-kategorik",
    "title": "Modul 3 Sains Data",
    "section": "Encoding Data Kategorik",
    "text": "Encoding Data Kategorik\nSebelum kita membahas metode imputasi, kita akan membahas tentang melakukan “encoding” untuk data kategorik.\nBanyak metode sains data / machine learning yang hanya bisa digunakan dengan data numerik. Oleh karena itu, data kategorik perlu diubah terlebih dahulu menjadi data numerik, melakukan yang namanya categorical data encoding\nMetode yang sering digunakan adalah one hot encoding. Misalnya ada satu fitur kategorik dengan \\(n\\) kemungkinan data, bernama \\(D_i\\) untuk \\(i = 1, 2, \\dots, n\\). Maka fitur tersebut diganti dengan \\(n\\) kolom baru, misal bernama \\(K_i\\) untuk \\(i = 1, 2, \\dots, n\\), di mana pada kolom ke-i, isinya adalah\n\n\\(1\\), apabila data aslinya pada baris tersebut adalah \\(D_i\\)\n\\(0\\) apabila bukan \\(D_i\\)\n\n\nfrom sklearn.preprocessing import OneHotEncoder\n\n\nencoder = OneHotEncoder()\n\n\nhasil_onehot = encoder.fit_transform(df[[\"ocean_proximity\"]])\n\n\nprint(encoder.categories_)\n\n[array(['&lt;1H OCEAN', 'INLAND', 'ISLAND', 'NEAR BAY', 'NEAR OCEAN'],\n      dtype=object)]\n\n\n\nprint(encoder.categories_[0])\n\n['&lt;1H OCEAN' 'INLAND' 'ISLAND' 'NEAR BAY' 'NEAR OCEAN']\n\n\n\nkolom_encoding = list(encoder.categories_[0])\n\n\nprint(kolom_encoding)\n\n['&lt;1H OCEAN', 'INLAND', 'ISLAND', 'NEAR BAY', 'NEAR OCEAN']\n\n\n\nonehot_array = hasil_onehot.toarray()\n\n\nprint(onehot_array)\n\n[[0. 0. 0. 1. 0.]\n [0. 0. 0. 1. 0.]\n [0. 0. 0. 1. 0.]\n ...\n [0. 1. 0. 0. 0.]\n [0. 1. 0. 0. 0.]\n [0. 1. 0. 0. 0.]]\n\n\n\nonehot_df = pd.DataFrame(onehot_array, columns=kolom_encoding)\n\n\nonehot_df\n\n\n\n\n\n\n\n\n\n&lt;1H OCEAN\nINLAND\nISLAND\nNEAR BAY\nNEAR OCEAN\n\n\n\n\n0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n1\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n2\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n3\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n4\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n...\n...\n...\n...\n...\n...\n\n\n20635\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20636\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20637\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20638\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20639\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n\n\n20640 rows × 5 columns\n\n\n\n\n\ndf = pd.concat([df, onehot_df], axis=1)\n\n\ndf\n\n\n\n\n\n\n\n\n\nlongitude\nlatitude\nhousing_median_age\ntotal_rooms\ntotal_bedrooms\npopulation\nhouseholds\nmedian_income\nmedian_house_value\nocean_proximity\n&lt;1H OCEAN\nINLAND\nISLAND\nNEAR BAY\nNEAR OCEAN\n\n\n\n\n0\n-122.23\n37.88\n41.0\n880.0\n129.0\n322.0\n126.0\n8.3252\n452600.0\nNEAR BAY\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n1\n-122.22\n37.86\n21.0\n7099.0\n1106.0\n2401.0\n1138.0\n8.3014\n358500.0\nNEAR BAY\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n2\n-122.24\n37.85\n52.0\n1467.0\n190.0\n496.0\n177.0\n7.2574\n352100.0\nNEAR BAY\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n3\n-122.25\n37.85\n52.0\n1274.0\n235.0\n558.0\n219.0\n5.6431\n341300.0\nNEAR BAY\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n4\n-122.25\n37.85\n52.0\n1627.0\n280.0\n565.0\n259.0\n3.8462\n342200.0\nNEAR BAY\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n20635\n-121.09\n39.48\n25.0\n1665.0\n374.0\n845.0\n330.0\n1.5603\n78100.0\nINLAND\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20636\n-121.21\n39.49\n18.0\n697.0\n150.0\n356.0\n114.0\n2.5568\n77100.0\nINLAND\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20637\n-121.22\n39.43\n17.0\n2254.0\n485.0\n1007.0\n433.0\n1.7000\n92300.0\nINLAND\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20638\n-121.32\n39.43\n18.0\n1860.0\n409.0\n741.0\n349.0\n1.8672\n84700.0\nINLAND\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20639\n-121.24\n39.37\n16.0\n2785.0\n616.0\n1387.0\n530.0\n2.3886\n89400.0\nINLAND\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n\n\n20640 rows × 15 columns\n\n\n\n\n\ndf = df.drop([\"ocean_proximity\"], axis=1)\n\n\ndf\n\n\n\n\n\n\n\n\n\nlongitude\nlatitude\nhousing_median_age\ntotal_rooms\ntotal_bedrooms\npopulation\nhouseholds\nmedian_income\nmedian_house_value\n&lt;1H OCEAN\nINLAND\nISLAND\nNEAR BAY\nNEAR OCEAN\n\n\n\n\n0\n-122.23\n37.88\n41.0\n880.0\n129.0\n322.0\n126.0\n8.3252\n452600.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n1\n-122.22\n37.86\n21.0\n7099.0\n1106.0\n2401.0\n1138.0\n8.3014\n358500.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n2\n-122.24\n37.85\n52.0\n1467.0\n190.0\n496.0\n177.0\n7.2574\n352100.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n3\n-122.25\n37.85\n52.0\n1274.0\n235.0\n558.0\n219.0\n5.6431\n341300.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n4\n-122.25\n37.85\n52.0\n1627.0\n280.0\n565.0\n259.0\n3.8462\n342200.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n20635\n-121.09\n39.48\n25.0\n1665.0\n374.0\n845.0\n330.0\n1.5603\n78100.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20636\n-121.21\n39.49\n18.0\n697.0\n150.0\n356.0\n114.0\n2.5568\n77100.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20637\n-121.22\n39.43\n17.0\n2254.0\n485.0\n1007.0\n433.0\n1.7000\n92300.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20638\n-121.32\n39.43\n18.0\n1860.0\n409.0\n741.0\n349.0\n1.8672\n84700.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20639\n-121.24\n39.37\n16.0\n2785.0\n616.0\n1387.0\n530.0\n2.3886\n89400.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n\n\n20640 rows × 14 columns"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul3.html#metode-imputasi",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul3.html#metode-imputasi",
    "title": "Modul 3 Sains Data",
    "section": "Metode Imputasi",
    "text": "Metode Imputasi\n\nMedian\n\ndf_fill_median = df.copy()\n\n\ndf[\"total_bedrooms\"].median()\n\n435.0\n\n\n\nbedrooms_median = df[\"total_bedrooms\"].median()\nprint(bedrooms_median)\n\n435.0\n\n\n\ndf_fill_median[\"total_bedrooms\"] = df_fill_median[\"total_bedrooms\"].fillna(bedrooms_median)\n\n\ndf_fill_median.isna().sum()\n\nlongitude             0\nlatitude              0\nhousing_median_age    0\ntotal_rooms           0\ntotal_bedrooms        0\npopulation            0\nhouseholds            0\nmedian_income         0\nmedian_house_value    0\n&lt;1H OCEAN             0\nINLAND                0\nISLAND                0\nNEAR BAY              0\nNEAR OCEAN            0\ndtype: int64\n\n\nCara lain, menggunakan scikit-learn:\n\ndf_fill_median2 = df.copy()\n\n\nfrom sklearn.impute import SimpleImputer\n\n\nmedian_imputer = SimpleImputer(\n    missing_values=np.nan, strategy='median'\n)\n\n\ndf_fill_median2[[\"total_bedrooms\"]] = median_imputer.fit_transform(\n    df_fill_median2[[\"total_bedrooms\"]]\n)\n\n\ndf_fill_median2.isna().sum()\n\nlongitude             0\nlatitude              0\nhousing_median_age    0\ntotal_rooms           0\ntotal_bedrooms        0\npopulation            0\nhouseholds            0\nmedian_income         0\nmedian_house_value    0\n&lt;1H OCEAN             0\nINLAND                0\nISLAND                0\nNEAR BAY              0\nNEAR OCEAN            0\ndtype: int64\n\n\n\n\nModus\n\ndf_fill_mode = df.copy()\n\n\ndf[\"total_bedrooms\"].mode()\n\n0    280.0\nName: total_bedrooms, dtype: float64\n\n\n\ndf[\"total_bedrooms\"].mode()[0]\n\n280.0\n\n\n\nbedrooms_mode = df[\"total_bedrooms\"].mode()[0]\nprint(bedrooms_mode)\n\n280.0\n\n\n\ndf_fill_mode[\"total_bedrooms\"] = df_fill_mode[\"total_bedrooms\"].fillna(bedrooms_mode)\n\n\ndf_fill_mode.isna().sum()\n\nlongitude             0\nlatitude              0\nhousing_median_age    0\ntotal_rooms           0\ntotal_bedrooms        0\npopulation            0\nhouseholds            0\nmedian_income         0\nmedian_house_value    0\n&lt;1H OCEAN             0\nINLAND                0\nISLAND                0\nNEAR BAY              0\nNEAR OCEAN            0\ndtype: int64\n\n\nCara lain, menggunakan scikit-learn:\n\ndf_fill_mode2 = df.copy()\n\n\nmode_imputer = SimpleImputer(\n    missing_values=np.nan, strategy='most_frequent'\n)\n\n\ndf_fill_mode2[[\"total_bedrooms\"]] = mode_imputer.fit_transform(\n    df_fill_mode2[[\"total_bedrooms\"]]\n)\n\n\ndf_fill_mode2.isna().sum()\n\nlongitude             0\nlatitude              0\nhousing_median_age    0\ntotal_rooms           0\ntotal_bedrooms        0\npopulation            0\nhouseholds            0\nmedian_income         0\nmedian_house_value    0\n&lt;1H OCEAN             0\nINLAND                0\nISLAND                0\nNEAR BAY              0\nNEAR OCEAN            0\ndtype: int64\n\n\n\n\nMean (rata-rata)\n\ndf_fill_mean = df.copy()\n\n\ndf_fill_mean[\"total_bedrooms\"].mean()\n\n537.8705525375618\n\n\n\nnp.round(df_fill_mean[\"total_bedrooms\"].mean())\n\n538.0\n\n\n\nbedrooms_mean = np.round(df_fill_mean[\"total_bedrooms\"].mean())\nprint(bedrooms_mean)\n\n538.0\n\n\n\ndf_fill_mean[\"total_bedrooms\"] = df_fill_mean[\"total_bedrooms\"].fillna(bedrooms_mean)\n\n\ndf_fill_mean.isna().sum()\n\nlongitude             0\nlatitude              0\nhousing_median_age    0\ntotal_rooms           0\ntotal_bedrooms        0\npopulation            0\nhouseholds            0\nmedian_income         0\nmedian_house_value    0\n&lt;1H OCEAN             0\nINLAND                0\nISLAND                0\nNEAR BAY              0\nNEAR OCEAN            0\ndtype: int64\n\n\nCara lain, menggunakan scikit-learn:\n\ndf_fill_mean2 = df.copy()\n\n\nmean_imputer = SimpleImputer(\n    missing_values=np.nan, strategy='mean'\n)\n\n\ndf_fill_mean2[[\"total_bedrooms\"]] = mean_imputer.fit_transform(\n    df_fill_mean2[[\"total_bedrooms\"]]\n)\n\n\ndf_fill_mean2.isna().sum()\n\nlongitude             0\nlatitude              0\nhousing_median_age    0\ntotal_rooms           0\ntotal_bedrooms        0\npopulation            0\nhouseholds            0\nmedian_income         0\nmedian_house_value    0\n&lt;1H OCEAN             0\nINLAND                0\nISLAND                0\nNEAR BAY              0\nNEAR OCEAN            0\ndtype: int64\n\n\n\n\nKNNImputer\n\nfrom sklearn.impute import KNNImputer\n\n\nknn_imputer = KNNImputer(n_neighbors=3)\n\n\ndf_fill_knn = df.copy()\n\nKNN Imputer memerlukan kolom-kolom lainnya sebagai acuan, dan hanya bisa bekerja dengan data numerik. Sehingga, kita perlu mem-filter terlebih dahulu kolom-kolom numerik dari dataset kita.\n\ndf_fill_knn.select_dtypes(include='number')\n\n\n\n\n\n\n\n\n\nlongitude\nlatitude\nhousing_median_age\ntotal_rooms\ntotal_bedrooms\npopulation\nhouseholds\nmedian_income\nmedian_house_value\n&lt;1H OCEAN\nINLAND\nISLAND\nNEAR BAY\nNEAR OCEAN\n\n\n\n\n0\n-122.23\n37.88\n41.0\n880.0\n129.0\n322.0\n126.0\n8.3252\n452600.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n1\n-122.22\n37.86\n21.0\n7099.0\n1106.0\n2401.0\n1138.0\n8.3014\n358500.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n2\n-122.24\n37.85\n52.0\n1467.0\n190.0\n496.0\n177.0\n7.2574\n352100.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n3\n-122.25\n37.85\n52.0\n1274.0\n235.0\n558.0\n219.0\n5.6431\n341300.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n4\n-122.25\n37.85\n52.0\n1627.0\n280.0\n565.0\n259.0\n3.8462\n342200.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n20635\n-121.09\n39.48\n25.0\n1665.0\n374.0\n845.0\n330.0\n1.5603\n78100.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20636\n-121.21\n39.49\n18.0\n697.0\n150.0\n356.0\n114.0\n2.5568\n77100.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20637\n-121.22\n39.43\n17.0\n2254.0\n485.0\n1007.0\n433.0\n1.7000\n92300.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20638\n-121.32\n39.43\n18.0\n1860.0\n409.0\n741.0\n349.0\n1.8672\n84700.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20639\n-121.24\n39.37\n16.0\n2785.0\n616.0\n1387.0\n530.0\n2.3886\n89400.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n\n\n20640 rows × 14 columns\n\n\n\n\n\ndf_fill_knn.select_dtypes(include='number').columns\n\nIndex(['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n       'total_bedrooms', 'population', 'households', 'median_income',\n       'median_house_value', '&lt;1H OCEAN', 'INLAND', 'ISLAND', 'NEAR BAY',\n       'NEAR OCEAN'],\n      dtype='object')\n\n\n\nnum_col = df_fill_knn.select_dtypes(include='number').columns\n\n\ndf_fill_knn[num_col] = knn_imputer.fit_transform(df_fill_knn[num_col])\n\n\ndf_fill_knn.isna().sum()\n\nlongitude             0\nlatitude              0\nhousing_median_age    0\ntotal_rooms           0\ntotal_bedrooms        0\npopulation            0\nhouseholds            0\nmedian_income         0\nmedian_house_value    0\n&lt;1H OCEAN             0\nINLAND                0\nISLAND                0\nNEAR BAY              0\nNEAR OCEAN            0\ndtype: int64"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul3.html#perbandingan-metode-imputasi",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul3.html#perbandingan-metode-imputasi",
    "title": "Modul 3 Sains Data",
    "section": "Perbandingan Metode Imputasi",
    "text": "Perbandingan Metode Imputasi\nKita bisa membandingkan beberapa metode imputasi (dan memilih yang mana yang terbaik) dengan langkah-langkah berikut.\n\nUse a sample of your own dataset that does not contain any missing data (will serve as ground truth).\nIntroduce increasing proportions of missing data at random (e.g. 5–50 % in 5 % increments).\nReconstruct the missing data using the various methods.\nCompute the sum of squared errors between the reconstructed and the original data, for each method and each proportion of missing data.\n\nLangkah pertama, kita perlu memperoleh sample dari dataset kita yang tidak mengandung missing value, yang bisa disebut ground truth. Cara termudah adalah dengan menghapus baris-baris yang memiliki missing value (biasanya dipilih lagi sample hanya sebagian baris, tapi di sini tidak kita lakukan):\n\ndf_ground_truth = df.dropna()\n\n\ndf_ground_truth\n\n\n\n\n\n\n\n\n\nlongitude\nlatitude\nhousing_median_age\ntotal_rooms\ntotal_bedrooms\npopulation\nhouseholds\nmedian_income\nmedian_house_value\n&lt;1H OCEAN\nINLAND\nISLAND\nNEAR BAY\nNEAR OCEAN\n\n\n\n\n0\n-122.23\n37.88\n41.0\n880.0\n129.0\n322.0\n126.0\n8.3252\n452600.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n1\n-122.22\n37.86\n21.0\n7099.0\n1106.0\n2401.0\n1138.0\n8.3014\n358500.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n2\n-122.24\n37.85\n52.0\n1467.0\n190.0\n496.0\n177.0\n7.2574\n352100.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n3\n-122.25\n37.85\n52.0\n1274.0\n235.0\n558.0\n219.0\n5.6431\n341300.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n4\n-122.25\n37.85\n52.0\n1627.0\n280.0\n565.0\n259.0\n3.8462\n342200.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n20635\n-121.09\n39.48\n25.0\n1665.0\n374.0\n845.0\n330.0\n1.5603\n78100.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20636\n-121.21\n39.49\n18.0\n697.0\n150.0\n356.0\n114.0\n2.5568\n77100.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20637\n-121.22\n39.43\n17.0\n2254.0\n485.0\n1007.0\n433.0\n1.7000\n92300.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20638\n-121.32\n39.43\n18.0\n1860.0\n409.0\n741.0\n349.0\n1.8672\n84700.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20639\n-121.24\n39.37\n16.0\n2785.0\n616.0\n1387.0\n530.0\n2.3886\n89400.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n\n\n20433 rows × 14 columns\n\n\n\n\nSelanjutnya, kita perlu membolong-bolongi dataset ini, agar sekian persen diisi missing value.\n\nimport random\n\n\ndef missing_value_generator(df_original, percentage):\n    df_miss = df_original.copy()\n    baris, kolom = df_miss.shape\n    n_total = baris*kolom\n\n    permutasi = list(range(n_total))\n    random.shuffle(permutasi)\n\n    n_pilih = int(percentage * n_total)\n    pilihan = permutasi[0 : n_pilih]\n\n    for p in pilihan:\n        df_miss.iloc[ int(p/kolom), p%kolom ] = np.nan\n    \n    return df_miss\n\n\ndf_miss_5 = missing_value_generator(df, 0.05)\n\n\ndf_miss_5.isna().sum()\n\nlongitude             1021\nlatitude              1015\nhousing_median_age    1064\ntotal_rooms           1004\ntotal_bedrooms        1205\npopulation            1087\nhouseholds            1032\nmedian_income         1004\nmedian_house_value    1018\n&lt;1H OCEAN             1050\nINLAND                1023\nISLAND                1085\nNEAR BAY              1051\nNEAR OCEAN             981\ndtype: int64\n\n\n\ndef compare_imputation(df_ground_truth, methods, percentages):\n    list_missing_df = []\n    for percent in percentages:\n        df_miss = missing_value_generator(df_ground_truth, percent)\n        list_missing_df.append(df_miss)\n\n    all_results = []\n    for method in methods:\n        method_results = []\n        for df_miss in list_missing_df:\n            df_imputed = method.fit_transform(df_miss)\n            SSE = ((df_ground_truth - df_imputed)**2).sum().sum()\n            method_results.append(SSE)\n        all_results.append(method_results)\n\n    return all_results\n\n\nmedian_imputer = SimpleImputer(missing_values=np.nan, strategy='median')\nmean_imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\nmode_imputer = SimpleImputer(missing_values=np.nan, strategy=\"most_frequent\")\n\n\nlist_persen = [0.05, 0.10, 0.15, 0.20, 0.25]\n\n\nall_results = compare_imputation(\n    df_ground_truth,\n    [median_imputer, mean_imputer, mode_imputer],\n    list_persen\n)\n\n\nall_results\n\n[[16106399718053.193,\n  27686624654974.12,\n  42067852690522.375,\n  57674869517426.2,\n  71398507402041.0],\n [15149962314993.664,\n  26691038947100.4,\n  39993567341678.87,\n  54874386927172.04,\n  67502299532092.21],\n [104263768244576.97,\n  200631901715894.3,\n  302872434183477.3,\n  413821496079702.0,\n  502638602704461.3]]\n\n\n\nprint(\"Median:\", all_results[0])\nprint(\"Mean:\", all_results[1])\nprint(\"Mode:\", all_results[2])\n\nMedian: [16106399718053.193, 27686624654974.12, 42067852690522.375, 57674869517426.2, 71398507402041.0]\nMean: [15149962314993.664, 26691038947100.4, 39993567341678.87, 54874386927172.04, 67502299532092.21]\nMode: [104263768244576.97, 200631901715894.3, 302872434183477.3, 413821496079702.0, 502638602704461.3]\n\n\n\nplt.plot(list_persen, all_results[0])\nplt.plot(list_persen, all_results[1])\nplt.plot(list_persen, all_results[2])\nplt.legend([\"Median\", \"Mean\", \"Mode\"])\nplt.show()\n\n\n\n\n\n\n\n\nDari hasil tersebut, didapat bahwa secara keseluruhan, untuk setiap persentase missing values, metode imputasi dengan menggunakan mean menghasilkan SSE yang terkecil dibandingkan imputasi dengan median dan modus. Oleh karena itu, kita akan menggunakan metode imputasi menggunakan mean untuk mengisi missing value pada kolom “total_bedrooms” dari df asli.\n\n# melihat kembali df awal\ndf\n\n\n\n\n\n\n\n\n\nlongitude\nlatitude\nhousing_median_age\ntotal_rooms\ntotal_bedrooms\npopulation\nhouseholds\nmedian_income\nmedian_house_value\n&lt;1H OCEAN\nINLAND\nISLAND\nNEAR BAY\nNEAR OCEAN\n\n\n\n\n0\n-122.23\n37.88\n41.0\n880.0\n129.0\n322.0\n126.0\n8.3252\n452600.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n1\n-122.22\n37.86\n21.0\n7099.0\n1106.0\n2401.0\n1138.0\n8.3014\n358500.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n2\n-122.24\n37.85\n52.0\n1467.0\n190.0\n496.0\n177.0\n7.2574\n352100.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n3\n-122.25\n37.85\n52.0\n1274.0\n235.0\n558.0\n219.0\n5.6431\n341300.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n4\n-122.25\n37.85\n52.0\n1627.0\n280.0\n565.0\n259.0\n3.8462\n342200.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n20635\n-121.09\n39.48\n25.0\n1665.0\n374.0\n845.0\n330.0\n1.5603\n78100.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20636\n-121.21\n39.49\n18.0\n697.0\n150.0\n356.0\n114.0\n2.5568\n77100.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20637\n-121.22\n39.43\n17.0\n2254.0\n485.0\n1007.0\n433.0\n1.7000\n92300.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20638\n-121.32\n39.43\n18.0\n1860.0\n409.0\n741.0\n349.0\n1.8672\n84700.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20639\n-121.24\n39.37\n16.0\n2785.0\n616.0\n1387.0\n530.0\n2.3886\n89400.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n\n\n20640 rows × 14 columns\n\n\n\n\n\ndf.isna().sum()\n\nlongitude               0\nlatitude                0\nhousing_median_age      0\ntotal_rooms             0\ntotal_bedrooms        207\npopulation              0\nhouseholds              0\nmedian_income           0\nmedian_house_value      0\n&lt;1H OCEAN               0\nINLAND                  0\nISLAND                  0\nNEAR BAY                0\nNEAR OCEAN              0\ndtype: int64\n\n\n\n# lakukan imputasi dengan metode terbaik yg telah didapat, yaitu dengan mean\n\ndf[['total_bedrooms']] = mean_imputer.fit_transform(df[['total_bedrooms']] )\n\n\ndf\n\n\n\n\n\n\n\n\n\nlongitude\nlatitude\nhousing_median_age\ntotal_rooms\ntotal_bedrooms\npopulation\nhouseholds\nmedian_income\nmedian_house_value\n&lt;1H OCEAN\nINLAND\nISLAND\nNEAR BAY\nNEAR OCEAN\n\n\n\n\n0\n-122.23\n37.88\n41.0\n880.0\n129.0\n322.0\n126.0\n8.3252\n452600.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n1\n-122.22\n37.86\n21.0\n7099.0\n1106.0\n2401.0\n1138.0\n8.3014\n358500.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n2\n-122.24\n37.85\n52.0\n1467.0\n190.0\n496.0\n177.0\n7.2574\n352100.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n3\n-122.25\n37.85\n52.0\n1274.0\n235.0\n558.0\n219.0\n5.6431\n341300.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n4\n-122.25\n37.85\n52.0\n1627.0\n280.0\n565.0\n259.0\n3.8462\n342200.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n20635\n-121.09\n39.48\n25.0\n1665.0\n374.0\n845.0\n330.0\n1.5603\n78100.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20636\n-121.21\n39.49\n18.0\n697.0\n150.0\n356.0\n114.0\n2.5568\n77100.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20637\n-121.22\n39.43\n17.0\n2254.0\n485.0\n1007.0\n433.0\n1.7000\n92300.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20638\n-121.32\n39.43\n18.0\n1860.0\n409.0\n741.0\n349.0\n1.8672\n84700.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n20639\n-121.24\n39.37\n16.0\n2785.0\n616.0\n1387.0\n530.0\n2.3886\n89400.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n\n\n20640 rows × 14 columns\n\n\n\n\n\ndf.isna().sum()\n\nlongitude             0\nlatitude              0\nhousing_median_age    0\ntotal_rooms           0\ntotal_bedrooms        0\npopulation            0\nhouseholds            0\nmedian_income         0\nmedian_house_value    0\n&lt;1H OCEAN             0\nINLAND                0\nISLAND                0\nNEAR BAY              0\nNEAR OCEAN            0\ndtype: int64\n\n\n\nExport Dataframe yang telah diimputasi ke CSV\n\ndf.to_csv(\"housing_modified.csv\")"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul3.html#regresi-linier",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul3.html#regresi-linier",
    "title": "Modul 3 Sains Data",
    "section": "Regresi Linier",
    "text": "Regresi Linier"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul2.html",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul2.html",
    "title": "Modul 2 Sains Data: Visualisasi Data",
    "section": "",
    "text": "Kembali ke Sains Data\nPada modul ini kita akan mempelajari beberapa cara untuk membuat visualisasi data menggunakan package Matplotlib dan Seaborn. Seaborn merupakan salah satu package visualisasi data yang sangat sering digunakan karena fleksibilitas dan banyaknya jenis plot yang disediakan."
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul2.html#prerequisites",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul2.html#prerequisites",
    "title": "Modul 2 Sains Data: Visualisasi Data",
    "section": "Prerequisites",
    "text": "Prerequisites\n\nImport Module\nSebelum memulai, mari kita import terlebih dahulu module - module yang diperlukan.\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n\nImport Data\nPada module kali ini, akan digunakan tiga data csv yang berbeda untuk mempermudah kebutuhan visualisasi, yaitu:\n\nSpotify Dataset (spotify.csv), bisa di-download dari\n\nDirect link (langsung dari GitHub Pages ini)\nKaggle\nGoogle Drive: https://bit.ly/DataWeek2 atau langsung\n\nFlight Delays Dataset (flight_delays.csv), bisa di-download dari\n\nDirect link (langsung dari GitHub Pages ini)\nKaggle\nGoogle Drive: https://bit.ly/DataWeek2 atau langsung\n\nInsurance Dataset (insurance.csv), bisa di-download dari\n\nDirect link (langsung dari GitHub Pages ini)\nKaggle\nGoogle Drive: https://bit.ly/DataWeek2 atau langsung\n\n\natau langsung download ketiganya sekaligus, bisa dari:\n\nGoogle Drive: https://bit.ly/DataWeek2 atau langsung\n\nKemudian, baca tiap CSV sebagai dataframe:\n\nspotify_df = pd.read_csv(\"./spotify.csv\",\n                         index_col='Date',\n                         parse_dates=['Date'])\nflight_df = pd.read_csv(\"./flight_delays.csv\")\ninsurance_df = pd.read_csv(\"./insurance.csv\")"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul2.html#review-matplotlib",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul2.html#review-matplotlib",
    "title": "Modul 2 Sains Data: Visualisasi Data",
    "section": "Review Matplotlib",
    "text": "Review Matplotlib\nSeperti yang sudah dipelajari pada Algoritma dan Pemrograman, visualisasi data dapat dilakukan dengan module matplotlib, antara lain untuk membuat line plot dan scatter plot.\nPertama, kita akan menggunakan data Spotify, yaitu data total daily streams 5 lagu hits pada masanya.\n\nspotify_df\n\n\n\n\n\n\n\n\n\nShape of You\nDespacito\nSomething Just Like This\nHUMBLE.\nUnforgettable\n\n\nDate\n\n\n\n\n\n\n\n\n\n2017-01-06\n12287078\nNaN\nNaN\nNaN\nNaN\n\n\n2017-01-07\n13190270\nNaN\nNaN\nNaN\nNaN\n\n\n2017-01-08\n13099919\nNaN\nNaN\nNaN\nNaN\n\n\n2017-01-09\n14506351\nNaN\nNaN\nNaN\nNaN\n\n\n2017-01-10\n14275628\nNaN\nNaN\nNaN\nNaN\n\n\n...\n...\n...\n...\n...\n...\n\n\n2018-01-05\n4492978\n3450315.0\n2408365.0\n2685857.0\n2869783.0\n\n\n2018-01-06\n4416476\n3394284.0\n2188035.0\n2559044.0\n2743748.0\n\n\n2018-01-07\n4009104\n3020789.0\n1908129.0\n2350985.0\n2441045.0\n\n\n2018-01-08\n4135505\n2755266.0\n2023251.0\n2523265.0\n2622693.0\n\n\n2018-01-09\n4168506\n2791601.0\n2058016.0\n2727678.0\n2627334.0\n\n\n\n\n366 rows × 5 columns\n\n\n\n\nCatatan:\n\nShape of You dirilis tanggal 6 Januari 2017.\nDespacito dirilis tanggal 13 Januari 2017.\nSomething Just Like This dirilis tanggal 22 Februari 2017.\nHUMBLE. dirilis tanggal 30 Maret 2017.\nUnforgettable dirilis tanggal 7 April 2017.\n\nPerhatikan bahwa ada beberapa data NaN (not a number), artinya tidak ada data (missing data).\n\nspotify_df.isna()\n\n\n\n\n\n\n\n\n\nShape of You\nDespacito\nSomething Just Like This\nHUMBLE.\nUnforgettable\n\n\nDate\n\n\n\n\n\n\n\n\n\n2017-01-06\nFalse\nTrue\nTrue\nTrue\nTrue\n\n\n2017-01-07\nFalse\nTrue\nTrue\nTrue\nTrue\n\n\n2017-01-08\nFalse\nTrue\nTrue\nTrue\nTrue\n\n\n2017-01-09\nFalse\nTrue\nTrue\nTrue\nTrue\n\n\n2017-01-10\nFalse\nTrue\nTrue\nTrue\nTrue\n\n\n...\n...\n...\n...\n...\n...\n\n\n2018-01-05\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n2018-01-06\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n2018-01-07\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n2018-01-08\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n2018-01-09\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n\n\n366 rows × 5 columns\n\n\n\n\n\nspotify_df.isna().sum()\n\nShape of You                 0\nDespacito                    7\nSomething Just Like This    47\nHUMBLE.                     84\nUnforgettable               91\ndtype: int64\n\n\nCara menangani missing values tergantung konteks. Di sini, lagu-lagu dengan data NaN pada tanggal tertentu memang belum dirilis.\n\nUntuk analisis trend tiap lagu sejak dirilis, sebaiknya data NaN dibiarkan saja.\nUntuk analisis frekuensi streaming, data NaN bisa diganti jadi nol. (Hati-hati, jangan sampai nantinya lupa dan malah terpikir “kok bisa ya lagu ini ga didengerin sama sekali”)\nApabila semua lagu ingin dibandingkan datanya di masa sudah rilis semua, sebaiknya baris-baris dengan data NaN itu dihapus.\n\nKali ini, kita akan memperhatikan trend tiap lagu, sehingga data NaN kita biarkan saja.\nBerikut adalah cara untuk membuat line plot pada satu fitur di dataframe menggunakan matplotlib\n\n\"\"\"\nMembuat line plot untuk lagu Shape of You menggunakan matplotlib\n\"\"\"\n\n# Mengatur besar figur plot\nplt.subplots(figsize=(8,6))\n\n# Membuat line plot\nplt.plot(spotify_df['Shape of You'], 'b')\n# Membuat label sumbu-x dan sumbu-y\nplt.xlabel('Date')\nplt.ylabel('Shape of You Total Daily Streams')\n# Menampilkan plot\nplt.show()\n\n\n\n\n\n\n\n\nApabila kita ingin menampilkan fitur-fitur lain dalam figur yang sama, kita dapat memanfaatkan loop\n\n\"\"\"\nMembuat line plot untuk semua lagu dalam spotify_df menggunakan loop\n\"\"\"\n\nplt.subplots(figsize=(8,6))\n\n# Loop setiap nama kolom pada dataframe, lalu plot\nfor column in spotify_df.columns:\n    plt.plot(spotify_df[column])\n\nplt.legend(spotify_df.columns)\nplt.show()\n\n\n\n\n\n\n\n\nNamun, terdapat cara yang lebih mudah selain menggunakan looping. pandas dataframe memiliki method yang dapat secara langsung memvisualisasikan keseluruhan fiturnya, yaitu .plot().\nPada .plot() kita memiliki beberapa parameter yang dapat diatur, antara lain kind dan figsize. kind berfungsi untuk mengatur jenis plot yang ingin kita buat, sedangkan figsize berfungsi untuk mengatur besar figur yang dihasilkan.\nParameter lainnya dapat dilihat pada:\nhttps://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.html\n\n\"\"\"\nMembuat line plot untuk semua lagu dalam spotify_df menggunakan pandas .plot()\n\"\"\"\n\nspotify_df.plot(kind='line', figsize=(8,6))\nplt.xlabel('Date')\nplt.ylabel('Total Daily Streams')\nplt.show()\n\n\n\n\n\n\n\n\nSelain line plot, terdapat banyak macam kind yang bisa digunakan. Pada code cell dibawah terlihat bahwa pandas .plot() dapat menghasilkan histogram (perlu diperhatikan bahwa jenis plot perlu menyesuaikan tipe data yang dimiliki, terlihat bahwa menggunakan data spotify, histogram tidak menghasilkan insight yang cukup berguna).\n\nspotify_df.plot(kind='hist', figsize=(8,6), alpha=.7)\n\nplt.show()\n\n\n\n\n\n\n\n\nPada praktikum Algoritma dan Pemrograman kita juga telah mempelajari cara untuk membuat scatter plot. Berikut code untuk membuat scatter plot menggunakan matplotlib, untuk melihat korelasi antara daily streams lagu Shape of You dengan Something Just Like This.\n\n\"\"\"\nMembuat scatter plot untuk melihat korelasi antara lagu\nShape of You dengan Something Just Like This menggunakan\nmatplotlib\n\"\"\"\n\nplt.subplots(figsize=(8,6))\n\nplt.scatter(x=spotify_df['Shape of You'], \n            y=spotify_df['Something Just Like This'],\n            alpha=.5)\nplt.xlabel('\"Shape of You\" Total Daily Streams')\nplt.ylabel('\"Something Just Like This\" Total Daily Streams')\nplt.show()"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul2.html#pengenalan-seaborn",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul2.html#pengenalan-seaborn",
    "title": "Modul 2 Sains Data: Visualisasi Data",
    "section": "Pengenalan Seaborn",
    "text": "Pengenalan Seaborn\nWalaupun matplotlib cukup fleksibel dalam menghasilkan plot, tetapi tipe plot yang disediakan cenderung terbatas. Oleh karena itu, kita dapat menggunakan Seaborn karena tipe plot yang disediakan sangat banyak sesuai kebutuhan kita, antara lain line, bar, heatmap, scatter, box, swarm, histogram, density, dan masih banyak lagi.\n\nLine Plot\nLine plot biasa digunakan untuk melihat trend data dalam jangka waktu tertentu.\nUntuk membuat line plot pada seaborn, kita dapat menggunakan sns.lineplot(). Jika data yang ingin kita visualisasikan adalah dataframe, kita dapat memasukkan variabel dataframe tersebut pada parameter data, seperti code di bawah ini.\n\n\"\"\"\nMembuat line plot dengan module seaborn\n\"\"\"\n\nplt.subplots(figsize=(8,6))\nsns.lineplot(data=spotify_df)\nplt.show()\n\n\n\n\n\n\n\n\nFleksibilitas Seaborn membuat kita dapat memilih color palette yang sesuai dengan keinginan kita. Kita dapat memilih palette yang sudah disediakan oleh seaborn (antara lain: bright, deep, pastel, dan masih banyak lagi) atau kita dapat mengatur sendiri palette yang ingin kita gunakan.\nUntuk memilih palette yang akan digunakan untuk plot selanjutnya pada seaborn, kita dapat menggunakan sns.set_palette().\nJenis palette yang disediakan seaborn serta cara membuat color palette secara mandiri dapat dilihat pada:\nhttps://seaborn.pydata.org/tutorial/color_palettes.html#tools-for-choosing-color-palettes\n\n# Mengganti color palette menjadi \"bright\"\nsns.set_palette('bright')\n\n\n\"\"\"\nMembuat line plot setelah color palette diubah menjadi \"bright\"\n\"\"\"\n\n# Mengatur besar figur yang ingin ditampilkan\nplt.figure(figsize=(14,6))\n\n# Membuat line plot\nsns.lineplot(data=spotify_df)\n# Membuat judul figur\nplt.title(\"Daily Global Streams of Popular Songs in 2017-2018\")\n# Menampilkan plot\nplt.show()\n\n\n\n\n\n\n\n\nApabila tidak semua fitur pada data ingin kita visualisasikan, kita dapat menggunakan sns.lineplot() beberapa kali, sesuai dengan banyaknya fitur yang ingin kita tampilkan, seperti pada code di bawah.\n\nplt.figure(figsize=(14,6))\n\n# Membuat line plot hanya dengan lagu Shape of You\nsns.lineplot(data=spotify_df['Shape of You'], label=\"Shape of You\")\n# Menambahkan line plot pada figur dengan lagu Despacito\nsns.lineplot(data=spotify_df['Despacito'], label=\"Despacito\")\n\nplt.title(\"Daily Global Streams of Popular Songs in 2017-2018\")\nplt.xlabel(\"Date\")\nplt.ylabel('')\nplt.show()\n\n\n\n\n\n\n\n\n\n\nBar Plot\nBar plot biasa digunakan untuk membandingkan kuantitas/nilai pada data bertipe kategori.\nSelanjutnya, kita akan menggunakan data flight_delays.csv, yaitu data rata-rata keterlambatan beberapa maskapai pesawat pada setiap bulannya.\n\nflight_df\n\n\n\n\n\n\n\n\n\nMonth\nAA\nAS\nB6\nDL\nEV\nF9\nHA\nMQ\nNK\nOO\nUA\nUS\nVX\nWN\n\n\n\n\n0\n1\n6.955843\n-0.320888\n7.347281\n-2.043847\n8.537497\n18.357238\n3.512640\n18.164974\n11.398054\n10.889894\n6.352729\n3.107457\n1.420702\n3.389466\n\n\n1\n2\n7.530204\n-0.782923\n18.657673\n5.614745\n10.417236\n27.424179\n6.029967\n21.301627\n16.474466\n9.588895\n7.260662\n7.114455\n7.784410\n3.501363\n\n\n2\n3\n6.693587\n-0.544731\n10.741317\n2.077965\n6.730101\n20.074855\n3.468383\n11.018418\n10.039118\n3.181693\n4.892212\n3.330787\n5.348207\n3.263341\n\n\n3\n4\n4.931778\n-3.009003\n2.780105\n0.083343\n4.821253\n12.640440\n0.011022\n5.131228\n8.766224\n3.223796\n4.376092\n2.660290\n0.995507\n2.996399\n\n\n4\n5\n5.173878\n-1.716398\n-0.709019\n0.149333\n7.724290\n13.007554\n0.826426\n5.466790\n22.397347\n4.141162\n6.827695\n0.681605\n7.102021\n5.680777\n\n\n5\n6\n8.191017\n-0.220621\n5.047155\n4.419594\n13.952793\n19.712951\n0.882786\n9.639323\n35.561501\n8.338477\n16.932663\n5.766296\n5.779415\n10.743462\n\n\n6\n7\n3.870440\n0.377408\n5.841454\n1.204862\n6.926421\n14.464543\n2.001586\n3.980289\n14.352382\n6.790333\n10.262551\nNaN\n7.135773\n10.504942\n\n\n7\n8\n3.193907\n2.503899\n9.280950\n0.653114\n5.154422\n9.175737\n7.448029\n1.896565\n20.519018\n5.606689\n5.014041\nNaN\n5.106221\n5.532108\n\n\n8\n9\n-1.432732\n-1.813800\n3.539154\n-3.703377\n0.851062\n0.978460\n3.696915\n-2.167268\n8.000101\n1.530896\n-1.794265\nNaN\n0.070998\n-1.336260\n\n\n9\n10\n-0.580930\n-2.993617\n3.676787\n-5.011516\n2.303760\n0.082127\n0.467074\n-3.735054\n6.810736\n1.750897\n-2.456542\nNaN\n2.254278\n-0.688851\n\n\n10\n11\n0.772630\n-1.916516\n1.418299\n-3.175414\n4.415930\n11.164527\n-2.719894\n0.220061\n7.543881\n4.925548\n0.281064\nNaN\n0.116370\n0.995684\n\n\n11\n12\n4.149684\n-1.846681\n13.839290\n2.504595\n6.685176\n9.346221\n-1.706475\n0.662486\n12.733123\n10.947612\n7.012079\nNaN\n13.498720\n6.720893\n\n\n\n\n\n\n\n\nUntuk membuat bar plot pada seaborn dengan dataframe, kita dapat menggunakan sns.barplot() dengan tiga parameter yang wajib kita set, yaitu:\n\ndata: dataframe yang ingin kita visualisasikan\nx: nama fitur pada dataframe yang ingin kita jadikan sumbu-x\ny: nama fitur pada dataframe yang ingin kita jadikan sumbu-y\n\nPada kode di bawah, juga digunakan satu parameter opsional, yaitu palette yang merupakan cara lain untuk mengatur color palette yang ingin kita gunakan\n\n\"\"\"\nMembuat bar plot keterlambatan maskapai EV setiap \nbulannya menggunakan seaborn\n\"\"\"\n\nplt.figure(figsize=(14,6))\n\nsns.barplot(data=flight_df, x='Month', y='EV',\n            palette=sns.color_palette('deep'))\nplt.ylabel('EV Flight Delays (minute)')\nplt.title('Average EV Flight Delays per Month')\nplt.show()\n\n\n\n\n\n\n\n\nBerdasarkan hasil plot di atas, terlihat bahwa maskapai EV memiliki rata-rata keterlambatan terlama pada bulan Juni, serta tercepat pada bulan September.\nSelanjutnya, mari kita coba lihat urutan rata-rata keterlambatan semua maskapai dalam satu tahun (maskapai mana yang memiliki rata-rata keterlambatan terlama, serta maskapai mana yang tercepat).\nHal pertama yang perlu kita lakukan adalah, jadikan fitur Month sebagai index dataframe.\n\n# Set fitur \"Month\" menjadi index dataframe\nflight_df = flight_df.set_index('Month')\nflight_df.head(2)\n\n\n\n\n\n\n\n\n\nAA\nAS\nB6\nDL\nEV\nF9\nHA\nMQ\nNK\nOO\nUA\nUS\nVX\nWN\n\n\nMonth\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\n6.955843\n-0.320888\n7.347281\n-2.043847\n8.537497\n18.357238\n3.512640\n18.164974\n11.398054\n10.889894\n6.352729\n3.107457\n1.420702\n3.389466\n\n\n2\n7.530204\n-0.782923\n18.657673\n5.614745\n10.417236\n27.424179\n6.029967\n21.301627\n16.474466\n9.588895\n7.260662\n7.114455\n7.784410\n3.501363\n\n\n\n\n\n\n\n\nSelanjutnya, kita perlu hitung rata-rata keterlambatan tiap maskapai dalam satu tahun, yaitu hitung rata-rata tiap kolom pada dataframe menggunakan .mean() (Tambahan: apabila kita ingin menghitung rata-rata tiap barisnya, kita dapat menggunakan parameter axis=1 pada .mean()). .mean() akan menghasilkan pandas Series.\nLalu, agar mempermudah kita dalam melihat visualisasi bar plotnya, kita dapat menggunakan .sort_values().\n\n# Simpan rata-rata keterlambatan semua maskapai dalam satu tahun pada variabel flight_mean_inyear\nflight_mean_inyear = flight_df.mean()\n# Urutkan flight_mean_inyear secara ascending\nflight_mean_inyear = flight_mean_inyear.sort_values()\n\nflight_mean_inyear\n\nAS    -1.023656\nDL     0.231116\nHA     1.993205\nUS     3.776815\nAA     4.120776\nWN     4.275277\nVX     4.717718\nUA     5.413415\nOO     5.909658\nMQ     5.964953\nEV     6.543328\nB6     6.788370\nF9    13.035736\nNK    14.549663\ndtype: float64\n\n\nTerakhir, visualisasikan bar plot menggunakan cara seperti sebelumnya.\nKita dapat lihat pada code dibawah bahwa tidak digunakan parameter data, karena flight_mean_inyear merupakan pandas Series (bukan dataframe) sehingga lebih mudah jika kita langsung menggunakan parameter x dan y saja.\n\nplt.subplots(figsize=(14,6))\nsns.barplot(x=flight_mean_inyear.index, \n            y=flight_mean_inyear.values,\n            palette=sns.color_palette('deep'))\nplt.title('Average Delay per Flight in a Year')\nplt.show()\n\n\n\n\n\n\n\n\nBerdasarkan plot diatas, NK merupakan maskapai dengan rata-rata keterlambatan terlama dalam satu tahun, sedangkan AS adalah yang tercepat (AS bernilai negatif yang berarti rata-rata kedatangan pesawat lebih cepat dari yang dijadwalkan dalam satu tahun.\n\n\nHeatmap\nHeatmap biasa digunakan untuk mempermudah melihat pola pada data berdasarkan warna yang dihasilkan.\nPada seaborn, kita dapat menggunakan heatmap dengan sns.heatmap() seperti pada kode dibawah. Parameter annot berfungsi untuk menampilkan nilai data (jika True) atau tidak (jika False).\nBar sebelah kanan heatmap menunjukkan bahwa, semakin lama keterlambatan pesawat, maka warna yang dihasilkan semakin terang. Sebaliknya, semakin gelap warna yang dihasilkan berarti semakin cepat pesawat datang tersebut.\n\n\"\"\"\nMembuat heatmap menggunakan Seaborn\n\"\"\"\nplt.figure(figsize=(14,10))\n\nsns.heatmap(data=flight_df, annot=True)\nplt.title(\"Average Arrival Delay for Each Airline, by Month\")\nplt.xlabel(\"Airline\")\nplt.show()\n\n\n\n\n\n\n\n\nBerdasarkan heatmap di atas, kita dapat melihat dengan mudah pada bulan apa suatu maskapai sangat terlambat (contoh: maskapai NK pada bulan Juni).\nHeatmap sangat sering digunakan untuk melihat korelasi antarfitur pada dataset agar kita dapat mengerti lebih jauh tentang fitur-fitur pada data, atau juga dapat dimanfaatkan untuk melakukan feature selection sebelum membuat sebuat model Machine Learning.\nUntuk melakukan hal tersebut, kita perlu menghitung dahulu korelasi antar fitur menggunakan pandas .corr(), yaitu fungsi yang akan menghitung korelasi antar dua fitur menggunakan korelasi Pearson.\nNotes: Metode korelasi dapat diubah dengan menggunakan parameter method pada .corr(), contoh: .corr(method='spearman'). Metode lainnya dapat dilihat pada:\nhttps://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html\n\n# Hitung korelasi antar dua fitur pada flight_df\nflight_corr = flight_df.corr()\n\nflight_corr\n\n\n\n\n\n\n\n\n\nAA\nAS\nB6\nDL\nEV\nF9\nHA\nMQ\nNK\nOO\nUA\nUS\nVX\nWN\n\n\n\n\nAA\n1.000000\n0.334980\n0.429854\n0.805229\n0.896523\n0.903986\n0.220065\n0.842701\n0.573716\n0.620477\n0.809874\n0.823713\n0.425237\n0.615664\n\n\nAS\n0.334980\n1.000000\n0.340359\n0.394359\n0.356608\n0.336791\n0.684979\n0.283977\n0.480863\n0.350657\n0.457414\n0.489025\n0.229571\n0.519228\n\n\nB6\n0.429854\n0.340359\n1.000000\n0.643313\n0.342627\n0.510718\n0.467905\n0.529724\n0.032038\n0.591115\n0.233021\n0.788345\n0.579750\n0.151750\n\n\nDL\n0.805229\n0.394359\n0.643313\n1.000000\n0.796951\n0.783265\n0.262251\n0.598765\n0.625277\n0.569073\n0.797339\n0.821757\n0.700605\n0.691805\n\n\nEV\n0.896523\n0.356608\n0.342627\n0.796951\n1.000000\n0.828515\n0.099369\n0.721468\n0.784026\n0.692697\n0.911499\n0.669736\n0.462638\n0.730115\n\n\nF9\n0.903986\n0.336791\n0.510718\n0.783265\n0.828515\n1.000000\n0.273878\n0.912984\n0.414064\n0.582509\n0.671986\n0.878874\n0.308397\n0.465765\n\n\nHA\n0.220065\n0.684979\n0.467905\n0.262251\n0.099369\n0.273878\n1.000000\n0.436015\n0.176485\n0.056941\n0.066821\n0.586160\n-0.008439\n-0.007296\n\n\nMQ\n0.842701\n0.283977\n0.529724\n0.598765\n0.721468\n0.912984\n0.436015\n1.000000\n0.281890\n0.586963\n0.503575\n0.660181\n0.150111\n0.239744\n\n\nNK\n0.573716\n0.480863\n0.032038\n0.625277\n0.784026\n0.414064\n0.176485\n0.281890\n1.000000\n0.365273\n0.827455\n0.293515\n0.395419\n0.742869\n\n\nOO\n0.620477\n0.350657\n0.591115\n0.569073\n0.692697\n0.582509\n0.056941\n0.586963\n0.365273\n1.000000\n0.626051\n0.590313\n0.561515\n0.548304\n\n\nUA\n0.809874\n0.457414\n0.233021\n0.797339\n0.911499\n0.671986\n0.066821\n0.503575\n0.827455\n0.626051\n1.000000\n0.477816\n0.536968\n0.926800\n\n\nUS\n0.823713\n0.489025\n0.788345\n0.821757\n0.669736\n0.878874\n0.586160\n0.660181\n0.293515\n0.590313\n0.477816\n1.000000\n0.333396\n0.242344\n\n\nVX\n0.425237\n0.229571\n0.579750\n0.700605\n0.462638\n0.308397\n-0.008439\n0.150111\n0.395419\n0.561515\n0.536968\n0.333396\n1.000000\n0.630278\n\n\nWN\n0.615664\n0.519228\n0.151750\n0.691805\n0.730115\n0.465765\n-0.007296\n0.239744\n0.742869\n0.548304\n0.926800\n0.242344\n0.630278\n1.000000\n\n\n\n\n\n\n\n\nPandas .corr() menghasilkan dataframe dengan nama baris dan kolom yang sama, serta berisi nilai korelasi antara baris dan kolom yang ditinjau (contoh: korelasi antara maskapai AA dan AS adalah 0,334980). Serta, dataframe yang dihasilkan adalah sebuat matriks simetris.\nTentu dengan hanya melihat dataframe di atas, tidak terlihat begitu jelas mana fitur yang memiliki korelasi tinggi dan mana yang yang memiliki korelasi rendah. Oleh karena itu, kita dapat memanfaatkan heatmap.\nPada code di bawah, untuk mempermudah pembacaan heatmap, kita menggunakan parameter vmin, vmax, dan center pada sns.heatmap(). vmin berfungsi untuk mengatur nilai terendah, vmax berfungsi untuk mengatur nilai tertinggi, dan center berfungsi untuk mengatur nilai tengah pada heatmap. Korelasi Pearson menghasilkan nilai antara -1 hingga 1, sehingga kita dapat set ketiga parameter tersebut seperti pada code di bawah.\n\nplt.figure(figsize=(14,10))\n\nsns.heatmap(data=flight_corr, vmin=-1, vmax=1, center=0, annot=True)\nplt.title(\"Pearson Correlation of Each Airline Flight Delays\")\nplt.xlabel(\"Airline\")\nplt.show()\n\n\n\n\n\n\n\n\nDengan menggunakan heatmap, sekarang terlihat bahwa mana maskapai yang keterlambatannya berkorelasi tinggi dan mana yang rendah. Misal, AA dan EV menghasilkan korelasi yang cukup tinggi positif, yaitu 0.9, yang artinya jika keterlambatan maskapai AA tinggi, begitu juga maskapai EV, dan sebaliknya jika keterlambatan maskapai AA rendah, begitu juga maskapai EV.\nUntuk meyakinkan kita dengan hal tersebut, kita dapat lihat pada materi selanjutnya, yaitu Scatter Plot.\n\n\nScatter Plot\nScatter plot biasa digunakan untuk melihat korelasi antara dua fitur bertipe numerik.\nUntuk menggunakan scatter plot pada seaborn, kita dapat menggunakan sns.scatterplot(), dengan parameter yang sama seperti kita membuat bar plot.\n\n\"\"\"\nMembuat scatter plot untuk melihat \nketerkaitan pada keterlambatan pesawat\nmaskapai EV dan AA\n\"\"\"\n\nsns.scatterplot(data=flight_df, x='EV', y='AA')\nplt.show()\n\n\n\n\n\n\n\n\nMelalui scatter plot di atas, kita dapat semakin yakin bahwa kesimpulan yang kita ambil dengan melihat heatmap sebelumnya benar.\n\n\"\"\"\nTambahan scatter plot pada maskapai lain yang\nmemiliki korelasi tinggi\n\"\"\"\n\nsns.scatterplot(data=flight_df, x='EV', y='UA')\nplt.show()\n\n\n\n\n\n\n\n\n\n\"\"\"\nScatter plot pada maskapai yang memiliki\nkorelasi rendah (mendekati 0)\n\"\"\"\n\nsns.scatterplot(data=flight_df, x='UA', y='HA')\nplt.show()\n\n\n\n\n\n\n\n\nPada heatmap, terlihat bahwa maskapai UA dan HA memiliki korelasi yang rendah, yaitu 0.067. Sehingga, jika kita buat scatter plotnya, menghasilkan plot seperti di atas.\nSekarang kita akan menggunakan dataset lainnya, yaitu insurance.csv yang merupakan data berisi biaya asuransi (charges) beberapa orang.\n\ninsurance_df.head()\n\n\n\n\n\n\n\n\n\nage\nsex\nbmi\nchildren\nsmoker\nregion\ncharges\n\n\n\n\n0\n19\nfemale\n27.900\n0\nyes\nsouthwest\n16884.92400\n\n\n1\n18\nmale\n33.770\n1\nno\nsoutheast\n1725.55230\n\n\n2\n28\nmale\n33.000\n3\nno\nsoutheast\n4449.46200\n\n\n3\n33\nmale\n22.705\n0\nno\nnorthwest\n21984.47061\n\n\n4\n32\nmale\n28.880\n0\nno\nnorthwest\n3866.85520\n\n\n\n\n\n\n\n\nMisal, kita ingin melihat keterkaitan indeks massa tubuh (bmi) seseorang dengan biaya asuransi (charges) orang tersebut. Sama seperti sebelumnya, kita dapat melakukannya seperti pada code di bawah.\n\n# Mengubah palette menjadi default\nsns.set_palette('tab10')\n# Membuat scatter plot antara fitur bmi dan charges\nsns.scatterplot(data=insurance_df, x='bmi', y='charges')\n\nplt.show()\n\n\n\n\n\n\n\n\nScatter plot di atas menunjukkan bahwa korelasi antara bmi dan charges adalah cenderung positif, tetapi tidak terlalu tinggi. Yang artinya, orang dengan BMI tinggi, cenderung akan membayar biaya asuransi lebih tinggi.\nAgar kita semakin yakin dengan kesimpulan tersebut, kita dapat menambahakn garis regresi pada scatter plot tersebut dengan menggunakan sns.regplot().\n\nsns.regplot(data=insurance_df, x='bmi', y='charges')\nplt.show()\n\n\n\n\n\n\n\n\nBerdasarkan scatter plot dan garis regresi dihasilkan, terlihat bahwa kesimpulan yang kita ambil benar. Agar semakin yakin lagi, kita juga dapat menghitung langsung korelasi Pearsonnya menggunakan cara sebelumnya, yaitu pandas .corr().\n\ninsurance_df[['bmi', 'charges']].corr()\n\n\n\n\n\n\n\n\n\nbmi\ncharges\n\n\n\n\nbmi\n1.000000\n0.198341\n\n\ncharges\n0.198341\n1.000000\n\n\n\n\n\n\n\n\nDengan menggunakan seaborn, kita juga dapat memvisualisasikan scatter plot berdasarkan dengan pewarnaan yang berbeda berdasarkan fitur lainnya yang bertipe kategorik.\nMisal, kita ingin membuat scatter plot antara fitur bmi dan charges dengan pewarnaannya berdasarkan nilai dari fitur smoker, yaitu yes atau no. Kita dapat set parameter hue='smoker' pada sns.scatterplot() seperti pada code di bawah.\n\nsns.scatterplot(data=insurance_df, x='bmi', y='charges', hue='smoker')\nplt.show()\n\n\n\n\n\n\n\n\nSehingga dihasilkan pewarnaan yang berbeda untuk seseorang yang merupakan perokok (biru) dan yang tidak (orange). Berdasarkan scatter plot di atas, terlihat bahwa korelasi antara bmi dan charges untuk perokok cendering tinggi positif (semakin besar bmi, semakin besar juga charges). Sedangkan, untuk bukan perokok, korelasinya cenderung rendah (semakin besar bmi, tidak terlalu berpengaruh terhadap charges).\nSeperti cara sebelumnya, kita dapat menambahkan garis regresi. Namun, karena kita disini menggunakan hue, terdapat dua cara untuk menambahkan garis regresi, yaitu yang pertama adalah menggunakan sns.regplot() seperti di bawah ini.\n\nsns.regplot(data=insurance_df.query('smoker == \"yes\"'), x='bmi', y='charges') # axes 1\nsns.regplot(data=insurance_df.query('smoker == \"no\"'), x='bmi', y='charges') # axes 2\nplt.show()\n\n\n\n\n\n\n\n\nPerhatikan bahwa sns.regplot() dipanggil dua kali karena fungsi tersebut tidak memiliki parameter hue.\nUntuk mempermudah, kita dapat menggunakan cara kedua, yaitu menggunakan sns.lmplot(). Cara kerja sns.lmplot() yaitu menggabungkan dua (atau lebih) sns.regplot() dalam satu figur.\n\nsns.lmplot(data=insurance_df, x='bmi', y='charges', hue='smoker')\nplt.show()\n\n\n\n\n\n\n\n\n\n\nBox Plot dan Swarm Plot\nBox plot dan swarm plot biasa digunakan untuk melihat keterkaitan antara data kategorik dan data numerik. Swarm plot biasa disebut sebagai “categorical scatter plot”, karena plot yang dihasilkan mirip seperti scatter plot, tetapi untuk data kategorik.\nUntuk menggunakan box plot pada seaborn kita dapat menggunakan sns.boxplot().\nUntuk menggunakan swarm plot pada seaborn kita dapat menggunakan sns.swarmplot().\nMisal, kita ingin melihat keterkaitan antara fitur smoker dan charges menggunakan swarm plot. Maka, kita dapat menggunakan code seperti di bawah ini.\n\nplt.subplots(figsize=(10,6))\n\nsns.swarmplot(data=insurance_df, x='smoker', y='charges', size=3)\nplt.show()\n\n\n\n\n\n\n\n\nBerdasarkan swarm plot di atas, terlihat bahwa perokok cenderung memiliki biaya asuransi yang lebih tinggi dibandingkan yang bukan perokok. Selain itu, semakin lebar “swarm” pada suatu kategori berarti semakin banyak seseorang dengan nilai charges tersebut.\nApabila kita ingin menggunakan box plot, maka dapat digunakan code seperti di bawah ini.\n\nsns.boxplot(data=insurance_df, x='smoker', y='charges')\nplt.show()\n\n\n\n\n\n\n\n\nPada box plot, terdapat dua istilah yang umum digunakan, yaitu “box” dan “whiskers”. Pada box plot di atas, “box” merupakan persegi panjang berwarna biru dan orange. Garis di tengah box merupakan nilai mediannya, serta garis bawah dan garis atas box merupakan kuartil bawah (Q1) dan kuartil atas (Q3) secara berurutan. “Whiskers” adalah garis yang merupakan perpanjangan dari box. Ujung dari whiskers atas adalah Q3 + (1.5 x IQR) data, sedangkan ujung whiskers bawah adalah Q1 - (1.5 x IQR) data.\nTitik di luar box dan whiskers tersebut adalah titik yang biasa dijadikan sebagai outlier (penentuan outlier diserahkan ke diri masing-masing, apakah hanya dengan melihat box plot atau dengan menggunakan metode lain, tetapi untuk mempermudah dapat menggunakan box plot).\n\n\nHistogram dan Density Plot\nSelain box plot dan swarm plot, kita juga dapat melihat persebaran data menggunakan histogram dan density plot. Histogram biasa digunakan untuk melihat persebaran data secara diskrit, sedangkan density plot untuk melihat persebaran data secara kontinu.\nUntuk membuat histogram pada seaborn, kita dapat menggunakan sns.histplot().\nUntuk membuat density plot pada seaborn, kita dapat menggunakan sns.kdeplot().\nMisal, kita ingin melihat persebaran dari fitur charges pada insurance_df. Maka dapat digunakan code seperti di bawah.\n\nplt.subplots(figsize=(12,6))\n\nsns.histplot(data=insurance_df, x='charges')\nplt.show()\n\n\n\n\n\n\n\n\nBerdasarkan histogram di atas, terlihat bahwa distribusi charges cenderung “skew” atau miring ke kanan. “Skewness” atau tingkat kecondongan merupakan aspek yang penting untuk diperhatikan ketika kita ingin membuat model Machine Learning.\nSeperti scatter plot, kita juga dapat menentukan pewarnaan histogram berdasarkan fitur lainnya dengan menggunakan parameter hue seperti di bawah ini/\n\nplt.subplots(figsize=(12,6))\nsns.histplot(data=insurance_df, x='charges', hue='smoker')\nplt.show()\n\n\n\n\n\n\n\n\nJika ingin membuat density plot dari fitur charges, kita dapat menggunakan kode seperti di bawah ini. Parameter shade berfungsi untuk memberikan warna di bawah kurva.\n\nplt.subplots(figsize=(12,6))\nsns.kdeplot(data=insurance_df, x='charges', shade=True)\nplt.show()\n\n\n\n\n\n\n\n\nsns.kdeplot() juga dapat menggunakan parameter hue.\n\nplt.subplots(figsize=(12,6))\nsns.kdeplot(data=insurance_df, x='charges',\n            hue='smoker', shade=True)\nplt.show()\n\n\n\n\n\n\n\n\nApabila kita ingin menggabungkan histogram dan density plot dalam satu figur, kita dapat menggunakan sns.histplot() dengan parameter kde=True.\n\nplt.subplots(figsize=(12,6))\nsns.histplot(data=insurance_df, x='charges', hue='smoker', kde=True)\nplt.show()\n\n\n\n\n\n\n\n\n\n\nJoint Plot\nPada seaborn, kita juga dapat membuat dua plot yang berbeda dari dua fitur dalam satu figur yang sama menggunakan sns.jointplot().\nJenis plot yang dihasilkan dapat diatur pada parameter kind. Pilihan jenis kind yang disediakan dapat dilihat pada:\nhttps://seaborn.pydata.org/generated/seaborn.jointplot.html\n\nsns.jointplot(data=insurance_df, x='charges', y='bmi', hue='smoker', kind=\"scatter\")\n\nplt.show()\n\n\n\n\n\n\n\n\n\nsns.jointplot(data=insurance_df, x='charges', y='bmi', hue='smoker', kind=\"hist\")\n\nplt.show()\n\n\n\n\n\n\n\n\n\nsns.jointplot(data=insurance_df, x='charges', y='bmi', hue='smoker', kind=\"kde\")\n\nplt.show()"
  },
  {
    "objectID": "semuahalaman/modulprak/2024/genap/saindat/modul2.html#supplementary-panduan-pemilihan-plot",
    "href": "semuahalaman/modulprak/2024/genap/saindat/modul2.html#supplementary-panduan-pemilihan-plot",
    "title": "Modul 2 Sains Data: Visualisasi Data",
    "section": "Supplementary: Panduan Pemilihan Plot",
    "text": "Supplementary: Panduan Pemilihan Plot\n\n\n\nimage.png\n\n\nsource: https://www.kaggle.com/code/alexisbcook/choosing-plot-types-and-custom-styles"
  }
]